Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f0c896aaf28>, tc2=<function tc2 at 0x7f0c896bb048>, tc3=<function tc3 at 0x7f0c896bb158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 11.7254
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 11
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24745908> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 11.725352112676056
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246dad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24745a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 11.725352112676056
Completed Iteration #0
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 2
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 3
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 4
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 5
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 6
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 7
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 8
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 9
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 10
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 11
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 12
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 13
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 14
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 15
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 16
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 17
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.03521126760563398 18
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.07042253521126796 19
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.07042253521126796 20
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.07042253521126796 21
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.07042253521126796 22
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.07042253521126796 23
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c246edf28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 24
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 25
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 26
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 27
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 28
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 29
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 30
Completed Iteration #24
Best Reward: 0.03521126760563398
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 31
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 32
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edf28> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 18
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 33
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 19
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 34
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 20
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 35
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 36
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 22
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 37
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 23
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 38
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 24
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 39
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 12
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 25
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 40
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 26
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 41
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->5->15
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 14
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 27
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 42
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 28
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 43
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.07042253521126796 16
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.10563380281690193 29
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.10563380281690193 44
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edf28> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1408450704225359 30
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1408450704225359 45
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.10563380281690193 18
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1408450704225359 31
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1408450704225359 46
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.10563380281690193 19
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1408450704225359 32
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1408450704225359 47
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c24640780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246408d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1710> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 33
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 48
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 34
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 49
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 35
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 50
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1710> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 36
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 51
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 24
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 37
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 52
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 25
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 38
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 53
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1408450704225359 26
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.1760563380281699 39
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.1760563380281699 54
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 27
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 40
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 55
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->5->15->8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 28
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 41
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 56
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 29
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 42
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 57
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 30
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 43
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 58
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 31
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 44
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 59
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 32
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 45
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 60
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 24
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 33
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 46
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 61
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 25
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 34
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 47
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 62
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 26
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 35
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 48
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 63
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 27
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 36
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 49
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 64
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 28
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 37
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 50
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 65
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 29
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 38
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 51
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 66
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 30
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 39
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 52
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 67
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 31
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 40
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 53
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 68
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1408450704225359 32
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.1760563380281699 41
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.21126760563380387 54
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.21126760563380387 69
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.07042253521126796 17
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1760563380281699 33
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.21126760563380387 42
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.24647887323943785 55
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.24647887323943785 70
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->5->15->8->10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.07042253521126796 18
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1760563380281699 34
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.21126760563380387 43
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.24647887323943785 56
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.24647887323943785 71
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.07042253521126796 19
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1760563380281699 35
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.21126760563380387 44
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.24647887323943785 57
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.24647887323943785 72
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.07042253521126796 20
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.1760563380281699 36
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.21126760563380387 45
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.24647887323943785 58
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.24647887323943785 73
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.10563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.21126760563380387 37
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.24647887323943785 46
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.2816901408450718 59
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.2816901408450718 74
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be47d54a8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.24647887323943785 38
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.2816901408450718 47
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3169014084507058 60
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3169014084507058 75
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.24647887323943785 39
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.2816901408450718 48
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3169014084507058 61
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3169014084507058 76
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.2816901408450718 40
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3169014084507058 49
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3521126760563398 62
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3521126760563398 77
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.2816901408450718 41
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3169014084507058 50
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3521126760563398 63
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3521126760563398 78
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1760563380281699 26
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.2816901408450718 42
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3169014084507058 51
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3521126760563398 64
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3521126760563398 79
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1760563380281699 27
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.2816901408450718 43
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3169014084507058 52
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3521126760563398 65
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3521126760563398 80
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->5->15->8->10->2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.1760563380281699 28
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.2816901408450718 44
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3169014084507058 53
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.3521126760563398 66
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.3521126760563398 81
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.21126760563380387 29
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.3169014084507058 45
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3521126760563398 54
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.38732394366197376 67
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.38732394366197376 82
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.21126760563380387 30
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.3169014084507058 46
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3521126760563398 55
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.38732394366197376 68
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.38732394366197376 83
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a780> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.21126760563380387 31
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.3169014084507058 47
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3521126760563398 56
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.38732394366197376 69
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.38732394366197376 84
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.21126760563380387 32
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.3169014084507058 48
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.3521126760563398 57
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.38732394366197376 70
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.38732394366197376 85
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.24647887323943785 33
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.3521126760563398 49
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.38732394366197376 58
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.42253521126760774 71
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.42253521126760774 86
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be47891d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.2816901408450718 34
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.38732394366197376 50
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.42253521126760774 59
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.4577464788732417 72
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.4577464788732417 87
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.2816901408450718 35
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.38732394366197376 51
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.42253521126760774 60
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.4577464788732417 73
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.4577464788732417 88
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.2816901408450718 36
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.38732394366197376 52
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.42253521126760774 61
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.4577464788732417 74
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.4577464788732417 89
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a780> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.3169014084507058 37
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.42253521126760774 53
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.4577464788732417 62
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.4929577464788757 75
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.4929577464788757 90
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.3169014084507058 38
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.42253521126760774 54
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.4577464788732417 63
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.4929577464788757 76
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.4929577464788757 91
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.3169014084507058 39
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.42253521126760774 55
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.4577464788732417 64
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.4929577464788757 77
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.4929577464788757 92
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d0b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.3521126760563398 40
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.4577464788732417 56
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.4929577464788757 65
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.5281690140845097 78
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.5281690140845097 93
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed7b8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.24647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.3169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.3521126760563398 41
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.4577464788732417 57
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.4929577464788757 66
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.5281690140845097 79
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.5281690140845097 94
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4789518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47896a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.3521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.38732394366197376 42
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.4929577464788757 58
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.5281690140845097 67
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.5633802816901436 80
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.5633802816901436 95
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->5->15->8->10->2->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.2816901408450718 20
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.3521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.38732394366197376 43
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.4929577464788757 59
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.5281690140845097 68
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.5633802816901436 81
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.5633802816901436 96
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4790240> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.3169014084507058 21
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.42253521126760774 44
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5281690140845097 60
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.5633802816901436 69
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.5985915492957776 82
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.5985915492957776 97
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.3169014084507058 22
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.42253521126760774 45
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5281690140845097 61
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.5633802816901436 70
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.5985915492957776 83
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.5985915492957776 98
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4790a90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.3521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.42253521126760774 32
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.4577464788732417 46
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5633802816901436 62
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.5985915492957776 71
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.6338028169014116 84
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.6338028169014116 99
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.3521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.42253521126760774 33
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.4577464788732417 47
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5633802816901436 63
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.5985915492957776 72
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.6338028169014116 85
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.6338028169014116 100
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c24691438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.38732394366197376 25
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.4929577464788757 48
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5985915492957776 64
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.6338028169014116 73
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.6690140845070456 86
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.6690140845070456 101
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.38732394366197376 26
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.4929577464788757 49
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5985915492957776 65
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.6338028169014116 74
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.6690140845070456 87
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.6690140845070456 102
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed7b8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.4929577464788757 50
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.5985915492957776 66
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.6338028169014116 75
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.6690140845070456 88
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.6690140845070456 103
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4790518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.4929577464788757 37
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5281690140845097 51
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6338028169014116 67
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.6690140845070456 76
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7042253521126796 89
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7042253521126796 104
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.42253521126760774 29
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5281690140845097 52
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6338028169014116 68
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.6690140845070456 77
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7042253521126796 90
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7042253521126796 105
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.42253521126760774 30
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5281690140845097 53
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6338028169014116 69
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.6690140845070456 78
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7042253521126796 91
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7042253521126796 106
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->5->15->8->10->2->0->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be473d1d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8fd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4577464788732417 31
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5633802816901436 54
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6690140845070456 70
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7042253521126796 79
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7394366197183135 92
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7394366197183135 107
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35f8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.2816901408450718 18
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5281690140845097 41
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5633802816901436 55
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6690140845070456 71
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7042253521126796 80
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7394366197183135 93
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7394366197183135 108
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5281690140845097 42
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5633802816901436 56
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6690140845070456 72
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7042253521126796 81
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7394366197183135 94
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7394366197183135 109
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8fd0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.2816901408450718 20
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5281690140845097 43
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5633802816901436 57
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6690140845070456 73
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7042253521126796 82
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7394366197183135 95
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7394366197183135 110
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5281690140845097 44
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5633802816901436 58
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6690140845070456 74
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7042253521126796 83
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7394366197183135 96
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7394366197183135 111
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5281690140845097 45
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5633802816901436 59
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.6690140845070456 75
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7042253521126796 84
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7394366197183135 97
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7394366197183135 112
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be47edf60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d0b8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4929577464788757 37
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5633802816901436 46
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5985915492957776 60
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.7042253521126796 76
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7394366197183135 85
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7746478873239475 98
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7746478873239475 113
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5633802816901436 47
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5985915492957776 61
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.7042253521126796 77
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7394366197183135 86
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7746478873239475 99
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7746478873239475 114
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5633802816901436 48
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5985915492957776 62
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.7042253521126796 78
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7394366197183135 87
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7746478873239475 100
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7746478873239475 115
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8fd0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c50> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf60> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f0c2464ddd8> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7f0c2472af60> 0.5633802816901436 49
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.5985915492957776 63
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.7042253521126796 79
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f438> 0.7394366197183135 88
backprop <src.mcts.MCTS_Node object at 0x7f0c246913c8> 0.7746478873239475 101
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed780> 0.7746478873239475 116
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->5->15->8->10->2->0->0->2
Best Reward: 0.03521126760563398
iteration: 2
found coverage increase 0.03521126760563398
Current Total Coverage 11.76056338028169
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 11.76056338028169
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 300
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d7f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 11.76056338028169
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4705ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 2
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 3
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 4
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 5
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 6
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 7
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 8
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 9
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 10
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 11
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 12
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 13
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47059b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 14
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47059b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 15
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 16
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 17
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47226a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 18
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 19
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 20
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 21
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705ba8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 22
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 23
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 24
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 25
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 26
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 27
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 28
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 29
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 30
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 31
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 32
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.03521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.03521126760563398 33
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.07042253521126796 19
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.07042253521126796 34
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.07042253521126796 20
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.07042253521126796 35
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.07042253521126796 21
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.07042253521126796 36
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.07042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.07042253521126796 37
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5550> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.10563380281690193 23
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.10563380281690193 38
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.10563380281690193 24
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.10563380281690193 39
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.10563380281690193 25
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.10563380281690193 40
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc550> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 26
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 41
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 27
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 42
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 28
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 43
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc550> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 29
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 44
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 30
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 45
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47336a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 31
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 46
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc550> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 32
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 47
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1408450704225359 33
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1408450704225359 48
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->3->17
Best Reward: 0.03521126760563398
coverage_call_count 400
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1760563380281699 34
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1760563380281699 49
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1408450704225359 17
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1760563380281699 35
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1760563380281699 50
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.1760563380281699 36
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.1760563380281699 51
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1760563380281699 19
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.21126760563380387 37
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.21126760563380387 52
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1760563380281699 20
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.21126760563380387 38
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.21126760563380387 53
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5668> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1760563380281699 21
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.21126760563380387 39
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.21126760563380387 54
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.1760563380281699 22
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.21126760563380387 40
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.21126760563380387 55
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.21126760563380387 23
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.24647887323943785 41
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.24647887323943785 56
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47537b8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 42
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 57
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 43
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 58
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->3->17->7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 44
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 59
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 45
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 60
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 28
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 46
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 61
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 29
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 47
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 62
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.24647887323943785 30
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.2816901408450718 48
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.2816901408450718 63
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4687c88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.2816901408450718 31
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.3169014084507058 49
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.3169014084507058 64
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.3169014084507058 32
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.3521126760563398 50
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.3521126760563398 65
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.3521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.38732394366197376 51
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.38732394366197376 66
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2550> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687358> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.3169014084507058 22
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.42253521126760774 52
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.42253521126760774 67
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.38732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.42253521126760774 53
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.42253521126760774 68
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687358> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.42253521126760774 54
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.42253521126760774 69
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2ef0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcc18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.3521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.42253521126760774 37
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.4577464788732417 55
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.4577464788732417 70
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->3->17->7->4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.38732394366197376 26
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.4577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.4929577464788757 56
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.4929577464788757 71
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47059e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687c88> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.42253521126760774 27
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.5281690140845097 57
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.5281690140845097 72
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46877f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.4577464788732417 28
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.5633802816901436 58
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.5633802816901436 73
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4687080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687da0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.4929577464788757 29
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5633802816901436 41
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.5985915492957776 59
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.5985915492957776 74
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4687438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ba8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5281690140845097 30
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5985915492957776 42
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.6338028169014116 60
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.6338028169014116 75
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5281690140845097 31
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5985915492957776 43
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.6338028169014116 61
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.6338028169014116 76
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82b0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.2816901408450718 11
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5281690140845097 32
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5985915492957776 44
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.6338028169014116 62
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.6338028169014116 77
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.2816901408450718 12
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5281690140845097 33
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5985915492957776 45
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.6338028169014116 63
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.6338028169014116 78
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.2816901408450718 13
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.38732394366197376 23
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5281690140845097 34
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.5985915492957776 46
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.6338028169014116 64
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.6338028169014116 79
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.3169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5633802816901436 35
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.6338028169014116 47
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.6690140845070456 65
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.6690140845070456 80
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7f60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.4577464788732417 25
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5985915492957776 36
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.6690140845070456 48
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.7042253521126796 66
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.7042253521126796 81
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.4577464788732417 26
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.5985915492957776 37
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.6690140845070456 49
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.7042253521126796 67
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.7042253521126796 82
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2b00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.38732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.4929577464788757 27
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.6338028169014116 38
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.7042253521126796 50
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.7394366197183135 68
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.7394366197183135 83
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->3->17->7->4->0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.42253521126760774 18
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.5281690140845097 28
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.6690140845070456 39
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.7394366197183135 51
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.7746478873239475 69
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.7746478873239475 84
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.4577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.5633802816901436 29
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.7042253521126796 40
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.7746478873239475 52
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.8098591549295815 70
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.8098591549295815 85
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be463f198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.5985915492957776 30
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.7394366197183135 41
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.8098591549295815 53
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.8450704225352155 71
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.8450704225352155 86
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.4929577464788757 21
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.5985915492957776 31
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.7394366197183135 42
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.8098591549295815 54
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.8450704225352155 72
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.8450704225352155 87
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be463f898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530f0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.5281690140845097 22
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.6338028169014116 32
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.7746478873239475 43
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.8450704225352155 55
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.8802816901408494 73
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.8802816901408494 88
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687da0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.21126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.5281690140845097 23
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.6338028169014116 33
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.7746478873239475 44
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.8450704225352155 56
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.8802816901408494 74
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.8802816901408494 89
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4653358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.24647887323943785 10
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.5633802816901436 24
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.6690140845070456 34
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.8098591549295815 45
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.8802816901408494 57
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.9154929577464834 75
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.9154929577464834 90
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.24647887323943785 11
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.5633802816901436 25
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.6690140845070456 35
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.8098591549295815 46
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.8802816901408494 58
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.9154929577464834 76
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.9154929577464834 91
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6338028169014116 26
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7394366197183135 36
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.8802816901408494 47
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9507042253521174 59
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.9859154929577514 77
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.9859154929577514 92
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6338028169014116 27
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7394366197183135 37
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.8802816901408494 48
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9507042253521174 60
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.9859154929577514 78
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.9859154929577514 93
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653198> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6338028169014116 28
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7394366197183135 38
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.8802816901408494 49
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9507042253521174 61
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.9859154929577514 79
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 0.9859154929577514 94
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be463f940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6690140845070456 29
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7746478873239475 39
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9154929577464834 50
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9859154929577514 62
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0211267605633854 80
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0211267605633854 95
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6690140845070456 30
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7746478873239475 40
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9154929577464834 51
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9859154929577514 63
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0211267605633854 81
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0211267605633854 96
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #6
root->3->17->7->4->0->0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6690140845070456 31
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7746478873239475 41
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9154929577464834 52
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9859154929577514 64
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0211267605633854 82
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0211267605633854 97
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.6690140845070456 32
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.7746478873239475 42
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9154929577464834 53
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 0.9859154929577514 65
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0211267605633854 83
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0211267605633854 98
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
coverage_call_count 500
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4669940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7042253521126796 33
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8098591549295815 43
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9507042253521174 54
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0211267605633854 66
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0563380281690193 84
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0563380281690193 99
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7042253521126796 34
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8098591549295815 44
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9507042253521174 55
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0211267605633854 67
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0563380281690193 85
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0563380281690193 100
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7042253521126796 35
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8098591549295815 45
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9507042253521174 56
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0211267605633854 68
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0563380281690193 86
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0563380281690193 101
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be463f080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.42253521126760774 22
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7394366197183135 36
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8450704225352155 46
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.9859154929577514 57
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0563380281690193 69
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.0915492957746533 87
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.0915492957746533 102
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7e10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.4577464788732417 23
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7746478873239475 37
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8802816901408494 47
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.0211267605633854 58
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0915492957746533 70
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.1267605633802873 88
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.1267605633802873 103
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7e10> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.4577464788732417 24
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7746478873239475 38
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8802816901408494 48
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.0211267605633854 59
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0915492957746533 71
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.1267605633802873 89
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.1267605633802873 104
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.4577464788732417 25
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.7746478873239475 39
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.8802816901408494 49
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.0211267605633854 60
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.0915492957746533 72
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.1267605633802873 90
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.1267605633802873 105
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.4929577464788757 26
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.8098591549295815 40
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.9154929577464834 50
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.0563380281690193 61
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.1267605633802873 73
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.1619718309859213 91
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.1619718309859213 106
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #7
root->3->17->7->4->0->0->1
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4677b70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.5281690140845097 27
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.8450704225352155 41
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 0.9507042253521174 51
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.0915492957746533 62
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.1619718309859213 74
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.1971830985915553 92
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.1971830985915553 107
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f0bac1765f8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677940> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.5985915492957776 28
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.9154929577464834 42
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.0211267605633854 52
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.1619718309859213 63
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.2323943661971892 75
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.2676056338028232 93
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.2676056338028232 108
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f0bac183128> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176da0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.42253521126760774 17
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.6690140845070456 29
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.9859154929577514 43
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.0915492957746533 53
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.2323943661971892 64
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.3028169014084572 76
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.3380281690140912 94
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.3380281690140912 109
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677940> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.42253521126760774 18
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.6690140845070456 30
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.9859154929577514 44
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.0915492957746533 54
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.2323943661971892 65
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.3028169014084572 77
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.3380281690140912 95
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.3380281690140912 110
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677940> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.42253521126760774 19
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.6690140845070456 31
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.9859154929577514 45
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.0915492957746533 55
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.2323943661971892 66
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.3028169014084572 78
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.3380281690140912 96
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.3380281690140912 111
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176da0> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.3521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.7394366197183135 32
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 1.0563380281690193 46
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.1619718309859213 56
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.3028169014084572 67
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.3732394366197251 79
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.4084507042253591 97
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.4084507042253591 112
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f0be4669b00> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46772e8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.42253521126760774 11
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.5633802816901436 21
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.8098591549295815 33
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 1.1267605633802873 47
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.2323943661971892 57
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.3732394366197251 68
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.443661971830993 80
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.478873239436627 98
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.478873239436627 113
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0be4773748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.4577464788732417 12
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc50> 0.5985915492957776 22
backprop <src.mcts.MCTS_Node object at 0x7f0be4687be0> 0.8450704225352155 34
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 1.1619718309859213 48
backprop <src.mcts.MCTS_Node object at 0x7f0be4733e48> 1.2676056338028232 58
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 1.4084507042253591 69
backprop <src.mcts.MCTS_Node object at 0x7f0be473dd30> 1.478873239436627 81
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 1.514084507042261 99
backprop <src.mcts.MCTS_Node object at 0x7f0be47056a0> 1.514084507042261 114
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #8
root->3->17->7->4->0->0->1->18
Best Reward: 0.07042253521126796
iteration: 5
found coverage increase 0.07042253521126796
Current Total Coverage 11.830985915492958
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c559a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4419fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca116f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 11.830985915492958
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 11.830985915492958
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 600
Completed Iteration #4
Best Reward: 0
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be46dca20> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0352112676056322 4
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0352112676056322 5
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0352112676056322 6
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0352112676056322 7
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0352112676056322 8
Completed Iteration #9
Best Reward: 0.0352112676056322
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0352112676056322 9
Completed Iteration #11
Best Reward: 0.0352112676056322
Completed Iteration #12
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be4653908> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 10
Completed Iteration #13
Best Reward: 0.0352112676056322
Completed Iteration #14
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 11
Completed Iteration #15
Best Reward: 0.0352112676056322
Completed Iteration #16
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 12
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 13
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 14
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 15
Completed Iteration #21
Best Reward: 0.0352112676056322
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 16
Completed Iteration #23
Best Reward: 0.0352112676056322
Completed Iteration #24
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.0704225352112644 17
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0352112676056322
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.14084507042253058 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.14084507042253058 18
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be473d588> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790358> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dca20> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.17605633802816278 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.17605633802816278 19
Completed Iteration #1
Best Reward: 0.07042253521126618
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.17605633802816278 6
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.17605633802816278 20
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47b80b8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.21126760563379499 7
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.21126760563379499 21
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.21126760563379499 8
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.21126760563379499 22
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.21126760563379499 9
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.21126760563379499 23
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.21126760563379499 10
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.21126760563379499 24
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.21126760563379499 11
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.21126760563379499 25
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5898> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.28169014084506117 12
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.28169014084506117 26
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c44025b70> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.17605633802816456 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.31690140845069337 13
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.31690140845069337 27
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2588> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.24647887323943074 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.38732394366195955 14
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.38732394366195955 28
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be473d048> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.3169014084506969 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.4577464788732257 15
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.4577464788732257 29
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d048> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.3169014084506969 7
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.4577464788732257 16
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.4577464788732257 30
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8c18> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8550> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.3521126760563291 8
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.4929577464788579 17
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.4929577464788579 31
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b56a0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.3873239436619613 9
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.5281690140844901 18
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.5281690140844901 32
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d54e0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.4225352112675935 10
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.5633802816901223 19
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.5633802816901223 33
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be4653550> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.17605633802816456 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.4929577464788597 11
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.6338028169013885 20
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.6338028169013885 34
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #2
root->1->19
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed438> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.21126760563379676 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.5281690140844919 12
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.6690140845070207 21
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.6690140845070207 35
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed2e8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.24647887323942896 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.5633802816901241 13
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.7042253521126529 22
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.7042253521126529 36
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.24647887323942896 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.5633802816901241 14
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.7042253521126529 23
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.7042253521126529 37
Completed Iteration #3
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.31690140845069514 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.6338028169013903 15
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.7746478873239191 24
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.7746478873239191 38
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be4789eb8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed630> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5898> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.35211267605632735 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.6690140845070225 16
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.8098591549295513 25
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.8098591549295513 39
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.35211267605632735 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.6690140845070225 17
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.8098591549295513 26
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.8098591549295513 40
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b70> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.4225352112675935 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.7394366197182887 18
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.8802816901408175 27
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.8802816901408175 41
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.4929577464788597 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.8098591549295548 19
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.9507042253520837 28
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.9507042253520837 42
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be4790a90> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.5281690140844919 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.845070422535187 20
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.9859154929577159 29
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.9859154929577159 43
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed2e8> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.5281690140844919 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.845070422535187 21
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.9859154929577159 30
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 0.9859154929577159 44
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #3
root->1->19->0
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed320> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed358> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.17605633802816456 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.5633802816901241 15
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.8802816901408193 22
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.021126760563348 31
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.021126760563348 45
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be4789898> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789e80> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.24647887323943074 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.6338028169013903 16
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.9507042253520854 23
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.0915492957746142 32
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.0915492957746142 46
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.24647887323943074 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.6338028169013903 17
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.9507042253520854 24
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.0915492957746142 33
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.0915492957746142 47
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.3169014084506969 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.7042253521126565 18
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.0211267605633516 25
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.1619718309858804 34
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.1619718309858804 48
Completed Iteration #6
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed358> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.3521126760563291 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.7394366197182887 19
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.0563380281689838 26
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.1971830985915126 35
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.1971830985915126 49
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
coverage_call_count 700
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5eb8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789e80> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.3873239436619613 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.7746478873239209 20
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.091549295774616 27
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.2323943661971448 36
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.2323943661971448 50
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c50> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5390> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.4577464788732275 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.845070422535187 21
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.1619718309858822 28
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.302816901408411 37
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.302816901408411 51
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba860> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed358> 0.14084507042253058 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.5281690140844937 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.9154929577464532 22
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.2323943661971484 29
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.3732394366196772 38
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.3732394366196772 52
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf28> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e38d0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.5985915492957599 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.9859154929577194 23
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.3028169014084146 30
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.4436619718309434 39
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.4436619718309434 53
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.5985915492957599 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.9859154929577194 24
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.3028169014084146 31
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.4436619718309434 40
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.4436619718309434 54
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5dd8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5390> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.6338028169013921 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.0211267605633516 25
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.3380281690140468 32
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.4788732394365756 41
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.4788732394365756 55
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be4790550> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed2b0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c50> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5390> 0.17605633802816456 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.7042253521126582 15
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.0915492957746178 26
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.408450704225313 33
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.5492957746478417 42
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.5492957746478417 56
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5be0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55f8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.7746478873239244 16
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.161971830985884 27
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.4788732394365791 34
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.619718309859108 43
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.619718309859108 57
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e38d0> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.7746478873239244 17
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.161971830985884 28
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.4788732394365791 35
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.619718309859108 44
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.619718309859108 58
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3400> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789e80> 0.14084507042253058 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.8098591549295566 18
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.1971830985915162 29
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.5140845070422113 36
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.6549295774647401 45
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.6549295774647401 59
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3f98> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.21126760563379854 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.8802816901408228 19
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.2676056338027824 30
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.5845070422534775 37
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.7253521126760063 46
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.7253521126760063 60
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47892b0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5390> 0.21126760563379676 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.915492957746455 20
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.3028169014084146 31
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.6197183098591097 38
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.7605633802816385 47
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.7605633802816385 61
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #4
root->1->19->0->0
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.21126760563379854 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.915492957746455 21
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.3028169014084146 32
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.6197183098591097 39
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.7605633802816385 48
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.7605633802816385 62
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a7b8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.24647887323943074 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.9507042253520872 22
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.3380281690140468 33
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.654929577464742 40
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.7957746478872707 49
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.7957746478872707 63
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c2465af60> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a550> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.3169014084506969 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.0211267605633534 23
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.408450704225313 34
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.725352112676008 41
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.8661971830985369 50
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.8661971830985369 64
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.3169014084506969 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.0211267605633534 24
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.408450704225313 35
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.725352112676008 42
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.8661971830985369 51
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.8661971830985369 65
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2d30> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.3873239436619631 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.0915492957746196 25
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.4788732394365791 36
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.7957746478872743 43
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.936619718309803 52
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.936619718309803 66
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47d50b8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b70> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.4225352112675953 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.1267605633802518 26
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.5140845070422113 37
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.8309859154929065 44
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 1.9718309859154353 53
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 1.9718309859154353 67
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be4789128> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789b00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3f98> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.4577464788732275 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.161971830985884 27
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.5492957746478435 38
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.8661971830985387 45
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.0070422535210675 54
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.0070422535210675 68
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.4577464788732275 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.161971830985884 28
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.5492957746478435 39
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.8661971830985387 46
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.0070422535210675 55
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.0070422535210675 69
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3748> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.4929577464788597 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.1971830985915162 29
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.5845070422534757 40
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.9014084507041709 47
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.0422535211266997 56
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.0422535211266997 70
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.5281690140844919 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.2323943661971484 30
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.619718309859108 41
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.936619718309803 48
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.077464788732332 57
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.077464788732332 71
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #5
root->1->19->0->0->0
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.17605633802816456 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.5633802816901241 15
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.2676056338027806 31
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.6549295774647401 42
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 1.9718309859154353 49
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.112676056337964 58
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.112676056337964 72
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df98> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464deb8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.24647887323943074 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.6338028169013903 16
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.3380281690140468 32
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.7253521126760063 43
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.0422535211267014 50
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.1830985915492302 59
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.1830985915492302 73
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.24647887323943074 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.6338028169013903 17
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.3380281690140468 33
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.7253521126760063 44
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.0422535211267014 51
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.1830985915492302 60
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.1830985915492302 74
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a550> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.24647887323943074 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.6338028169013903 18
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.3380281690140468 34
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.7253521126760063 45
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.0422535211267014 52
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.1830985915492302 61
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.1830985915492302 75
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464deb8> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.10563380281689838 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.10563380281689838 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.24647887323943074 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.6338028169013903 19
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.3380281690140468 35
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.7253521126760063 46
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.0422535211267014 53
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.1830985915492302 62
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.1830985915492302 76
Completed Iteration #5
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.24647887323943074 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.6338028169013903 20
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.3380281690140468 36
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.7253521126760063 47
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.0422535211267014 54
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.1830985915492302 63
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.1830985915492302 77
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5550> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.14084507042253058 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.28169014084506294 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.6690140845070225 21
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.373239436619679 37
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.7605633802816385 48
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.0774647887323336 55
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.2183098591548625 64
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.2183098591548625 78
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0be47bacc0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda20> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.3521126760563291 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.7394366197182887 22
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.4436619718309451 38
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.8309859154929047 49
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.1478873239436 56
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.2887323943661286 65
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.2887323943661286 79
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dcf8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda20> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.3873239436619613 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.7746478873239209 23
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.4788732394365773 39
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.8661971830985369 50
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.183098591549232 57
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.323943661971761 66
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.323943661971761 80
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d4a8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.4225352112675935 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.8098591549295531 24
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.5140845070422095 40
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.901408450704169 51
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.2183098591548642 58
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.359154929577393 67
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.359154929577393 81
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c24640550> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640048> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.17605633802816456 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.21126760563379676 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.4929577464788597 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.8802816901408193 25
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.5845070422534757 41
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.9718309859154353 52
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.2887323943661304 59
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.429577464788659 68
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.429577464788659 82
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.4929577464788597 15
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.8802816901408193 26
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.5845070422534757 42
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 1.9718309859154353 53
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.2887323943661304 60
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.429577464788659 69
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.429577464788659 83
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5f8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a550> 0.10563380281689838 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.5281690140844919 16
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.9154929577464515 27
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.619718309859108 43
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.0070422535210675 54
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.3239436619717626 61
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.4647887323942914 70
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.4647887323942914 84
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.5281690140844919 17
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.9154929577464515 28
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.619718309859108 44
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.0070422535210675 55
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.3239436619717626 62
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.4647887323942914 71
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.4647887323942914 85
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda20> 0.10563380281689838 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.5281690140844919 18
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.9154929577464515 29
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.619718309859108 45
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.0070422535210675 56
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.3239436619717626 63
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.4647887323942914 72
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.4647887323942914 86
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda20> 0.10563380281689838 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.5281690140844919 19
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.9154929577464515 30
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.619718309859108 46
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.0070422535210675 57
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.3239436619717626 64
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.4647887323942914 73
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.4647887323942914 87
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #6
root->1->19->0->0->0->0
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c24640080> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.24647887323942896 7
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.5633802816901241 20
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.9507042253520837 31
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.6549295774647401 47
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.0422535211266997 58
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.359154929577395 65
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.4999999999999236 74
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.4999999999999236 88
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d048> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.31690140845069514 8
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6338028169013903 21
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.0211267605633498 32
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7253521126760063 48
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.112676056337966 59
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.429577464788661 66
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.57042253521119 75
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.57042253521119 89
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d048> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.31690140845069514 9
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6338028169013903 22
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.0211267605633498 33
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7253521126760063 49
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.112676056337966 60
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.429577464788661 67
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.57042253521119 76
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.57042253521119 90
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.31690140845069514 10
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6338028169013903 23
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.0211267605633498 34
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7253521126760063 50
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.112676056337966 61
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.429577464788661 68
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.57042253521119 77
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.57042253521119 91
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d048> 0.07042253521126618 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.31690140845069514 11
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6338028169013903 24
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.0211267605633498 35
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7253521126760063 51
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.112676056337966 62
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.429577464788661 69
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.57042253521119 78
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.57042253521119 92
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.31690140845069514 12
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6338028169013903 25
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.0211267605633498 36
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7253521126760063 52
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.112676056337966 63
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.429577464788661 70
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.57042253521119 79
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.57042253521119 93
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5550> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.31690140845069514 13
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6338028169013903 26
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.0211267605633498 37
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7253521126760063 53
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.112676056337966 64
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.429577464788661 71
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.57042253521119 80
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.57042253521119 94
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c246da8d0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.35211267605632735 14
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.6690140845070225 27
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.056338028168982 38
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.7605633802816385 54
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.147887323943598 65
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.464788732394293 72
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.605633802816822 81
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.605633802816822 95
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c2464db38> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.4225352112675935 15
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.7394366197182887 28
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.1267605633802482 39
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.8309859154929047 55
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.2183098591548642 66
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.5352112676055594 73
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.676056338028088 82
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.676056338028088 96
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c24745748> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d278> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d048> 0.10563380281689838 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.4577464788732257 16
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.7746478873239209 29
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.1619718309858804 40
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.8661971830985369 56
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.2535211267604964 67
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.5704225352111916 74
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.7112676056337204 83
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.7112676056337204 97
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c24640668> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246400b8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464db38> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.4929577464788579 17
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.8098591549295531 30
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.1971830985915126 41
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.901408450704169 57
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.2887323943661286 68
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.6056338028168238 75
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.7464788732393526 84
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.7464788732393526 98
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c246edf28> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.5281690140844901 18
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.8450704225351853 31
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.2323943661971448 42
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.9366197183098013 58
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.323943661971761 69
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.640845070422456 76
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.781690140844985 85
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.781690140844985 99
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed940> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5668> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda20> 0.0352112676056322 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.5633802816901223 19
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.8802816901408175 32
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.267605633802777 43
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 1.9718309859154335 59
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.359154929577393 70
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.676056338028088 77
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.816901408450617 86
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.816901408450617 100
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3fd0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.5985915492957545 20
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.9154929577464497 33
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.3028169014084092 44
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.0070422535210657 60
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.3943661971830252 71
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.7112676056337204 78
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.852112676056249 87
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.852112676056249 101
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #7
root->1->19->0->0->0->0->6
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.17605633802816456 6
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.5985915492957545 21
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.9154929577464497 34
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.3028169014084092 45
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.0070422535210657 61
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.3943661971830252 72
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.7112676056337204 79
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.852112676056249 88
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.852112676056249 102
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640048> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.17605633802816456 7
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.5985915492957545 22
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.9154929577464497 35
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.3028169014084092 46
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.0070422535210657 62
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.3943661971830252 73
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.7112676056337204 80
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.852112676056249 89
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.852112676056249 103
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a978> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b32b0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.24647887323943074 8
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.6690140845070207 23
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 0.9859154929577159 36
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.3732394366196754 47
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.077464788732332 63
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.4647887323942914 74
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.7816901408449866 81
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.9225352112675154 90
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.9225352112675154 104
Completed Iteration #7
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c2464de10> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640048> 0.10563380281689838 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.28169014084506294 9
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.7042253521126529 24
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 1.021126760563348 37
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.4084507042253076 48
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.112676056337964 64
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.4999999999999236 75
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.8169014084506188 82
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.9577464788731476 91
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.9577464788731476 105
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c24640780> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b32b0> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.31690140845069514 10
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.7394366197182851 25
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 1.0563380281689803 38
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.4436619718309398 49
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.1478873239435963 65
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.535211267605556 76
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.852112676056251 83
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.9929577464787798 92
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.9929577464787798 106
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.31690140845069514 11
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.7394366197182851 26
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 1.0563380281689803 39
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.4436619718309398 50
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.1478873239435963 66
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.535211267605556 77
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.852112676056251 84
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 2.9929577464787798 93
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 2.9929577464787798 107
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3ba8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ede48> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.35211267605632735 12
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab38> 0.7746478873239173 27
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3630> 1.0915492957746125 40
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 1.478873239436572 51
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 2.1830985915492285 67
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 2.570422535211188 78
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 2.887323943661883 85
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 3.028169014084412 94
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc860> 3.028169014084412 108
Completed Iteration #13
Best Reward: 0.07042253521126618
coverage_call_count 800
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #8
root->1->19->0->0->0->0->6->3
Best Reward: 0.07042253521126618
iteration: 8
found coverage increase 0.07042253521126618
Current Total Coverage 11.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246910b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246910b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24691080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 11.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c57c1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c5277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c5279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c24691ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 11.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 4
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1833c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 5
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 6
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1833c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 7
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 8
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 9
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 10
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 11
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 12
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1833c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 13
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 14
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 15
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 16
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 17
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 18
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 19
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 20
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 21
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 22
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 23
Completed Iteration #10
Best Reward: 0.03521126760563398
coverage_call_count 900
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 24
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 25
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 26
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 27
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 28
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 29
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 30
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.03521126760563398 31
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.07042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.07042253521126796 32
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.07042253521126796 16
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.07042253521126796 33
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.10563380281690193 34
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac0285f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0286d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1408450704225359 35
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1408450704225359 36
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0286d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1408450704225359 37
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1408450704225359 38
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1408450704225359 39
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1408450704225359 40
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c247df0f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.1760563380281699 41
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043e10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.21126760563380387 25
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.21126760563380387 42
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043e10> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.21126760563380387 26
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.21126760563380387 43
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df0f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.21126760563380387 27
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.21126760563380387 44
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->7->17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.21126760563380387 28
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.21126760563380387 45
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.21126760563380387 29
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.21126760563380387 46
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac036550> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.24647887323943785 30
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.24647887323943785 47
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.24647887323943785 31
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.24647887323943785 48
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.24647887323943785 32
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.24647887323943785 49
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac183a20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183b70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.2816901408450718 33
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.2816901408450718 50
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0c247df6a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.3169014084507058 34
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.3169014084507058 51
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac050eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.3521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.3521126760563398 35
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.3521126760563398 52
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac0506d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 26
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 53
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 37
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 54
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036550> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 28
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 38
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 55
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 39
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 56
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247df0f0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 40
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 57
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->7->17->8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183b70> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 19
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 41
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 58
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.38732394366197376 32
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.38732394366197376 42
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.38732394366197376 59
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac036240> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.42253521126760774 33
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.42253521126760774 43
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.42253521126760774 60
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.42253521126760774 34
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.42253521126760774 44
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.42253521126760774 61
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.4577464788732417 45
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.4577464788732417 62
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.3521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.4929577464788757 36
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.4929577464788757 46
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.4929577464788757 63
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.38732394366197376 25
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5281690140845097 37
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5281690140845097 47
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5281690140845097 64
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.38732394366197376 26
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5281690140845097 38
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5281690140845097 48
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5281690140845097 65
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5281690140845097 39
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5281690140845097 49
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5281690140845097 66
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->7->17->8->2
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5633802816901436 40
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5633802816901436 50
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5633802816901436 67
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f6d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.2816901408450718 14
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.4577464788732417 29
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5985915492957776 41
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5985915492957776 51
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5985915492957776 68
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed860> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.4577464788732417 30
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5985915492957776 42
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5985915492957776 52
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5985915492957776 69
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.21126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.4577464788732417 31
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5985915492957776 43
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5985915492957776 53
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5985915492957776 70
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.5985915492957776 44
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.5985915492957776 54
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.5985915492957776 71
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd00b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.24647887323943785 11
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.4929577464788757 33
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6338028169014116 45
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6338028169014116 55
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6338028169014116 72
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
coverage_call_count 1000
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0bac036cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 12
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 34
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 46
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 56
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 73
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 13
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 35
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 47
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 57
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 74
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->7->17->8->2->2
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 14
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 36
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 48
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 58
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 75
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 37
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 49
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 59
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 76
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 38
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 50
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 60
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 77
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 39
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 51
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 61
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 78
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 18
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 40
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 52
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 62
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 79
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.3521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5281690140845097 41
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.6690140845070456 53
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.6690140845070456 63
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.6690140845070456 80
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedda0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 20
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 42
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 54
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 64
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 81
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->7->17->8->2->2->14
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 21
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 28
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 43
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 55
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 65
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 82
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 22
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 44
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 56
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 66
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 83
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 23
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 45
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 57
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 67
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 84
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 46
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 58
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 68
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 85
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedda0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 32
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 47
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 59
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 69
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 86
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.10563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.38732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5633802816901436 48
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7042253521126796 60
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7042253521126796 70
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7042253521126796 87
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1408450704225359 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.3521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.42253521126760774 34
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.5985915492957776 49
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7394366197183135 61
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7394366197183135 71
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7394366197183135 88
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 28
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 50
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 62
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 72
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 89
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->7->17->8->2->2->14->3
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 51
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 63
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 73
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 90
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 52
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 64
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 74
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 91
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 53
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 65
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 75
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 92
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 32
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 39
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 54
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 66
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 76
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 93
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 40
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 55
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 67
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 77
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 94
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 17
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 41
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 56
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 68
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 78
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 95
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb86d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 42
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 57
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 69
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 79
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 96
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 43
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 58
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 70
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 80
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 97
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 37
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 44
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 59
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 71
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 81
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 98
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.1760563380281699 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.38732394366197376 38
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4577464788732417 45
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6338028169014116 60
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.7746478873239475 72
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.7746478873239475 82
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.7746478873239475 99
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8ef0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1760563380281699 22
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.21126760563380387 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.42253521126760774 39
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4929577464788757 46
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6690140845070456 61
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.8098591549295815 73
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.8098591549295815 83
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.8098591549295815 100
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.07042253521126796 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1760563380281699 23
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.21126760563380387 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.42253521126760774 40
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4929577464788757 47
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6690140845070456 62
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.8098591549295815 74
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.8098591549295815 84
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.8098591549295815 101
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.07042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.21126760563380387 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.42253521126760774 41
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4929577464788757 48
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6690140845070456 63
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.8098591549295815 75
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.8098591549295815 85
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.8098591549295815 102
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.07042253521126796 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d68> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.21126760563380387 32
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49e8> 0.42253521126760774 42
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.4929577464788757 49
backprop <src.mcts.MCTS_Node object at 0x7f0bac036390> 0.6690140845070456 64
backprop <src.mcts.MCTS_Node object at 0x7f0bac183780> 0.8098591549295815 76
backprop <src.mcts.MCTS_Node object at 0x7f0bac183748> 0.8098591549295815 86
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.8098591549295815 103
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->7->17->8->2->2->14->3->2
Best Reward: 0.03521126760563398
iteration: 11
found coverage increase 0.03521126760563398
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72390> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 11.936619718309858
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f192b0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eeccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 11.936619718309858
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edba58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e504a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e502e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e663c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e663c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 1300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e784e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e663c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 11.936619718309858
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e962b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e962b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e962b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 11.936619718309858
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eeca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 11.936619718309858
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.03521126760563398 7
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.03521126760563398 8
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.03521126760563398 9
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.03521126760563398 10
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.03521126760563398 11
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.03521126760563398 12
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.10563380281690371 13
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.10563380281690371 14
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.10563380281690371 15
Completed Iteration #18
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.10563380281690371 16
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba41701d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.1408450704225377 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.1408450704225377 17
Completed Iteration #20
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.1408450704225377 18
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.1408450704225377 19
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41702e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.1408450704225377 20
Completed Iteration #23
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.1408450704225377 21
Completed Iteration #24
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.1408450704225377 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.1408450704225377 22
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #0
root
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.17605633802817167 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.17605633802817167 23
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.17605633802817167 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.17605633802817167 24
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.17605633802817167 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.17605633802817167 25
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41701d0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.17605633802817167 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.17605633802817167 26
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.17605633802817167 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.17605633802817167 27
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.17605633802817167 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.17605633802817167 28
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160470> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.21126760563380564 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.21126760563380564 29
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.21126760563380564 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.21126760563380564 30
Completed Iteration #10
Best Reward: 0.07042253521126973
coverage_call_count 1400
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160748> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.21126760563380564 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.21126760563380564 31
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.21126760563380564 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.21126760563380564 32
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.24647887323943962 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.24647887323943962 33
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.24647887323943962 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.24647887323943962 34
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.24647887323943962 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.24647887323943962 35
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41701d0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.2816901408450736 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.2816901408450736 36
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.2816901408450736 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.2816901408450736 37
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.2816901408450736 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.2816901408450736 38
Completed Iteration #23
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160748> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.2816901408450736 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.2816901408450736 39
Completed Iteration #24
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.2816901408450736 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.2816901408450736 40
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.1408450704225377 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3169014084507076 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3169014084507076 41
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.21126760563380742 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3873239436619773 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3873239436619773 42
Completed Iteration #4
Best Reward: 0.07042253521126973
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Completed Iteration #7
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.21126760563380742 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3873239436619773 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3873239436619773 43
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.21126760563380742 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3873239436619773 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3873239436619773 44
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.21126760563380742 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3873239436619773 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3873239436619773 45
Completed Iteration #15
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.21126760563380742 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3873239436619773 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3873239436619773 46
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.21126760563380742 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.3873239436619773 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.3873239436619773 47
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.2464788732394414 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.4225352112676113 32
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.4225352112676113 48
Completed Iteration #20
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.2464788732394414 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.4225352112676113 33
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.4225352112676113 49
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d198> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.2816901408450754 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.45774647887324527 34
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.45774647887324527 50
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d198> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.2816901408450754 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.45774647887324527 35
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.45774647887324527 51
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d4e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.1408450704225377 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.31690140845070935 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.49295774647887924 36
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.49295774647887924 52
Completed Iteration #0
Best Reward: 0.07042253521126973
Completed Iteration #1
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.1408450704225377 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.31690140845070935 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.49295774647887924 37
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.49295774647887924 53
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.1408450704225377 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.31690140845070935 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.49295774647887924 38
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.49295774647887924 54
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.1408450704225377 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.31690140845070935 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.49295774647887924 39
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.49295774647887924 55
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba417df98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.17605633802817167 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.35211267605634333 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.5281690140845132 40
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.5281690140845132 56
Completed Iteration #7
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba41327f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.21126760563380564 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.3873239436619773 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.5633802816901472 41
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.5633802816901472 57
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132b38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.24647887323943962 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.4225352112676113 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.5985915492957812 42
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.5985915492957812 58
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417df98> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.24647887323943962 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.4225352112676113 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.5985915492957812 43
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.5985915492957812 59
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.2816901408450736 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.45774647887324527 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.6338028169014152 44
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.6338028169014152 60
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.2816901408450736 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.45774647887324527 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.6338028169014152 45
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.6338028169014152 61
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.3169014084507076 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.49295774647887924 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.6690140845070491 46
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.6690140845070491 62
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d4e0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.3169014084507076 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.49295774647887924 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.6690140845070491 47
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.6690140845070491 63
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #3
root->6->19->3
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41328d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.3169014084507076 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.49295774647887924 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.6690140845070491 48
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.6690140845070491 64
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.07042253521126973 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.3169014084507076 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.49295774647887924 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.6690140845070491 49
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.6690140845070491 65
Completed Iteration #1
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d5f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.10563380281690371 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.35211267605634156 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.5281690140845132 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.7042253521126831 50
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.7042253521126831 66
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.10563380281690371 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.35211267605634156 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.5281690140845132 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.7042253521126831 51
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.7042253521126831 67
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.17605633802817344 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.4225352112676113 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.598591549295783 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.7746478873239528 52
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.7746478873239528 68
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ebe0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e9e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.21126760563380742 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.45774647887324527 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.6338028169014169 32
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.8098591549295868 53
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.8098591549295868 69
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e782b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.2464788732394414 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.49295774647887924 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.6690140845070509 33
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.8450704225352208 54
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.8450704225352208 70
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9518> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d208> 0.07042253521126973 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.31690140845071113 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.563380281690149 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.7394366197183206 34
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.9154929577464905 55
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.9154929577464905 71
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.31690140845071113 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.563380281690149 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.7394366197183206 35
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.9154929577464905 56
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.9154929577464905 72
Completed Iteration #21
Best Reward: 0.07042253521126973
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d470> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d208> 0.10563380281690371 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.3521126760563451 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.598591549295783 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.7746478873239546 36
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.9507042253521245 57
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.9507042253521245 73
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #4
root->6->19->3->29
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.3521126760563451 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.598591549295783 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.7746478873239546 37
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.9507042253521245 58
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.9507042253521245 74
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba41321d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.3873239436619791 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.6338028169014169 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.8098591549295886 38
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 0.9859154929577585 59
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.9859154929577585 75
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.1408450704225377 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.42253521126761306 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.6690140845070509 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.8450704225352226 39
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.0211267605633925 60
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.0211267605633925 76
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41321d0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.1408450704225377 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.42253521126761306 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.6690140845070509 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.8450704225352226 40
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.0211267605633925 61
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.0211267605633925 77
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.1408450704225377 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.42253521126761306 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.6690140845070509 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.8450704225352226 41
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.0211267605633925 62
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.0211267605633925 78
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e94a8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.17605633802817167 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.45774647887324704 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.7042253521126849 32
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.8802816901408566 42
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.0563380281690264 63
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.0563380281690264 79
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41321d0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.17605633802817167 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.45774647887324704 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.7042253521126849 33
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.8802816901408566 43
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.0563380281690264 64
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.0563380281690264 80
Completed Iteration #12
Best Reward: 0.07042253521126973
coverage_call_count 1500
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba41013c8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e94a8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.21126760563380564 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.492957746478881 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.7394366197183189 34
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.9154929577464905 44
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.0915492957746604 65
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.0915492957746604 81
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba41018d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.24647887323943962 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.528169014084515 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.7746478873239528 35
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.9507042253521245 45
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.1267605633802944 66
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.1267605633802944 82
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160630> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.2816901408450736 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.563380281690149 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.8098591549295868 36
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.9859154929577585 46
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.1619718309859284 67
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.1619718309859284 83
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #5
root->6->19->3->29->4
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.14084507042253946 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.35211267605634333 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.6338028169014187 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.8802816901408566 37
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.0563380281690282 47
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.232394366197198 68
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.232394366197198 84
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.14084507042253946 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.35211267605634333 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.6338028169014187 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.8802816901408566 38
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.0563380281690282 48
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.232394366197198 69
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.232394366197198 85
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.14084507042253946 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.35211267605634333 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.6338028169014187 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.8802816901408566 39
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.0563380281690282 49
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.232394366197198 70
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.232394366197198 86
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111358> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df60> 0.07042253521126973 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.2112676056338092 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.42253521126761306 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7042253521126884 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9507042253521263 40
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.126760563380298 50
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3028169014084678 71
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3028169014084678 87
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.2112676056338092 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.42253521126761306 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7042253521126884 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9507042253521263 41
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.126760563380298 51
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3028169014084678 72
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3028169014084678 88
Completed Iteration #15
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.2112676056338092 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.42253521126761306 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7042253521126884 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9507042253521263 42
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.126760563380298 52
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3028169014084678 73
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3028169014084678 89
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df60> 0.07042253521126973 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.2112676056338092 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.42253521126761306 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7042253521126884 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9507042253521263 43
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.126760563380298 53
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3028169014084678 74
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3028169014084678 90
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e6d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.24647887323944317 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.45774647887324704 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7394366197183224 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9859154929577603 44
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.161971830985932 54
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3380281690141018 75
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3380281690141018 91
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #6
root->6->19->3->29->4->2
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.07042253521126973 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.24647887323944317 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.45774647887324704 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7394366197183224 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9859154929577603 45
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.161971830985932 55
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3380281690141018 76
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3380281690141018 92
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.07042253521126973 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.24647887323944317 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.45774647887324704 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7394366197183224 32
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9859154929577603 46
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.161971830985932 56
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3380281690141018 77
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3380281690141018 93
Completed Iteration #3
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.07042253521126973 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.24647887323944317 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.45774647887324704 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7394366197183224 33
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9859154929577603 47
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.161971830985932 57
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3380281690141018 78
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3380281690141018 94
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.07042253521126973 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.24647887323944317 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.45774647887324704 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7394366197183224 34
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 0.9859154929577603 48
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.161971830985932 58
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3380281690141018 79
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3380281690141018 95
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.10563380281690371 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.28169014084507715 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.492957746478881 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.7746478873239564 35
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.0211267605633942 49
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.197183098591566 59
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.3732394366197358 80
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.3732394366197358 96
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111c88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.1408450704225377 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.31690140845071113 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.528169014084515 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.8098591549295904 36
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.0563380281690282 50
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.2323943661971999 60
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.4084507042253698 81
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.4084507042253698 97
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0588> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.21126760563380742 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.38732394366198086 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.5985915492957847 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.8802816901408601 37
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.126760563380298 51
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.3028169014084696 61
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.4788732394366395 82
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.4788732394366395 98
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab1d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.2464788732394414 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.42253521126761484 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.6338028169014187 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.9154929577464941 38
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.161971830985932 52
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.3380281690141036 62
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.5140845070422735 83
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.5140845070422735 99
Completed Iteration #12
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.2464788732394414 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.42253521126761484 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.6338028169014187 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.9154929577464941 39
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.161971830985932 53
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.3380281690141036 63
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.5140845070422735 84
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.5140845070422735 100
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6a0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0eb8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.14084507042253946 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.31690140845071113 13
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.4929577464788846 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7042253521126884 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 0.9859154929577638 40
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.2323943661972017 54
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4084507042253733 64
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.5845070422535432 85
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.5845070422535432 101
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.3521126760563451 14
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.5281690140845186 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7394366197183224 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.0211267605633978 41
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.2676056338028356 55
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4436619718310073 65
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.6197183098591772 86
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.6197183098591772 102
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #7
root->6->19->3->29->4->2->8
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.14084507042253946 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.3521126760563451 15
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.5281690140845186 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7394366197183224 32
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.0211267605633978 42
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.2676056338028356 56
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4436619718310073 66
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.6197183098591772 87
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.6197183098591772 103
Completed Iteration #0
Best Reward: 0.07042253521126973
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.14084507042253946 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.3521126760563451 16
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.5281690140845186 24
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7394366197183224 33
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.0211267605633978 43
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.2676056338028356 57
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4436619718310073 67
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.6197183098591772 88
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.6197183098591772 104
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.14084507042253946 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.3521126760563451 17
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.5281690140845186 25
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7394366197183224 34
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.0211267605633978 44
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.2676056338028356 58
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4436619718310073 68
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.6197183098591772 89
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.6197183098591772 105
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c44a8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.17605633802817344 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.3873239436619791 18
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.5633802816901525 26
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7746478873239564 35
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.0563380281690318 45
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.3028169014084696 59
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4788732394366413 69
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.6549295774648112 90
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.6549295774648112 106
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.17605633802817344 8
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.3873239436619791 19
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.5633802816901525 27
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.7746478873239564 36
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.0563380281690318 46
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.3028169014084696 60
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.4788732394366413 70
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.6549295774648112 91
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.6549295774648112 107
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f0ba40619b0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49e8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.24647887323944317 9
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.4577464788732488 20
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.6338028169014223 28
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.8450704225352261 37
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.1267605633803015 47
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.3732394366197394 61
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.549295774647911 71
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.725352112676081 92
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.725352112676081 108
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49e8> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.24647887323944317 10
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.4577464788732488 21
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.6338028169014223 29
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.8450704225352261 38
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.1267605633803015 48
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.3732394366197394 62
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.549295774647911 72
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.725352112676081 93
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.725352112676081 109
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49e8> 0.07042253521126973 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.24647887323944317 11
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.4577464788732488 22
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.6338028169014223 30
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.8450704225352261 39
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.1267605633803015 49
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.3732394366197394 63
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.549295774647911 73
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.725352112676081 94
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.725352112676081 110
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4c18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0eb8> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.28169014084507715 12
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.4929577464788828 23
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e588> 0.6690140845070562 31
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e358> 0.8802816901408601 40
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dbe0> 1.1619718309859355 50
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170400> 1.4084507042253733 64
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 1.584507042253545 74
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160710> 1.7605633802817149 95
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 1.7605633802817149 111
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #8
root->6->19->3->29->4->2->8->29
Best Reward: 0.07042253521126973
iteration: 23
found coverage increase 0.07042253521126973
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419db00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160550> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41704a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 1700
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41704a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607f0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e667b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e667b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e667b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e667b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e506d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e966a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e966a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e966a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e505c0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1900
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6faba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb89e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb80f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb89e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb84e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e788d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0500b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.007042253521128
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c5276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c5277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0280b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0280b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0364a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0280b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0280b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0281d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24745a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247455f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247455f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c24691128> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca116f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c57c48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c55990ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c4b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c4b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c57c23da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c57c23da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c55990f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1837f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246912e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 2300
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246912e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ede48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ede48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1761d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ede48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677400> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1763c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246daeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246da198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46539e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46539e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b78d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46870f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d56a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47baa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4753ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be473d6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47530b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47530b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3f98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4419fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca116f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a22b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a22b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd01d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1837f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1837f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24745748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1830f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24745550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1830f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c4b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c57c48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac183438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246edac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c57c1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6faba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb82e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f527f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f527f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c57c1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f527f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f527f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fa90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6feda58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac043f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eeccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f720f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41602b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41602b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ecdd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e785c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e785c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 3100
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e785c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69eccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba419da20> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 3200
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246404e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dcfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247c2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247c2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247c2f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47909b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba6d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47890b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8198> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4705da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41014e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41014e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47bab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47056d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47bab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41329b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41329b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04a8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba41110b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75daccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75daccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d489b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75daccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75daccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75daccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75daca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be473d9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d355f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d355f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d352b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd7b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35d30> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c584e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c584e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c042b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c042b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48358> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d609e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75daccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e16a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41117b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757caef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdcf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46f82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40aba58> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4653828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4687dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe49b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41012e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40611d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41012e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40611d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46694a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be463f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba69eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba69ec908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba413d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b75c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba413db38> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40616a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40616a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4160f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46dc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4400
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c44025ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba413dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba419d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2472a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4677860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41015f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6eec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e787f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757cac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246da7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac043978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 4500
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0289e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0434a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f4ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0287f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75dacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac028b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4790198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2477f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e66fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f72358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac050278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac028208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40610b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6faba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4c4b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be463fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fabbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac0362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac036128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24691eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46a21d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4687ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac050320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4677c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fd0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47538d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247df780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47538d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be46b79e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40e90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4700
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4705c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c04b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24691240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c049e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c049e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c049e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fe4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4773e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75de02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac0367b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0bac036320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c347f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4733128> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246404a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4653828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246408d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246408d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c4c527cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca116f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47334a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47334a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4705d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4733080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b35c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75cfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b35c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0ba415efd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6edb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c55990ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c24640780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b84e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c55990ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6e50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac028400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac183828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac1831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6ada0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d609b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca11696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d600b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d609b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41322b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2464dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41322b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75deff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47eda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41327f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47895f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9def0> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 5000
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75db8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0bac183828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4111710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c518> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6fedc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c4419fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c587f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c24640198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c246b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba415ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c485c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48780> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba41322b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d60518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75def9b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e486d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e486d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e486d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e486d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f52ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4753da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 5200
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4733b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e960b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e968d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e968d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e277b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6f19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e275c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19b38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e270f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75ce6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e661d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e661d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e661d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0bac1767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c48a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e485f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e52b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749aba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749aba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749abe80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba415e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749abb38> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749bea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 4
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 5
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 6
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 7
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 8
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 9
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 10
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 11
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66860> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749076a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749076a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749076a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e9b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749074e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749074e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4753da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 5500
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b757e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74916978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748dde80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b757e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d48fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5940> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748806a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748807b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748806a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5860> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75d487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748515f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748515f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74907cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74851a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748295f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748295f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748189b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748290f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74818358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749bea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74907cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e27f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74880470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749bea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e96ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e66c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74818278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74861da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74829710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ed68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b748d35c0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b748efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74851cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74836390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74880da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74836630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748d3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74829fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b748a5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74861d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743807b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743807b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b743809b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c247b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743f6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c247b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba417d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74380550> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b743956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b743804a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0be4669908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749162b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749162b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c2465af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba40a0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e3a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74e48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be46699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b749161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b749d4358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74916cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74380da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74e19908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b74e194e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7496edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0c246b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74395780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74395630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ec2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c584e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ba6ebb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be4722518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b7499ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0c2465a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74916198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be4722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 6000
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba41320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74380860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0be47edfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b74efce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b7496e1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c58ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b7496ec50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b74efcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75def588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75defac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75defb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0ba4132208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75deff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75deff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0be47d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75def0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0ca1169da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0b75def3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75c8c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75deff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0b75d0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0b75c6acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0b75c9de10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 12.007042253521128
initial coverage: 11.7254
time passed (minutes): 60.0665
iterations: 198
number of new inputs: 320
final coverage: 12.007
total coverage increase: 0.28169
