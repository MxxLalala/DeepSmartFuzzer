Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='tfc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'tfc'], random_seed=1, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7fa40995bf28>, tc2=<function tc2 at 0x7fa40996d048>, tc3=<function tc3 at 0x7fa40996d158>, tfc_subject_layer=-3, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 370
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f70080> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5be48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70400> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 1 3
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b390> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47908> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 2 4
Completed Iteration #3
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364fcab38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47908> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 3 5
Completed Iteration #4
Best Reward: 1
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f479e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f708d0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 4 6
Completed Iteration #6
Best Reward: 1
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b0f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 5 7
Completed Iteration #9
Best Reward: 1
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b128> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b470> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 9 8
Completed Iteration #10
Best Reward: 4
Completed Iteration #11
Best Reward: 4
Completed Iteration #12
Best Reward: 4
Completed Iteration #13
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b8d0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70b00> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 13 9
Completed Iteration #14
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f47a90> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b2e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 14 10
Completed Iteration #15
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f47d30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b2e8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 15 11
Completed Iteration #16
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bb70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47908> 3 5
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 16 12
Completed Iteration #17
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f47978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b470> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 17 13
Completed Iteration #18
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b7f0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47cc0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 19 14
Completed Iteration #19
Best Reward: 4
Completed Iteration #20
Best Reward: 4
Completed Iteration #21
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b828> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f708d0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 21 15
Completed Iteration #22
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b518> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70b00> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 22 16
Completed Iteration #23
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bda0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47908> 4 6
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 23 17
Completed Iteration #24
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47908> 5 7
backprop <src.mcts.MCTS_Node object at 0x7fa3846440b8> 24 18
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 0
found coverage increase 4
Current Total Coverage 374
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70a90> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70978> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 2 2
Completed Iteration #0
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09cf8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70978> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 4 3
Completed Iteration #1
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bbe0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21518> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 7 4
Completed Iteration #2
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b940> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bb38> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 9 5
Completed Iteration #3
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b38> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b7b8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 12 6
Completed Iteration #4
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09240> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b7b8> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 15 7
Completed Iteration #5
Best Reward: 3
Completed Iteration #6
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364fca048> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f477b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 17 8
Completed Iteration #7
Best Reward: 3
Completed Iteration #8
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f097f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09278> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 18 9
Completed Iteration #9
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f47c88> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21518> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 22 10
Completed Iteration #10
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f093c8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21518> 10 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 25 11
Completed Iteration #11
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70eb8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21518> 13 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 28 12
Completed Iteration #12
Best Reward: 4
Completed Iteration #13
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70c50> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f475f8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 31 13
Completed Iteration #14
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f094e0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bb38> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 33 14
Completed Iteration #15
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f099b0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bb38> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 35 15
Completed Iteration #16
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364fca5c0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70978> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 37 16
Completed Iteration #17
Best Reward: 4
Completed Iteration #18
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364fcae48> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f477b8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 39 17
Completed Iteration #19
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364fca080> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f477b8> 7 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 42 18
Completed Iteration #20
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f47780> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21208> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 45 19
Completed Iteration #21
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b198> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21518> 16 6
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 48 20
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f09828> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09278> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 49 21
Completed Iteration #24
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70748> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b7b8> 10 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 53 22
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 1
found coverage increase 4
Current Total Coverage 378
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f702b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca4a8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 2
Completed Iteration #1
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f70710> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70f60> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bc88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70f60> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 4
Completed Iteration #4
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bcc0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 5
Completed Iteration #5
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f09e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaac8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 6
Completed Iteration #6
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21470> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca128> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa4241d92e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca240> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 8
Completed Iteration #9
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f09be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 9
Completed Iteration #10
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f70ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca4a8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 10
Completed Iteration #11
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5ba20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaac8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f095c0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca240> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 12
Completed Iteration #14
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21908> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca128> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 0 13
Completed Iteration #15
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca128> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 1 14
Completed Iteration #16
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21cc0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09208> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 1 15
Completed Iteration #17
Best Reward: 1
Completed Iteration #18
Best Reward: 1
Completed Iteration #19
Best Reward: 1
Completed Iteration #20
Best Reward: 1
Completed Iteration #21
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ecac88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca128> 1 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 1 16
Completed Iteration #22
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09208> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 1 17
Completed Iteration #23
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bac8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09048> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 1 18
Completed Iteration #24
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f09f60> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca4a8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 1 19
Completed Iteration #25
Best Reward: 1
Completed MCTS Level/Depth: #0
root
Best Reward: 1
No reward increase. Abort.
iteration: 2
found coverage increase 1
Current Total Coverage 379
Completed Iteration #0
Best Reward: 0
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bf60> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70dd8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 2 2
Completed Iteration #1
Best Reward: 2
Completed Iteration #2
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cf8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 2 3
Completed Iteration #3
Best Reward: 2
Completed Iteration #4
Best Reward: 2
Completed Iteration #5
Best Reward: 2
Reward: 7
backprop <src.mcts.MCTS_Node object at 0x7fa364f217b8> 7 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee19e8> 7 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 9 4
Completed Iteration #6
Best Reward: 7
Completed Iteration #7
Best Reward: 7
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70e10> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee19e8> 10 3
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 12 5
Completed Iteration #8
Best Reward: 7
Completed Iteration #9
Best Reward: 7
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5be10> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f700b8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 14 6
Completed Iteration #10
Best Reward: 7
Completed Iteration #11
Best Reward: 7
Completed Iteration #12
Best Reward: 7
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca550> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca4e0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 16 7
Completed Iteration #13
Best Reward: 7
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f478d0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee19e8> 14 4
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 20 8
Completed Iteration #14
Best Reward: 7
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1ba8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca940> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 24 9
Completed Iteration #15
Best Reward: 7
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee15f8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee19e8> 18 5
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 28 10
Completed Iteration #16
Best Reward: 7
Completed Iteration #17
Best Reward: 7
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee13c8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca940> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 31 11
Completed Iteration #18
Best Reward: 7
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaf28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cf8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 31 12
Completed Iteration #19
Best Reward: 7
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364eca668> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1748> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 32 13
Completed Iteration #20
Best Reward: 7
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364eca5c0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f700b8> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 36 14
Completed Iteration #21
Best Reward: 7
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b710> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca4e0> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 40 15
Completed Iteration #22
Best Reward: 7
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1fd0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba5c0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 44 16
Completed Iteration #23
Best Reward: 7
coverage_call_count 100
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee17b8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cf8> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 48 17
Completed Iteration #24
Best Reward: 7
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09908> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f700b8> 9 4
backprop <src.mcts.MCTS_Node object at 0x7fa364eca588> 51 18
Completed Iteration #25
Best Reward: 7
Completed MCTS Level/Depth: #0
root
Best Reward: 7
No reward increase. Abort.
iteration: 3
found coverage increase 7
Current Total Coverage 386
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecad30> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a748> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 2 2
Completed Iteration #2
Best Reward: 2
Completed Iteration #3
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f216d8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ab00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 3 3
Completed Iteration #4
Best Reward: 2
Completed Iteration #5
Best Reward: 2
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ebae80> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 7 4
Completed Iteration #6
Best Reward: 4
Completed Iteration #7
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f218d0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 8 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 11 5
Completed Iteration #8
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ecae48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1b38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 12 6
Completed Iteration #9
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba6a0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca860> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 14 7
Completed Iteration #10
Best Reward: 4
Completed Iteration #11
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e48> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca630> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 17 8
Completed Iteration #12
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ebaa58> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a588> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 18 9
Completed Iteration #13
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ebab70> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b6d8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f218d0> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 11 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 21 10
Completed Iteration #14
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364eca0b8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 22 11
Completed Iteration #15
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21710> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a5c0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 24 12
Completed Iteration #16
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ac88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1b38> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 25 13
Completed Iteration #17
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a8d0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a940> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 28 14
Completed Iteration #18
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ad30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca860> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 29 15
Completed Iteration #19
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ebaa20> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a748> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 30 16
Completed Iteration #20
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bc88> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a748> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 33 17
Completed Iteration #21
Best Reward: 4
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Completed Iteration #24
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a6d8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 14 5
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10b8> 36 18
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 4
found coverage increase 4
Current Total Coverage 390
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ee10f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecabe0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f70940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bd30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 1 3
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b898> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba390> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 2 4
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b828> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9beb8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 3 5
Completed Iteration #3
Best Reward: 1
Completed Iteration #4
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cc0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1da0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 4 6
Completed Iteration #5
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bdd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1da0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 5 7
Completed Iteration #6
Best Reward: 1
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a898> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9beb8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 5 8
Completed Iteration #9
Best Reward: 1
Completed Iteration #10
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364eca748> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a7b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 5 9
Completed Iteration #11
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364eba3c8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bd30> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 6 10
Completed Iteration #12
Best Reward: 1
Completed Iteration #13
Best Reward: 1
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a0b8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50cc0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 9 11
Completed Iteration #14
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ae80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecabe0> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 10 12
Completed Iteration #15
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bc50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba390> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 11 13
Completed Iteration #16
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21400> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1da0> 3 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 12 14
Completed Iteration #17
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364eba630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1da0> 4 5
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 13 15
Completed Iteration #18
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a710> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a7b8> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 14 16
Completed Iteration #19
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21278> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50cc0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 14 17
Completed Iteration #20
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50cc0> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 15 18
Completed Iteration #21
Best Reward: 3
Completed Iteration #22
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8aac8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9beb8> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b978> 15 19
Completed Iteration #23
Best Reward: 3
Completed Iteration #24
Best Reward: 3
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 5
found coverage increase 3
Current Total Coverage 393
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e50f60> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54470> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e50c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e546a0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 1 3
Completed Iteration #1
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ebae10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54cc0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 2 4
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1080> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba860> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 3 5
Completed Iteration #3
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54cc0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 4 6
Completed Iteration #4
Best Reward: 1
Completed Iteration #5
Best Reward: 1
Completed Iteration #6
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21b00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e546a0> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 4 7
Completed Iteration #7
Best Reward: 1
Completed Iteration #8
Best Reward: 1
Reward: 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f21da0> 5 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400526d8> 5 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 9 8
Completed Iteration #9
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e9be80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 10 9
Completed Iteration #10
Best Reward: 5
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e544a8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bbe0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 10 10
Completed Iteration #11
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f219e8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba860> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 12 11
Completed Iteration #12
Best Reward: 5
Completed Iteration #13
Best Reward: 5
Completed Iteration #14
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e50470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 13 12
Completed Iteration #15
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54048> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bbe0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 15 13
Completed Iteration #16
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052c18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54e10> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 16 14
Completed Iteration #17
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ebac18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bbe0> 3 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 17 15
Completed Iteration #18
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052b00> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bbe0> 4 5
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 18 16
Completed Iteration #19
Best Reward: 5
Completed Iteration #20
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052358> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400526d8> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 19 17
Completed Iteration #21
Best Reward: 5
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e50748> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba860> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 22 18
Completed Iteration #22
Best Reward: 5
Completed Iteration #23
Best Reward: 5
Completed Iteration #24
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052dd8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e546a0> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e54550> 23 19
Completed Iteration #25
Best Reward: 5
Completed MCTS Level/Depth: #0
root
Best Reward: 5
No reward increase. Abort.
iteration: 6
found coverage increase 5
Current Total Coverage 398
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e54160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a6a0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ebada0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 1 3
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a2e8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54588> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 3 4
Completed Iteration #4
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e54c50> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8add8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 3 5
Completed Iteration #5
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e54940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ebada0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 6
Completed Iteration #6
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e54c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54f98> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 7
Completed Iteration #7
Best Reward: 2
Completed Iteration #8
Best Reward: 2
Completed Iteration #9
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e50ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8add8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 8
Completed Iteration #10
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e50860> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8add8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 9
Completed Iteration #11
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400529e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54f98> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 10
Completed Iteration #12
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e9be10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ebada0> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 11
Completed Iteration #13
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052550> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bb70> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 12
Completed Iteration #14
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b208> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ebada0> 2 5
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 13
Completed Iteration #15
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a518> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50978> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 14
Completed Iteration #16
Best Reward: 2
coverage_call_count 200
Completed Iteration #17
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e54eb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000f518> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 15
Completed Iteration #18
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e54630> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000f6d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 16
Completed Iteration #19
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052d30> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54320> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 17
Completed Iteration #20
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340075da0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ebada0> 2 6
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 18
Completed Iteration #21
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400757f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bb70> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 19
Completed Iteration #22
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340075d68> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000f518> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 20
Completed Iteration #23
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340075e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54588> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 21
Completed Iteration #24
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400526a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000f6d8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e542b0> 4 22
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 7
found coverage increase 2
Current Total Coverage 400
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400750f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052fd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052668> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50fd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 0 3
Completed Iteration #1
Best Reward: 0
Reward: 5
backprop <src.mcts.MCTS_Node object at 0x7fa340052780> 5 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052978> 5 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 5 4
Completed Iteration #2
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54fd0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052860> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 7 5
Completed Iteration #3
Best Reward: 5
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa340052c88> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50d30> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 10 6
Completed Iteration #4
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa3400752e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052400> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 11 7
Completed Iteration #5
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e50390> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50d30> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 12 8
Completed Iteration #6
Best Reward: 5
Completed Iteration #7
Best Reward: 5
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e548d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052860> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 12 9
Completed Iteration #8
Best Reward: 5
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa340075a90> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54a90> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 16 10
Completed Iteration #9
Best Reward: 5
Completed Iteration #10
Best Reward: 5
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e54470> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50d30> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 16 11
Completed Iteration #11
Best Reward: 5
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052978> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 17 12
Completed Iteration #12
Best Reward: 5
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400755f8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50198> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 17 13
Completed Iteration #13
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075668> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54a90> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 19 14
Completed Iteration #14
Best Reward: 5
Completed Iteration #15
Best Reward: 5
Completed Iteration #16
Best Reward: 5
Completed Iteration #17
Best Reward: 5
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e50470> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54a90> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 19 15
Completed Iteration #18
Best Reward: 5
Completed Iteration #19
Best Reward: 5
Completed Iteration #20
Best Reward: 5
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340075be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052860> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 19 16
Completed Iteration #21
Best Reward: 5
Reward: 6
backprop <src.mcts.MCTS_Node object at 0x7fa340075470> 6 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075710> 6 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 25 17
Completed Iteration #22
Best Reward: 6
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400524a8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052fd0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 25 18
Completed Iteration #23
Best Reward: 6
Completed Iteration #24
Best Reward: 6
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340075160> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50198> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e54860> 26 19
Completed Iteration #25
Best Reward: 6
Completed MCTS Level/Depth: #0
root
Best Reward: 6
No reward increase. Abort.
iteration: 8
found coverage increase 6
Current Total Coverage 406
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e54cc0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 1 2
Completed Iteration #0
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e544e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a8d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 1 3
Completed Iteration #1
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a6d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 1 4
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e54908> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e505c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 2 5
Completed Iteration #3
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052630> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e54438> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 2 6
Completed Iteration #4
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8aba8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b550> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 2 7
Completed Iteration #5
Best Reward: 1
Completed Iteration #6
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50b00> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e507f0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 4 8
Completed Iteration #7
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052128> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e507f0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 4 9
Completed Iteration #8
Best Reward: 2
Completed Iteration #9
Best Reward: 2
Completed Iteration #10
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50080> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e507f0> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 6 10
Completed Iteration #11
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e507b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a6d8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 6 11
Completed Iteration #12
Best Reward: 2
Completed Iteration #13
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8afd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075e10> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 7 12
Completed Iteration #14
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50f60> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e507f0> 6 5
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 9 13
Completed Iteration #15
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ebaf60> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b4a8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 10 14
Completed Iteration #16
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052da0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a6d8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 10 15
Completed Iteration #17
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b4a8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 11 16
Completed Iteration #18
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052ef0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052c50> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 13 17
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364eba2b0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052c50> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 13 18
Completed Iteration #21
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b3c8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a8d0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 13 19
Completed Iteration #22
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ebae10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9b4a8> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 13 20
Completed Iteration #23
Best Reward: 2
Completed Iteration #24
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364eba208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340052c50> 3 4
backprop <src.mcts.MCTS_Node object at 0x7fa3400754a8> 14 21
Completed Iteration #25
Best Reward: 2
Completed MCTS Level/Depth: #0
root
Best Reward: 2
No reward increase. Abort.
iteration: 9
found coverage increase 2
Current Total Coverage 408
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e50c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 0 2
Completed Iteration #1
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ab70> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400750b8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 1 3
Completed Iteration #2
Best Reward: 1
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a828> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cc0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 2 4
Completed Iteration #3
Best Reward: 1
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa340075748> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1320> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 6 5
Completed Iteration #4
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e545c0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400520f0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 7 6
Completed Iteration #5
Best Reward: 4
Completed Iteration #6
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa3400759b0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400750b8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 8 7
Completed Iteration #7
Best Reward: 4
Completed Iteration #8
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340052d68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1320> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 9 8
Completed Iteration #9
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bfd0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e547f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 9 9
Completed Iteration #10
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e48> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 10 10
Completed Iteration #11
Best Reward: 4
Completed Iteration #12
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee19b0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eba908> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50c18> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e48> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 13 11
Completed Iteration #13
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075c88> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400520f0> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 15 12
Completed Iteration #14
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee13c8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e547f0> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 16 13
Completed Iteration #15
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1208> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075978> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 17 14
Completed Iteration #16
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1d68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ac18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 18 15
Completed Iteration #17
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ae80> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400520f0> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 19 16
Completed Iteration #18
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ab38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ebad30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a828> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cc0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 20 17
Completed Iteration #19
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ac88> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1cc0> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 20 18
Completed Iteration #20
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8aa90> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3400750b8> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 20 19
Completed Iteration #21
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee12b0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1320> 6 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 21 20
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Completed Iteration #24
Best Reward: 4
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e50cc0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1320> 7 5
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a390> 22 21
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 10
found coverage increase 4
Current Total Coverage 412
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340075a58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 0 2
Completed Iteration #0
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1ac8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075c18> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 1 3
Completed Iteration #1
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1b70> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21cc0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 1 4
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364eba588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21cc0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 1 5
Completed Iteration #4
Best Reward: 1
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364eba9b0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1748> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 4 6
Completed Iteration #5
Best Reward: 3
Completed Iteration #6
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a5c0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca9e8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 6 7
Completed Iteration #7
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bc50> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee16d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 6 8
Completed Iteration #8
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075438> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 6 9
Completed Iteration #9
Best Reward: 3
coverage_call_count 300
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f219b0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa340075c18> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 7 10
Completed Iteration #10
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa4241d92e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21e48> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 7 11
Completed Iteration #11
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364eba2e8> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 8 12
Completed Iteration #12
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364eba438> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 8 13
Completed Iteration #13
Best Reward: 3
Completed Iteration #14
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ebad68> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee16d8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 8 14
Completed Iteration #15
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f216d8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1748> 3 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 8 15
Completed Iteration #16
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364eba400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 1 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 8 16
Completed Iteration #17
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f09b00> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca9e8> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 8 17
Completed Iteration #18
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364e50358> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1748> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 9 18
Completed Iteration #19
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a4e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee16d8> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 9 19
Completed Iteration #20
Best Reward: 3
Completed Iteration #21
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ebac50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1748> 5 5
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 10 20
Completed Iteration #22
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340052a58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba58> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 10 21
Completed Iteration #23
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e9bf28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f21e48> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 10 22
Completed Iteration #24
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa340075198> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1be0> 1 5
backprop <src.mcts.MCTS_Node object at 0x7fa364e9ba20> 10 23
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 11
found coverage increase 3
Current Total Coverage 415
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340075630> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09c88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 1 2
Completed Iteration #0
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3400753c8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09c88> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 1 3
Completed Iteration #1
Best Reward: 1
Completed Iteration #2
Best Reward: 1
Completed Iteration #3
Best Reward: 1
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaef0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f211d0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 3 4
Completed Iteration #4
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364ecae48> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaa20> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 4 5
Completed Iteration #5
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa340075c50> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f099b0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 5 6
Completed Iteration #6
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f09438> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaa20> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 6 7
Completed Iteration #7
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364fcae48> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f211d0> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 8 8
Completed Iteration #8
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaba8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaa20> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 10 9
Completed Iteration #9
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364fcacc0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca470> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 11 10
Completed Iteration #10
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364fcac88> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bb38> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 12 11
Completed Iteration #11
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f21eb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5bb38> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 12 12
Completed Iteration #12
Best Reward: 2
Completed Iteration #13
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21198> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f099b0> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 13 13
Completed Iteration #14
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21748> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b940> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 14 14
Completed Iteration #15
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21fd0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaa20> 5 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 15 15
Completed Iteration #16
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f09e10> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f211d0> 5 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 16 16
Completed Iteration #17
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364f21160> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09c88> 2 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 17 17
Completed Iteration #18
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b6a0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b0b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 17 18
Completed Iteration #19
Best Reward: 2
Completed Iteration #20
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364ecadd8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09c88> 2 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 17 19
Completed Iteration #21
Best Reward: 2
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa364fcad30> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b940> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 18 20
Completed Iteration #22
Best Reward: 2
Completed Iteration #23
Best Reward: 2
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f214e0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b0b8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 18 21
Completed Iteration #24
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09390> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ecaa20> 8 6
backprop <src.mcts.MCTS_Node object at 0x7fa364f09630> 21 22
Completed Iteration #25
Best Reward: 3
Completed MCTS Level/Depth: #0
root
Best Reward: 3
No reward increase. Abort.
iteration: 12
found coverage increase 3
Current Total Coverage 418
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b198> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70ef0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 3 2
Completed Iteration #0
Best Reward: 3
Completed Iteration #1
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364fcac50> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70e48> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 6 3
Completed Iteration #2
Best Reward: 3
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f21dd8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca940> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 9 4
Completed Iteration #3
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f09208> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca940> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 13 5
Completed Iteration #4
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f09940> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09d68> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 17 6
Completed Iteration #5
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364fcaba8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e50ba8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b198> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70ef0> 7 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 21 7
Completed Iteration #6
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364e8a588> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca940> 10 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 24 8
Completed Iteration #7
Best Reward: 4
Reward: 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b668> 5 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09d68> 9 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 29 9
Completed Iteration #8
Best Reward: 5
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa340075208> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70e48> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 32 10
Completed Iteration #9
Best Reward: 5
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa340075390> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f704e0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 35 11
Completed Iteration #10
Best Reward: 5
Completed Iteration #11
Best Reward: 5
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ad68> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09d68> 13 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 39 12
Completed Iteration #12
Best Reward: 5
Completed Iteration #13
Best Reward: 5
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09a58> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70e48> 8 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 41 13
Completed Iteration #14
Best Reward: 5
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1a58> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70e48> 12 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 45 14
Completed Iteration #15
Best Reward: 5
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b710> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702b0> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 48 15
Completed Iteration #16
Best Reward: 5
Completed Iteration #17
Best Reward: 5
Completed Iteration #18
Best Reward: 5
Completed Iteration #19
Best Reward: 5
Completed Iteration #20
Best Reward: 5
Completed Iteration #21
Best Reward: 5
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ee15f8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca940> 14 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 52 16
Completed Iteration #22
Best Reward: 5
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1080> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70390> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 55 17
Completed Iteration #23
Best Reward: 5
Reward: 7
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b70> 7 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70f60> 7 2
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ad68> 11 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f09d68> 20 5
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 62 18
Completed Iteration #24
Best Reward: 7
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f5be48> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f702b0> 6 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f70358> 65 19
Completed Iteration #25
Best Reward: 7
Completed MCTS Level/Depth: #0
root
Best Reward: 7
No reward increase. Abort.
iteration: 13
found coverage increase 7
Current Total Coverage 425
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f476d8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000f630> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 2 2
Completed Iteration #0
Best Reward: 2
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09b70> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fbe0> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 4 3
Completed Iteration #1
Best Reward: 2
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f702e8> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 7 4
Completed Iteration #2
Best Reward: 3
Completed Iteration #3
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09908> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fbe0> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 9 5
Completed Iteration #4
Best Reward: 3
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f479e8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fe10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 9 6
Completed Iteration #5
Best Reward: 3
Completed Iteration #6
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09ba8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b00> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 11 7
Completed Iteration #7
Best Reward: 3
Completed Iteration #8
Best Reward: 3
Completed Iteration #9
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b828> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b00> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 13 8
Completed Iteration #10
Best Reward: 3
Completed Iteration #11
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364eca860> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 5 3
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 15 9
Completed Iteration #12
Best Reward: 3
Completed Iteration #13
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70240> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70860> 7 4
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 17 10
Completed Iteration #14
Best Reward: 3
Completed Iteration #15
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70438> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c42e8> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 19 11
Completed Iteration #16
Best Reward: 3
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f70518> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c42e8> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 21 12
Completed Iteration #17
Best Reward: 3
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa34000ff60> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa34000fe10> 1 3
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 22 13
Completed Iteration #18
Best Reward: 3
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70320> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b00> 8 4
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 26 14
Completed Iteration #19
Best Reward: 4
Completed Iteration #20
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364ecabe0> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b00> 12 5
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 30 15
Completed Iteration #21
Best Reward: 4
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364eca5f8> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b00> 16 6
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 34 16
Completed Iteration #22
Best Reward: 4
Reward: 3
backprop <src.mcts.MCTS_Node object at 0x7fa364f21278> 3 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c42e8> 7 4
backprop <src.mcts.MCTS_Node object at 0x7fa34000fcf8> 37 17
Completed Iteration #23
Best Reward: 4
Completed Iteration #24
Best Reward: 4
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 14
found coverage increase 4
Current Total Coverage 429
Completed Iteration #0
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f47b38> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4c18> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 2
Completed Iteration #1
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b0f0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e10> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 3
Completed Iteration #2
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f47a20> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4be0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 400
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f70128> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4f28> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 5
Completed Iteration #4
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f47ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f707b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b588> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f5b1d0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 7
Completed Iteration #8
Best Reward: 0
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f70400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4c18> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 0 8
Completed Iteration #9
Best Reward: 0
Reward: 1
backprop <src.mcts.MCTS_Node object at 0x7fa3387c42b0> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4d68> 1 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 1 9
Completed Iteration #10
Best Reward: 1
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f47978> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa338750400> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 1 10
Completed Iteration #11
Best Reward: 1
Reward: 4
backprop <src.mcts.MCTS_Node object at 0x7fa364f70978> 4 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4f28> 4 3
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 5 11
Completed Iteration #12
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f09518> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa338750400> 2 3
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 7 12
Completed Iteration #13
Best Reward: 4
Reward: 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4a58> 2 2
backprop <src.mcts.MCTS_Node object at 0x7fa338750400> 4 4
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 13
Completed Iteration #14
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f5ba58> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa338750390> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 14
Completed Iteration #15
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa34000feb8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4c18> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 15
Completed Iteration #16
Best Reward: 4
Completed Iteration #17
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f09ef0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364f707b8> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 16
Completed Iteration #18
Best Reward: 4
Completed Iteration #19
Best Reward: 4
Completed Iteration #20
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364e8ada0> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa364ee1e10> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 17
Completed Iteration #21
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa364f477b8> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4be0> 0 3
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 18
Completed Iteration #22
Best Reward: 4
Completed Iteration #23
Best Reward: 4
Reward: 0
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4160> 0 2
backprop <src.mcts.MCTS_Node object at 0x7fa3387c4be0> 0 4
backprop <src.mcts.MCTS_Node object at 0x7fa3387c47f0> 9 19
Completed Iteration #24
Best Reward: 4
Completed Iteration #25
Best Reward: 4
Completed MCTS Level/Depth: #0
root
Best Reward: 4
No reward increase. Abort.
iteration: 15
found coverage increase 4
Current Total Coverage 433
initial coverage: 370
time passed (minutes): 1.25497
iterations: 16
number of new inputs: 1024
final coverage: 433
total coverage increase: 63
