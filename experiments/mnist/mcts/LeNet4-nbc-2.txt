Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7ff41fafef28>, tc2=<function tc2 at 0x7ff41fb0f048>, tc3=<function tc3 at 0x7ff41fb0f158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 13.3803
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40884a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c908> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40410b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40889b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40889b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40889b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d908> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40280f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40289e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407db70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 12
Completed Iteration #20
Best Reward: 0
coverage_call_count 200
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa58> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847341d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847341d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384734208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846897f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 500
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846895f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ee09c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e374198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e374198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ef28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41043c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41043c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf28> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847706a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4189f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e374240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8198> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384770438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e374160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e374160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e374160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e374160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4189f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40413c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40413c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 800
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ada0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847349e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847087b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847de780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff384651320> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 1000
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41467b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6592e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6592e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1913c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1913c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1550> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 1300
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abc50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1372b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1372b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1372b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb3c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1378d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1378d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1378d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1710> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0945f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b748> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1600
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d410c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dce80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff38477aeb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d419ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40416d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41042e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 1800
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebde8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff38469b978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846896a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1aba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c00f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1910f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b4e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac128> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1c50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1043c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846514a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 22
Completed Iteration #22
Best Reward: 0
coverage_call_count 2200
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ad30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6808d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40418d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f152b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f15c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1379e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f152b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f156a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f156a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f156a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f156a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847085c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e680fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f285c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c104518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c172be0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 2500
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e685f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68b70> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e787b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e787b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a278> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d839b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 2600
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d835f8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e685f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f155f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e685f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e68e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d134e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d134e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d71860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c080> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847dee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3847dee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384734710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 2800
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1375c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1375c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 11
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1518> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d71a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38477a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ee077da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eda0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 13.380281690140844
coverage_call_count 3000
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a67f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d659b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 3100
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c094898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f159e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 3200
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebddd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdf98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384689ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f152e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 3300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f284a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6597f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6593c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e6593c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d832b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef28d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d837b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1914a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d83978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dcafd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338dca1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d212b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d955c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 3500
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d955c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d957f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d213c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d213c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386052b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a9e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5978> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec9e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf427f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf427f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386058d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf532e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf530f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf532e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf532e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf309e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf309e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf98> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeadd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bed50f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386058d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be489b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be489b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 4000
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be560b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eafba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be747b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be186a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be266a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be266a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26048> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be180f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be34940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38469b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38469b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d41a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be264e0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be34a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384708208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c191358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d95240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4028390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e78da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e78dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e78ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f284e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f284e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f28240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d95780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e688d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e688d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339f282b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e68f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3ebd2ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c04fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38477af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c00bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0170b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c017da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e6591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e659f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c191240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e68d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e680828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ebd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33865a390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c04f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d40552b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d41f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847a8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d407d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384770c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846ace80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3846dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e1860> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c137dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c02be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c137f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847deac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33865af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c172c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847deac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff38463c320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d561d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d56be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c017208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339e9c0f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e64bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e659b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4088c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384689eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e680940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4055828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c02bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38463c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d400eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d417c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3847de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d717f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be269e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d65438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be186a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 9
Completed Iteration #14
Best Reward: 0
coverage_call_count 4600
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be26ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be18fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be18a90> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384734710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be74b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be261d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f15e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff43e36eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38463c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d657f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d657f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37e64b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3d4146710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d657f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be26748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beea828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30beea828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30befd128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d40a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 4700
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be34d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf531d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338677d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c15a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338677710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384708080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338677470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386774e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386774e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386774e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38479ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30befd860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eafac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d71be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be18c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339f15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c094e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d650f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c00b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be74438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0947f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0947f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be262b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339f28668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecfb00> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befdcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37e66b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ae80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 4900
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff338650710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf191d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d217f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c0944a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d215f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d217b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d217b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42908> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3847de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d4041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38479a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf197b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d65588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d21e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339eaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30befde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf425c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be95b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386057f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30befdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 13.380281690140844
coverage_call_count 5100
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be956d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e12e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e12e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be956d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff33863d4a8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beeaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338dca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338da3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a400> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae237b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae232b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30beea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338da3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9804e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dcaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae236d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 5400
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bed5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be95198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9794a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9794a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9794a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9794a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a979e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae34828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f35f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30b9e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9797b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff38475b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a980eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 5600
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bdd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a979860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a98cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a90a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aea4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8d00f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a9e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 5700
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a875438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338dca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a979860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a98c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a980160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae4a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a91aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8bda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a95fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a875048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a82da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a81afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a875358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a82d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a84a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a8f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a91ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a84ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f36d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a80c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3e85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a94fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f36d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3a2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3859e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3859e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3f3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3859e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30a385e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a385160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fde80> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d2e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c0d9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf195c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30aebadd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386055c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aebafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff3386055c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33862bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d21fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338605710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5128> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a385780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf42c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae175f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3846512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff384651898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1044e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30a3854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3d403c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfeca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf307b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338650d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf307b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56358> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a3855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf0a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff33863db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf30cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae17780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff384651438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338650898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be56e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30be48eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff30be56470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff37c104208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bf19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33862bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30a9d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae23978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338605ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d217b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30ae5de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30be48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf9c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff30aeba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff33863dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff37c1fd1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff30bfec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff339ef2748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff3386055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bfd5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff339ecf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff30bf199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff338d137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff338d13da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff339ef22e8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 13.380281690140844
initial coverage: 13.3803
time passed (minutes): 60.2263
iterations: 237
number of new inputs: 0
final coverage: 13.3803
total coverage increase: 0
