Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f7ee806af28>, tc2=<function tc2 at 0x7f7ee807b048>, tc3=<function tc3 at 0x7f7ee807b158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 8.58779
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 8.587786259541986
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 8.587786259541986
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40951d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40debe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 8.587786259541986
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8128> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5668> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0190839694656475 9
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5668> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0190839694656475 10
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0190839694656475 11
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0190839694656475 12
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0190839694656475 13
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8f60> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.038167938931295 14
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.038167938931295 15
Completed Iteration #21
Best Reward: 0.0190839694656475
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.038167938931295 16
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.038167938931295 17
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e80> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0572519083969425 18
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0572519083969425 19
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0572519083969425 20
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.038167938931295 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0572519083969425 21
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.038167938931295 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0572519083969425 22
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.038167938931295 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0572519083969425 23
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 24
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 25
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 26
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 27
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 28
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 29
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0572519083969425 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.07633587786259 30
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5ac8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.07633587786259 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0954198473282375 31
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.07633587786259 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0954198473282375 32
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.07633587786259 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0954198473282375 33
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.07633587786259 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.0954198473282375 34
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5cf8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8dd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0954198473282375 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.114503816793885 35
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0954198473282375 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.114503816793885 36
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8dd8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0954198473282375 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.114503816793885 37
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0954198473282375 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.114503816793885 38
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0954198473282375 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.114503816793885 39
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deda0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057d30> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.114503816793885 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.1335877862595325 40
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.09541984732823927 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.15267175572518177 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.17175572519082927 41
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057d30> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.09541984732823927 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.15267175572518177 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.17175572519082927 42
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7ea40664a8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab00> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5630> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057be0> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.13358778625953605 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.19083969465647854 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.20992366412212604 43
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057be0> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.13358778625953605 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.19083969465647854 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.20992366412212604 44
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.13358778625953605 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.19083969465647854 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.20992366412212604 45
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #2
root->0->19
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8358> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.15267175572518354 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.20992366412212604 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.22900763358777354 46
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40579e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.07633587786259177 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.17175572519083104 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.22900763358777354 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.24809160305342104 47
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066dd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.09541984732823927 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.19083969465647854 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.24809160305342104 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.26717557251906854 48
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7f60> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40664e0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.13358778625953605 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.22900763358777532 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.2862595419847178 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.3053435114503653 49
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.13358778625953605 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.22900763358777532 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.2862595419847178 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.3053435114503653 50
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5160> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.15267175572518354 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.24809160305342282 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.3053435114503653 38
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.3244274809160128 51
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d7f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.17175572519083104 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.2671755725190703 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.3244274809160128 39
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.3435114503816603 52
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea401db70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.19083969465647854 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.2862595419847178 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.3435114503816603 40
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.3625954198473078 53
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a518> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.09541984732824105 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.20992366412212604 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3053435114503653 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.3625954198473078 41
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.3816793893129553 54
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d438> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.22900763358777354 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3244274809160128 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.3816793893129553 42
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4007633587786028 55
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea40255c0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.24809160305342104 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3435114503816603 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4007633587786028 43
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4198473282442503 56
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40579e8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.24809160305342104 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3435114503816603 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4007633587786028 44
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4198473282442503 57
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #3
root->0->19->6
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025be0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40256d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.11450381679388855 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.26717557251906854 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3625954198473078 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4198473282442503 45
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4389312977098978 58
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40664e0> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.11450381679388855 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.26717557251906854 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3625954198473078 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4198473282442503 46
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4389312977098978 59
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066470> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a9e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.13358778625953605 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.28625954198471604 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3816793893129553 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4389312977098978 47
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4580152671755453 60
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.13358778625953605 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.28625954198471604 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3816793893129553 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4389312977098978 48
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4580152671755453 61
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.13358778625953605 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.28625954198471604 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.3816793893129553 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4389312977098978 49
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4580152671755453 62
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.05725190839694427 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.17175572519083282 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.3244274809160128 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.4198473282442521 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.4770992366411946 50
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.4961832061068421 63
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025f98> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2099236641221296 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.3625954198473096 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.45801526717554886 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5152671755724914 51
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.5343511450381389 64
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40664e0> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2099236641221296 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.3625954198473096 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.45801526717554886 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5152671755724914 52
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.5343511450381389 65
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bae48> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d710> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2290076335877771 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.3816793893129571 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.47709923664119636 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5343511450381389 53
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.5534351145037864 66
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
coverage_call_count 200
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c64e0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d710> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2480916030534246 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4007633587786046 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.49618320610684385 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5534351145037864 54
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.5725190839694339 67
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #4
root->0->19->6->18
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6908> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.07633587786259177 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2671755725190721 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4198473282442521 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5152671755724914 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5725190839694339 55
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.5916030534350813 68
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a518> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.07633587786259177 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2671755725190721 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4198473282442521 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5152671755724914 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5725190839694339 56
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.5916030534350813 69
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045550> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 38
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 57
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 70
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 39
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 58
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 71
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 40
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 59
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 72
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 41
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 60
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 73
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 42
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 61
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 74
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 43
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 62
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 75
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.09541984732823927 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.2862595419847196 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.4389312977098996 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5343511450381389 44
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.5916030534350813 63
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6106870229007288 76
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #5
root->0->19->6->18->1
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6cf8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095860> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.13358778625953605 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.32442748091601636 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.47709923664119636 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.5725190839694356 45
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.6297709923663781 64
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6488549618320256 77
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3588> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6358> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.11450381679389032 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.17175572519083282 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.36259541984731314 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.5152671755724931 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.6106870229007324 46
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.6679389312976749 65
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6870229007633224 78
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095860> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.11450381679389032 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.17175572519083282 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.36259541984731314 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.5152671755724931 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.6106870229007324 47
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.6679389312976749 66
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.6870229007633224 79
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3be0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3b70> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.1526717557251871 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2099236641221296 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4007633587786099 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.5534351145037899 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.6488549618320292 48
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7061068702289717 67
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.7251908396946192 80
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6358> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.1526717557251871 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2099236641221296 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4007633587786099 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.5534351145037899 38
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.6488549618320292 49
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7061068702289717 68
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.7251908396946192 81
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f98> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3b70> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.1717557251908346 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2290076335877771 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4198473282442574 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.5725190839694374 39
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.6679389312976767 50
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7251908396946192 69
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.7442748091602667 82
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6898> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.1908396946564821 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2480916030534246 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4389312977099049 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.5916030534350849 40
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.6870229007633242 51
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7442748091602667 70
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.7633587786259142 83
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e36d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095860> 0.05725190839694427 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.2099236641221296 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2671755725190721 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4580152671755524 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.6106870229007324 41
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.7061068702289717 52
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7633587786259142 71
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.7824427480915617 84
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.2099236641221296 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2671755725190721 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4580152671755524 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.6106870229007324 42
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.7061068702289717 53
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7633587786259142 72
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.7824427480915617 85
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e32e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6358> 0.05725190839694427 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.2290076335877771 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.2862595419847196 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4770992366411999 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.6297709923663799 43
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.7251908396946192 54
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.7824427480915617 73
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.8015267175572092 86
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f37f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.2480916030534246 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.3053435114503671 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.4961832061068474 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.6488549618320274 44
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.7442748091602667 55
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.8015267175572092 74
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.8206106870228567 87
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.05725190839694605
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.05725190839694605 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.09541984732824105 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.30534351145037064 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.36259541984731314 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.5534351145037935 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.7061068702289734 45
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8015267175572127 56
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.8587786259541552 75
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.8778625954198027 88
Completed Iteration #22
Best Reward: 0.05725190839694605
Completed Iteration #23
Best Reward: 0.05725190839694605
Completed Iteration #24
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba2b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.32442748091601814 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.38167938931296064 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.572519083969441 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.725190839694621 46
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8206106870228602 57
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.8778625954198027 76
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.8969465648854502 89
Completed Iteration #25
Best Reward: 0.05725190839694605
Completed MCTS Level/Depth: #6
root->0->19->6->18->1->14
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3e10> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.11450381679388855 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.34351145038166564 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.40076335877860814 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.5916030534350885 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.7442748091602684 47
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8396946564885077 58
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.8969465648854502 77
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9160305343510977 90
Completed Iteration #0
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.11450381679388855 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.34351145038166564 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.40076335877860814 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.5916030534350885 38
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.7442748091602684 48
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8396946564885077 59
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.8969465648854502 78
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9160305343510977 91
Completed Iteration #1
Best Reward: 0.05725190839694605
Completed Iteration #2
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.11450381679388855 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.34351145038166564 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.40076335877860814 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.5916030534350885 39
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.7442748091602684 49
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8396946564885077 60
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.8969465648854502 79
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9160305343510977 92
Completed Iteration #3
Best Reward: 0.05725190839694605
Completed Iteration #4
Best Reward: 0.05725190839694605
Completed Iteration #5
Best Reward: 0.05725190839694605
Completed Iteration #6
Best Reward: 0.05725190839694605
Completed Iteration #7
Best Reward: 0.05725190839694605
Completed Iteration #8
Best Reward: 0.05725190839694605
Completed Iteration #9
Best Reward: 0.05725190839694605
Completed Iteration #10
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.13358778625953605 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.36259541984731314 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.41984732824425564 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.610687022900736 40
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.763358778625916 50
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8587786259541552 61
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9160305343510977 80
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9351145038167452 93
Completed Iteration #11
Best Reward: 0.05725190839694605
Completed Iteration #12
Best Reward: 0.05725190839694605
Completed Iteration #13
Best Reward: 0.05725190839694605
Completed Iteration #14
Best Reward: 0.05725190839694605
Completed Iteration #15
Best Reward: 0.05725190839694605
Completed Iteration #16
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6fd0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.15267175572518354 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.38167938931296064 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.43893129770990313 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.6297709923663835 41
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.7824427480915634 51
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8778625954198027 62
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9351145038167452 81
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9541984732823927 94
Completed Iteration #17
Best Reward: 0.05725190839694605
Completed Iteration #18
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.15267175572518354 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.38167938931296064 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.43893129770990313 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.6297709923663835 42
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.7824427480915634 52
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8778625954198027 63
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9351145038167452 82
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9541984732823927 95
Completed Iteration #19
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bcc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.17175572519083104 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.40076335877860814 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.45801526717555063 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.648854961832031 43
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.8015267175572109 53
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8969465648854502 64
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9541984732823927 83
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9732824427480402 96
Completed Iteration #20
Best Reward: 0.05725190839694605
Completed Iteration #21
Best Reward: 0.05725190839694605
Completed Iteration #22
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.17175572519083104 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.40076335877860814 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.45801526717555063 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.648854961832031 44
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.8015267175572109 54
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.8969465648854502 65
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9541984732823927 84
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9732824427480402 97
Completed Iteration #23
Best Reward: 0.05725190839694605
Completed Iteration #24
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bdd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.19083969465647854 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.41984732824425564 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.47709923664119813 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.6679389312976785 45
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.8206106870228584 55
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.9160305343510977 66
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9732824427480402 85
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9923664122136877 98
Completed Iteration #25
Best Reward: 0.05725190839694605
Completed MCTS Level/Depth: #7
root->0->19->6->18->1->14->4
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.19083969465647854 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.41984732824425564 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.47709923664119813 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.6679389312976785 46
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.8206106870228584 56
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.9160305343510977 67
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9732824427480402 86
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9923664122136877 99
Completed Iteration #0
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.05725190839694605 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.19083969465647854 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.41984732824425564 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.47709923664119813 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.6679389312976785 47
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.8206106870228584 57
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.9160305343510977 68
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9732824427480402 87
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 0.9923664122136877 100
Completed Iteration #1
Best Reward: 0.05725190839694605
Completed Iteration #2
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7ea400af98> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3198> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.07633587786259355 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.20992366412212604 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.43893129770990313 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.49618320610684563 38
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.687022900763326 48
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.8396946564885059 58
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.9351145038167452 69
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.9923664122136877 88
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.0114503816793352 101
Completed Iteration #3
Best Reward: 0.05725190839694605
Completed Iteration #4
Best Reward: 0.05725190839694605
Completed Iteration #5
Best Reward: 0.05725190839694605
Completed Iteration #6
Best Reward: 0.05725190839694605
Completed Iteration #7
Best Reward: 0.05725190839694605
Completed Iteration #8
Best Reward: 0.05725190839694605
Reward: 0.05725190839694605
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b240> 0.05725190839694605 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b160> 0.05725190839694605 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.1335877862595396 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.2671755725190721 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.4961832061068492 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.5534351145037917 39
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.744274809160272 49
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.896946564885452 59
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 0.9923664122136913 70
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.0496183206106338 89
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.0687022900762813 102
Completed Iteration #9
Best Reward: 0.05725190839694605
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790208> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6cc0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.17175572519083637 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.30534351145036887 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.534351145038146 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.5916030534350885 40
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.7824427480915688 50
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.9351145038167488 60
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.030534351144988 71
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.0877862595419305 90
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.106870229007578 103
Completed Iteration #10
Best Reward: 0.05725190839694605
Completed Iteration #11
Best Reward: 0.05725190839694605
Reward: 0.05725190839694605
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.05725190839694605 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b898> 0.05725190839694605 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.22900763358778242 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.3625954198473149 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.591603053435092 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.6488549618320345 41
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.8396946564885148 51
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 0.9923664122136948 61
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.087786259541934 72
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.1450381679388766 91
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.164122137404524 104
Completed Iteration #12
Best Reward: 0.05725190839694605
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790e80> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b160> 0.09541984732824282 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.2671755725190792 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.4007633587786117 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.6297709923663888 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.6870229007633313 42
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.8778625954198116 52
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.0305343511449916 62
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.1259541984732309 73
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.1832061068701734 92
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.2022900763358209 105
Completed Iteration #13
Best Reward: 0.05725190839694605
Completed Iteration #14
Best Reward: 0.05725190839694605
Completed Iteration #15
Best Reward: 0.05725190839694605
Completed Iteration #16
Best Reward: 0.05725190839694605
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8940> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a84e0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790e80> 0.07633587786259355 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b160> 0.1335877862595396 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.30534351145037597 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.43893129770990846 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.6679389312976856 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.725190839694628 43
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.9160305343511084 53
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.0687022900762884 63
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.1641221374045276 74
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.2213740458014701 93
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.2404580152671176 106
Completed Iteration #17
Best Reward: 0.05725190839694605
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8e80> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3198> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.34351145038167274 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.47709923664120524 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.7061068702289823 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.7633587786259248 44
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.9541984732824051 54
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.1068702290075851 64
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.2022900763358244 75
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.259541984732767 94
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.2786259541984144 107
Completed Iteration #18
Best Reward: 0.05725190839694605
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3eb8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3e48> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.3816793893129695 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.515267175572502 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.7442748091602791 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.8015267175572216 45
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.9923664122137019 55
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.145038167938882 65
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.2404580152671212 76
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.2977099236640637 95
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.3167938931297112 108
Completed Iteration #19
Best Reward: 0.05725190839694605
Reward: 0.05725190839694605
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790be0> 0.05725190839694605 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066be0> 0.05725190839694605 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.43893129770991557 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.5725190839694481 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.8015267175572252 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.8587786259541677 46
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 1.049618320610648 56
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.202290076335828 66
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.2977099236640672 77
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.3549618320610097 96
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.3740458015266572 109
Completed Iteration #20
Best Reward: 0.05725190839694605
Completed Iteration #21
Best Reward: 0.05725190839694605
Completed Iteration #22
Best Reward: 0.05725190839694605
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.43893129770991557 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.5725190839694481 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.8015267175572252 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.8587786259541677 47
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 1.049618320610648 57
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.202290076335828 67
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.2977099236640672 78
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.3549618320610097 97
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.3740458015266572 110
Completed Iteration #23
Best Reward: 0.05725190839694605
Completed Iteration #24
Best Reward: 0.05725190839694605
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b6d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066be0> 0.07633587786259355 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c50> 0.45801526717556307 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3780> 0.5916030534350956 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066320> 0.8206106870228727 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea401de80> 0.8778625954198152 48
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 1.0687022900762955 58
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045390> 1.2213740458014755 68
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057dd8> 1.3167938931297147 79
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 1.3740458015266572 98
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de048> 1.3931297709923047 111
Completed Iteration #25
Best Reward: 0.05725190839694605
Completed MCTS Level/Depth: #8
root->0->19->6->18->1->14->4->2
Best Reward: 0.05725190839694605
iteration: 3
found coverage increase 0.05725190839694605
Current Total Coverage 8.645038167938932
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a85c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 8.645038167938932
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77ba20> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 5
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 6
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 7
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 8
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 9
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 10
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 11
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 12
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 13
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 14
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7902e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0190839694656475 15
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 16
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 17
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 18
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 19
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 20
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 21
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 22
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 23
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.038167938931295 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.038167938931295 24
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbd68> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 25
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 26
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 27
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 28
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 29
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 30
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 31
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7586d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 32
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 33
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 34
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 35
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 36
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #1
root->3
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 37
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 38
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 39
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0190839694656475 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a90> 0.0572519083969425 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a80f0> 0.0572519083969425 40
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #2
root->3->6
Best Reward: 0.0190839694656475
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0.0190839694656475
Current Total Coverage 8.66412213740458
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790240> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.01908396946565105 6
Completed Iteration #8
Best Reward: 0.01908396946565105
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.01908396946565105 7
Completed Iteration #9
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f28> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.0381679389313021 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 8
Completed Iteration #10
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 9
Completed Iteration #11
Best Reward: 0.01908396946565105
Completed Iteration #12
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 10
Completed Iteration #13
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 11
Completed Iteration #14
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 12
Completed Iteration #15
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 13
Completed Iteration #16
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 14
Completed Iteration #17
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 15
Completed Iteration #18
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 16
Completed Iteration #19
Best Reward: 0.01908396946565105
Completed Iteration #20
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0381679389313021 17
Completed Iteration #21
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770400> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.057251908396953155 18
Completed Iteration #22
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790828> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0381679389313021 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0763358778626042 19
Completed Iteration #23
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0763358778626042 20
Completed Iteration #24
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0381679389313021 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0763358778626042 21
Completed Iteration #25
Best Reward: 0.01908396946565105
Completed MCTS Level/Depth: #0
root
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.0381679389313021 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.0763358778626042 22
Completed Iteration #0
Best Reward: 0.01908396946565105
Completed Iteration #1
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb2b0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.057251908396953155 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.09541984732825526 23
Completed Iteration #2
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.057251908396953155 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.09541984732825526 24
Completed Iteration #3
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.057251908396953155 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.09541984732825526 25
Completed Iteration #4
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.057251908396953155 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.09541984732825526 26
Completed Iteration #5
Best Reward: 0.01908396946565105
Completed Iteration #6
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.0763358778626042 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.11450381679390631 27
Completed Iteration #7
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.0763358778626042 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.11450381679390631 28
Completed Iteration #8
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.09541984732825526 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.13358778625955736 29
Completed Iteration #9
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.09541984732825526 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.13358778625955736 30
Completed Iteration #10
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731278> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.11450381679390631 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.1526717557252084 31
Completed Iteration #11
Best Reward: 0.01908396946565105
Completed Iteration #12
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.11450381679390631 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.1526717557252084 32
Completed Iteration #13
Best Reward: 0.01908396946565105
Completed Iteration #14
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.11450381679390631 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.1526717557252084 33
Completed Iteration #15
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.11450381679390631 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.1526717557252084 34
Completed Iteration #16
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8128> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.13358778625955736 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.17175572519085947 35
Completed Iteration #17
Best Reward: 0.01908396946565105
Completed Iteration #18
Best Reward: 0.01908396946565105
Completed Iteration #19
Best Reward: 0.01908396946565105
Completed Iteration #20
Best Reward: 0.01908396946565105
Completed Iteration #21
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.13358778625955736 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.17175572519085947 36
Completed Iteration #22
Best Reward: 0.01908396946565105
Completed Iteration #23
Best Reward: 0.01908396946565105
Completed Iteration #24
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fba90> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.1526717557252084 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.19083969465651052 37
Completed Iteration #25
Best Reward: 0.01908396946565105
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.01908396946565105
Completed Iteration #0
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb908> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb7b8> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.0381679389313021 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.17175572519085947 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.20992366412216157 38
Completed Iteration #1
Best Reward: 0.01908396946565105
Completed Iteration #2
Best Reward: 0.01908396946565105
Completed Iteration #3
Best Reward: 0.01908396946565105
Completed Iteration #4
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb7b8> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.0381679389313021 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.17175572519085947 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.20992366412216157 39
Completed Iteration #5
Best Reward: 0.01908396946565105
Completed Iteration #6
Best Reward: 0.01908396946565105
Completed Iteration #7
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724c88> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724f28> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.057251908396953155 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.19083969465651052 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.22900763358781262 40
Completed Iteration #8
Best Reward: 0.01908396946565105
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7242b0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724630> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.0763358778626042 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.20992366412216157 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.24809160305346367 41
Completed Iteration #9
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.0763358778626042 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.20992366412216157 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.24809160305346367 42
Completed Iteration #10
Best Reward: 0.01908396946565105
Completed Iteration #11
Best Reward: 0.01908396946565105
Completed Iteration #12
Best Reward: 0.01908396946565105
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.0763358778626042 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.20992366412216157 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.24809160305346367 43
Completed Iteration #13
Best Reward: 0.01908396946565105
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.11450381679390276 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.24809160305346012 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.2862595419847622 44
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2710> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbe80> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 45
Completed Iteration #15
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724630> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 46
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 47
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 48
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbe80> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 49
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724f28> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 50
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 51
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #2
root->2->10
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.03816793893129855 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1335877862595538 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.26717557251911117 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3053435114504133 52
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770c88> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.0572519083969496 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.15267175572520486 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.2862595419847622 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3244274809160643 53
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770c88> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.0572519083969496 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.15267175572520486 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.2862595419847622 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3244274809160643 54
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.0572519083969496 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.15267175572520486 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.2862595419847622 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3244274809160643 55
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6791d0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.07633587786260065 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1717557251908559 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.3053435114504133 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3435114503817154 56
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.07633587786260065 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.1717557251908559 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.3053435114504133 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3435114503817154 57
Completed Iteration #24
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698e10> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.0954198473282517 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.19083969465650696 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.3244274809160643 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.36259541984736643 58
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #3
root->2->10->8
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698dd8> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698d30> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.0572519083969496 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.11450381679390276 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.20992366412215802 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.3435114503817154 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3816793893130175 59
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.0572519083969496 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.11450381679390276 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.20992366412215802 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.3435114503817154 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.3816793893130175 60
Completed Iteration #1
Best Reward: 0.03816793893129855
Completed Iteration #2
Best Reward: 0.03816793893129855
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1e10> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.07633587786260065 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1335877862595538 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.22900763358780907 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.36259541984736643 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.40076335877866853 61
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1da0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1780> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.0954198473282517 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.15267175572520486 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.24809160305346012 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.3816793893130175 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.4198473282443196 62
Completed Iteration #7
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0572519083969496 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 63
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 64
Completed Iteration #13
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 65
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0572519083969496 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 66
Completed Iteration #17
Best Reward: 0.03816793893129855
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 67
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1780> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 68
Completed Iteration #23
Best Reward: 0.03816793893129855
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #4
root->2->10->8->19
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0572519083969496 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 69
Completed Iteration #1
Best Reward: 0.03816793893129855
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0572519083969496 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 70
Completed Iteration #3
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0572519083969496 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.13358778625955026 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.1908396946565034 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.28625954198475867 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.41984732824431603 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.45801526717561813 71
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb048> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.07633587786260065 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.1526717557252013 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.20992366412215446 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3053435114504097 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.4389312977099671 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.4770992366412692 72
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7311d0> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.1145038167938992 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.19083969465649986 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.248091603053453 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.34351145038170827 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.47709923664126563 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5152671755725677 73
Completed Iteration #12
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbdd8> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719978> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2390> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.13358778625955026 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.2099236641221509 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.26717557251910407 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3625954198473593 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.4961832061069167 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5343511450382188 74
Completed Iteration #13
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7311d0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.13358778625955026 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.2099236641221509 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.26717557251910407 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3625954198473593 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.4961832061069167 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5343511450382188 75
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.13358778625955026 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.2099236641221509 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.26717557251910407 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3625954198473593 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.4961832061069167 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5343511450382188 76
Completed Iteration #18
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7702b0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.1526717557252013 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.22900763358780196 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.2862595419847551 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3816793893130104 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5152671755725677 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5534351145038698 77
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.1526717557252013 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.22900763358780196 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.2862595419847551 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3816793893130104 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5152671755725677 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5534351145038698 78
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.1526717557252013 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.22900763358780196 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.2862595419847551 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.3816793893130104 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5152671755725677 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5534351145038698 79
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ebe0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb860> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7311d0> 0.0572519083969496 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.17175572519085236 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.248091603053453 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.30534351145040617 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.4007633587786614 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5343511450382188 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5725190839695209 80
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #5
root->2->10->8->19->7
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.17175572519085236 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.248091603053453 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.30534351145040617 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.4007633587786614 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5343511450382188 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5725190839695209 81
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.17175572519085236 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.248091603053453 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.30534351145040617 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.4007633587786614 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5343511450382188 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5725190839695209 82
Completed Iteration #2
Best Reward: 0.03816793893129855
Completed Iteration #3
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.0572519083969496 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.1908396946565034 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.26717557251910407 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.3244274809160572 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.4198473282443125 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5534351145038698 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.5916030534351719 83
Completed Iteration #4
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7455c0> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0572519083969496 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.09541984732824815 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.22900763358780196 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.3053435114504026 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.36259541984735577 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.45801526717561103 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5916030534351684 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.6297709923664705 84
Completed Iteration #5
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.09541984732824815 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.22900763358780196 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.3053435114504026 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.36259541984735577 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.45801526717561103 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.5916030534351684 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.6297709923664705 85
Completed Iteration #6
Best Reward: 0.03816793893129855
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758ba8> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.1335877862595467 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.2671755725191005 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.34351145038170117 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4007633587786543 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.4961832061069096 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.6297709923664669 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.667938931297769 86
Completed Iteration #13
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e860> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb080> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.15267175572519776 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.28625954198475156 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.3625954198473522 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4198473282443054 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5152671755725606 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.648854961832118 69
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.6870229007634201 87
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745390> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.1717557251908488 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.3053435114504026 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.38167938931300327 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4389312977099564 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5343511450382117 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.667938931297769 70
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7061068702290711 88
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.1717557251908488 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.3053435114504026 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.38167938931300327 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4389312977099564 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5343511450382117 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.667938931297769 71
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7061068702290711 89
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0572519083969496 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.1717557251908488 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.3053435114504026 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.38167938931300327 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4389312977099564 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5343511450382117 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.667938931297769 72
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7061068702290711 90
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790208> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.0381679389313021 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.19083969465649986 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.32442748091605367 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4007633587786543 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4580152671756075 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5534351145038627 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.6870229007634201 73
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7251908396947222 91
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #6
root->2->10->8->19->7->0
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Completed Iteration #1
Best Reward: 0.03816793893129855
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0572519083969496 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.19083969465649986 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.32442748091605367 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4007633587786543 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4580152671756075 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5534351145038627 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.6870229007634201 74
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7251908396947222 92
Completed Iteration #3
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7455c0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0572519083969496 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.19083969465649986 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.32442748091605367 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4007633587786543 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4580152671756075 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5534351145038627 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.6870229007634201 75
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7251908396947222 93
Completed Iteration #4
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0572519083969496 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.19083969465649986 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.32442748091605367 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4007633587786543 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4580152671756075 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5534351145038627 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.6870229007634201 76
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7251908396947222 94
Completed Iteration #5
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e908> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280ef0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.0381679389313021 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.07633587786260065 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.2099236641221509 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.3435114503817047 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4198473282443054 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.47709923664125853 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5725190839695138 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7061068702290711 77
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7442748091603733 95
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2da0> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770e80> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b320> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0954198473282517 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.22900763358780196 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.36259541984735577 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4389312977099564 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4961832061069096 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5916030534351648 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7251908396947222 78
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7633587786260243 96
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0954198473282517 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.22900763358780196 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.36259541984735577 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4389312977099564 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4961832061069096 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5916030534351648 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7251908396947222 79
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7633587786260243 97
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0954198473282517 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.22900763358780196 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.36259541984735577 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4389312977099564 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4961832061069096 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5916030534351648 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7251908396947222 80
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7633587786260243 98
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0954198473282517 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.22900763358780196 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.36259541984735577 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4389312977099564 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4961832061069096 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5916030534351648 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7251908396947222 81
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7633587786260243 99
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0954198473282517 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.22900763358780196 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.36259541984735577 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4389312977099564 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4961832061069096 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5916030534351648 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7251908396947222 82
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7633587786260243 100
Completed Iteration #23
Best Reward: 0.03816793893129855
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #7
root->2->10->8->19->7->0->2
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.0381679389313021 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0954198473282517 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.22900763358780196 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.36259541984735577 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4389312977099564 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.4961832061069096 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.5916030534351648 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7251908396947222 83
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7633587786260243 101
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3160> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280ef0> 0.0381679389313021 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.057251908396953155 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.11450381679390276 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.248091603053453 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.3816793893130068 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4580152671756075 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5152671755725606 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6106870229008159 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7442748091603733 84
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.7824427480916754 102
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3a58> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280ef0> 0.057251908396953155 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.0763358778626042 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.1335877862595538 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.26717557251910407 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.4007633587786579 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.47709923664125853 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5343511450382117 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6297709923664669 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7633587786260243 85
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8015267175573264 103
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.0763358778626042 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.1335877862595538 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.26717557251910407 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.4007633587786579 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.47709923664125853 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5343511450382117 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6297709923664669 69
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7633587786260243 86
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8015267175573264 104
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3b00> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745c88> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.09541984732825526 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.15267175572520486 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.2862595419847551 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.4198473282443089 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4961832061069096 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5534351145038627 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.648854961832118 70
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7824427480916754 87
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8206106870229775 105
Completed Iteration #7
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.09541984732825526 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.15267175572520486 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.2862595419847551 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.4198473282443089 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.4961832061069096 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5534351145038627 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.648854961832118 71
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.7824427480916754 88
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8206106870229775 106
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3f98> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745c88> 0.0381679389313021 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.11450381679390631 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.1717557251908559 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.30534351145040617 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.43893129770996 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5152671755725606 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5725190839695138 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.667938931297769 72
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8015267175573264 89
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8396946564886285 107
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280ef0> 0.057251908396953155 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.11450381679390631 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.1717557251908559 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.30534351145040617 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.43893129770996 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5152671755725606 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5725190839695138 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.667938931297769 73
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8015267175573264 90
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8396946564886285 108
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f28> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e898> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.13358778625955736 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.19083969465650696 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.3244274809160572 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.45801526717561103 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5343511450382117 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5916030534351648 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6870229007634201 74
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8206106870229775 91
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8587786259542796 109
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.13358778625955736 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.19083969465650696 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.3244274809160572 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.45801526717561103 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5343511450382117 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5916030534351648 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6870229007634201 75
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8206106870229775 92
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8587786259542796 110
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.13358778625955736 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.19083969465650696 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.3244274809160572 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.45801526717561103 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5343511450382117 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5916030534351648 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6870229007634201 76
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8206106870229775 93
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8587786259542796 111
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.13358778625955736 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.19083969465650696 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.3244274809160572 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.45801526717561103 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5343511450382117 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.5916030534351648 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.6870229007634201 77
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8206106870229775 94
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8587786259542796 112
Completed Iteration #20
Best Reward: 0.03816793893129855
Reward: 0.01908396946565105
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790780> 0.01908396946565105 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280ef0> 0.0763358778626042 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.1526717557252084 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.20992366412215802 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.34351145038170827 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.4770992366412621 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5534351145038627 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.6106870229008159 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.7061068702290711 78
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8396946564886285 95
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8778625954199306 113
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3f98> 0.01908396946565105 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745c88> 0.0381679389313021 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758b38> 0.1526717557252084 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.20992366412215802 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758748> 0.34351145038170827 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.4770992366412621 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2f28> 0.5534351145038627 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.6106870229008159 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7194a8> 0.7061068702290711 79
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7908d0> 0.8396946564886285 96
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731c88> 0.8778625954199306 114
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #8
root->2->10->8->19->7->0->2->29
Best Reward: 0.03816793893129855
iteration: 6
found coverage increase 0.03816793893129855
Current Total Coverage 8.702290076335878
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 600
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bac18> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.019083969465649275 16
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.019083969465649275 17
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.019083969465649275 18
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.019083969465649275 19
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8ac8> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.057251908396947826 20
Completed Iteration #7
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.057251908396947826 21
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790cf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.0763358778625971 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.0763358778625971 22
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baf60> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.09541984732824638 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.09541984732824638 23
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40254a8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.11450381679389565 24
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.13358778625954493 25
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.1526717557251942 26
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790710> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.17175572519084348 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.17175572519084348 27
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc18> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.057251908396947826 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.20992366412214203 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.20992366412214203 28
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.20992366412214203 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.20992366412214203 29
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.20992366412214203 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.20992366412214203 30
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.20992366412214203 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.20992366412214203 31
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.20992366412214203 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.20992366412214203 32
Completed Iteration #2
Best Reward: 0.03816793893129855
Completed Iteration #3
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.0763358778625971 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.2290076335877913 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.2290076335877913 33
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a9b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066588> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.09541984732824638 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.24809160305344058 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.24809160305344058 34
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.09541984732824638 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.24809160305344058 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.24809160305344058 35
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066ba8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057f60> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.11450381679389565 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.26717557251908985 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.26717557251908985 36
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3a90> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.057251908396947826 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.13358778625954493 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.28625954198473913 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.28625954198473913 37
Completed Iteration #20
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6898> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.0763358778625971 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.1526717557251942 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.3053435114503884 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.3053435114503884 38
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba160> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066080> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.17175572519084348 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.3244274809160377 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.3244274809160377 39
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d668> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.17175572519084348 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.3244274809160377 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.3244274809160377 40
Completed Iteration #24
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ad68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a390> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc18> 0.057251908396947826 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.09541984732824638 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.19083969465649275 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.34351145038168696 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.34351145038168696 41
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #2
root->5->10
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.11450381679389565 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.20992366412214203 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.36259541984733623 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.36259541984733623 42
Completed Iteration #0
Best Reward: 0.03816793893129855
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066b38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.13358778625954493 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.2290076335877913 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.3816793893129855 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.3816793893129855 43
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d198> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.1526717557251942 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.24809160305344058 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.4007633587786348 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.4007633587786348 44
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066b38> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.1526717557251942 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.24809160305344058 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.4007633587786348 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.4007633587786348 45
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.17175572519084348 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.26717557251908985 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.41984732824428406 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.41984732824428406 46
Completed Iteration #7
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956d8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095198> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6898> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.19083969465649275 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.28625954198473913 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.43893129770993333 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.43893129770993333 47
Completed Iteration #8
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057c18> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095240> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc18> 0.0763358778625971 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.20992366412214203 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.3053435114503884 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.4580152671755826 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.4580152671755826 48
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea400acf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.2290076335877913 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.3244274809160377 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.4770992366412319 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.4770992366412319 49
Completed Iteration #10
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3fd0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.24809160305344058 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.34351145038168696 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.49618320610688116 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.49618320610688116 50
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6160> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a86d8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.26717557251908985 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.36259541984733623 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.5152671755725304 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.5152671755725304 51
Completed Iteration #13
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095588> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3a90> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.28625954198473913 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.3816793893129855 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.5343511450381797 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.5343511450381797 52
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.3244274809160377 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.41984732824428406 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.5725190839694783 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.5725190839694783 53
Completed Iteration #15
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066b38> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.3244274809160377 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.41984732824428406 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.5725190839694783 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.5725190839694783 54
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40577b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.34351145038168696 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.43893129770993333 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.5916030534351275 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.5916030534351275 55
Completed Iteration #18
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a358> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3fd0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.36259541984733623 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.4580152671755826 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.6106870229007768 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.6106870229007768 56
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baeb8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400add8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40577b8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.3816793893129855 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.4770992366412319 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.6297709923664261 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.6297709923664261 57
Completed Iteration #22
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d978> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d0f0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40577b8> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.4007633587786348 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.49618320610688116 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.6488549618320754 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.6488549618320754 58
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40954e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.41984732824428406 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.5152671755725304 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.6679389312977246 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.6679389312977246 59
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #3
root->5->10->5
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.0763358778625971 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.4580152671755826 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.553435114503829 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7061068702290232 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7061068702290232 60
Completed Iteration #1
Best Reward: 0.03816793893129855
Completed Iteration #2
Best Reward: 0.03816793893129855
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b89e8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.057251908396947826 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.09541984732824638 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.4770992366412319 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.5725190839694783 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7251908396946725 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7251908396946725 61
Completed Iteration #6
Best Reward: 0.03816793893129855
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095e48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8cc0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.11450381679389565 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.49618320610688116 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.5916030534351275 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7442748091603217 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7442748091603217 62
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.11450381679389565 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.49618320610688116 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.5916030534351275 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7442748091603217 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7442748091603217 63
Completed Iteration #10
Best Reward: 0.03816793893129855
coverage_call_count 700
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.13358778625954493 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.5152671755725304 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6106870229007768 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.763358778625971 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.763358778625971 64
Completed Iteration #12
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.13358778625954493 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.5152671755725304 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6106870229007768 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.763358778625971 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.763358778625971 65
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3eb8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.0763358778625971 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.1526717557251942 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.5343511450381797 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6297709923664261 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7824427480916203 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7824427480916203 66
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.1526717557251942 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.5343511450381797 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6297709923664261 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7824427480916203 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7824427480916203 67
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.5343511450381797 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6297709923664261 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.7824427480916203 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.7824427480916203 68
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8d30> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.17175572519084348 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.553435114503829 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6488549618320754 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.8015267175572696 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.8015267175572696 69
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40572e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.17175572519084348 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.553435114503829 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6488549618320754 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.8015267175572696 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.8015267175572696 70
Completed Iteration #24
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a9e8> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.11450381679389565 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.20992366412214203 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.5916030534351275 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.6870229007633739 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.8396946564885681 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.8396946564885681 71
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #4
root->5->10->5->12
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045b00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.057251908396947826 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.13358778625954493 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.2290076335877913 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.6106870229007768 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.7061068702290232 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.8587786259542174 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.8587786259542174 72
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40453c8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b89e8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.1526717557251942 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.24809160305344058 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.6297709923664261 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.7251908396946725 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.8778625954198667 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.8778625954198667 73
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045198> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.17175572519084348 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.26717557251908985 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.6488549618320754 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.7442748091603217 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.8969465648855159 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.8969465648855159 74
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de518> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.19083969465649275 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.28625954198473913 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.6679389312977246 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.763358778625971 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.9160305343511652 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.9160305343511652 75
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c25c0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191c18> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045198> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.20992366412214203 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.3053435114503884 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.6870229007633739 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.7824427480916203 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.9351145038168145 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.9351145038168145 76
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8160> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.2290076335877913 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.3244274809160377 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.7061068702290232 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8015267175572696 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.9541984732824638 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.9541984732824638 77
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025908> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.24809160305344058 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.34351145038168696 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.7251908396946725 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8206106870229188 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.973282442748113 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.973282442748113 78
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045fd0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.26717557251908985 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.36259541984733623 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.7442748091603217 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8396946564885681 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 0.9923664122137623 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 0.9923664122137623 79
Completed Iteration #24
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a50f0> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3053435114503884 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.4007633587786348 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.7824427480916203 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8778625954198667 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0305343511450609 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0305343511450609 80
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #5
root->5->10->5->12->3
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3053435114503884 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.4007633587786348 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.7824427480916203 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8778625954198667 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0305343511450609 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0305343511450609 81
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40decf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de710> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3244274809160377 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.41984732824428406 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8015267175572696 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8969465648855159 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0496183206107101 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0496183206107101 82
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3244274809160377 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.41984732824428406 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8015267175572696 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8969465648855159 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0496183206107101 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0496183206107101 83
Completed Iteration #2
Best Reward: 0.03816793893129855
Completed Iteration #3
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de710> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.0763358778625971 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3244274809160377 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.41984732824428406 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8015267175572696 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8969465648855159 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0496183206107101 69
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0496183206107101 84
Completed Iteration #4
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.0763358778625971 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3244274809160377 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.41984732824428406 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8015267175572696 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.8969465648855159 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0496183206107101 70
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0496183206107101 85
Completed Iteration #5
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.36259541984733623 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.4580152671755826 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8396946564885681 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.9351145038168145 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.0877862595420087 71
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.0877862595420087 86
Completed Iteration #6
Best Reward: 0.03816793893129855
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40660b8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de710> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.3816793893129855 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.4770992366412319 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8587786259542174 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.9541984732824638 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.106870229007658 72
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.106870229007658 87
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5128> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045b00> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.4007633587786348 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.49618320610688116 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.8778625954198667 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 0.973282442748113 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.1259541984733072 73
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.1259541984733072 88
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8860> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b84e0> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.0763358778625971 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.0763358778625971 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.19083969465649275 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.43893129770993333 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.5343511450381797 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.9160305343511652 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.0114503816794116 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.1641221374046058 74
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.1641221374046058 89
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b85f8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045b00> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.20992366412214203 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.4580152671755826 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.553435114503829 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.9351145038168145 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.0305343511450609 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.183206106870255 75
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.183206106870255 90
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5b00> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191d68> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.24809160305344058 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.49618320610688116 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.5916030534351275 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.973282442748113 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.0687022900763594 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.2213740458015536 76
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.2213740458015536 91
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #6
root->5->10->5->12->3->1
Best Reward: 0.03816793893129855
Completed Iteration #0
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5ac8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.09541984732824638 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.26717557251908985 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.5152671755725304 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.6106870229007768 35
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.9923664122137623 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.0877862595420087 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.240458015267203 77
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.240458015267203 92
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.26717557251908985 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.5152671755725304 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.6106870229007768 36
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.9923664122137623 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.0877862595420087 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.240458015267203 78
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.240458015267203 93
Completed Iteration #2
Best Reward: 0.03816793893129855
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698c88> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6794e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.09541984732824638 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.28625954198473913 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.5343511450381797 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.6297709923664261 37
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.0114503816794116 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.106870229007658 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.2595419847328522 79
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.2595419847328522 94
Completed Iteration #5
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698c18> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.1526717557251942 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.3244274809160377 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.5725190839694783 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.6679389312977246 38
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.0496183206107101 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.1450381679389565 69
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.2977099236641507 80
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.2977099236641507 95
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719320> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.19083969465649275 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.36259541984733623 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6106870229007768 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.7061068702290232 39
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.0877862595420087 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.183206106870255 70
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.3358778625954493 81
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.3358778625954493 96
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Completed Iteration #9
Best Reward: 0.03816793893129855
Completed Iteration #10
Best Reward: 0.03816793893129855
Completed Iteration #11
Best Reward: 0.03816793893129855
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.19083969465649275 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.36259541984733623 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6106870229007768 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.7061068702290232 40
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.0877862595420087 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.183206106870255 71
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.3358778625954493 82
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.3358778625954493 97
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Completed Iteration #18
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.19083969465649275 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.36259541984733623 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6106870229007768 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.7061068702290232 41
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.0877862595420087 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.183206106870255 72
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.3358778625954493 83
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.3358778625954493 98
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057ba8> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.2290076335877913 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.4007633587786348 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6488549618320754 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.7442748091603217 42
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1259541984733072 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.2213740458015536 73
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.3740458015267478 84
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.3740458015267478 99
Completed Iteration #20
Best Reward: 0.03816793893129855
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #7
root->5->10->5->12->3->1->0
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679c50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de8d0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.11450381679389565 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.24809160305344058 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.41984732824428406 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6679389312977246 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.763358778625971 43
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1450381679389565 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.240458015267203 74
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.393129770992397 85
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.393129770992397 100
Completed Iteration #0
Best Reward: 0.03816793893129855
Completed Iteration #1
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b84e0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.11450381679389565 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.24809160305344058 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.41984732824428406 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6679389312977246 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.763358778625971 44
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1450381679389565 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.240458015267203 75
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.393129770992397 86
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.393129770992397 101
Completed Iteration #2
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de8d0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.24809160305344058 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.41984732824428406 25
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6679389312977246 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.763358778625971 45
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1450381679389565 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.240458015267203 76
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.393129770992397 87
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.393129770992397 102
Completed Iteration #3
Best Reward: 0.03816793893129855
Completed Iteration #4
Best Reward: 0.03816793893129855
Completed Iteration #5
Best Reward: 0.03816793893129855
Completed Iteration #6
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.11450381679389565 8
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.24809160305344058 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.41984732824428406 26
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6679389312977246 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.763358778625971 46
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1450381679389565 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.240458015267203 77
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.393129770992397 88
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.393129770992397 103
Completed Iteration #7
Best Reward: 0.03816793893129855
Completed Iteration #8
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.11450381679389565 9
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.24809160305344058 17
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.41984732824428406 27
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6679389312977246 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.763358778625971 47
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1450381679389565 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.240458015267203 78
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.393129770992397 89
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.393129770992397 104
Completed Iteration #9
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40957f0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191940> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.13358778625954493 10
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.26717557251908985 18
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.43893129770993333 28
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.6870229007633739 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.7824427480916203 48
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.1641221374046058 69
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.2595419847328522 79
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.4122137404580464 90
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.4122137404580464 105
Completed Iteration #10
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fce48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.1526717557251942 11
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.28625954198473913 19
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.4580152671755826 29
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.7061068702290232 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.8015267175572696 49
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.183206106870255 70
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.2786259541985014 80
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.4312977099236956 91
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.4312977099236956 106
Completed Iteration #11
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5f60> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5d68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1550> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.17175572519084348 12
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.3053435114503884 20
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.4770992366412319 30
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.7251908396946725 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.8206106870229188 50
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.2022900763359043 71
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.2977099236641507 81
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.450381679389345 92
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.450381679389345 107
Completed Iteration #12
Best Reward: 0.03816793893129855
Completed Iteration #13
Best Reward: 0.03816793893129855
Completed Iteration #14
Best Reward: 0.03816793893129855
Completed Iteration #15
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698ef0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6987f0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.19083969465649275 13
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.3244274809160377 21
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.49618320610688116 31
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.7442748091603217 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.8396946564885681 51
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.2213740458015536 72
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.3167938931298 82
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.4694656488549942 93
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.4694656488549942 108
Completed Iteration #16
Best Reward: 0.03816793893129855
Completed Iteration #17
Best Reward: 0.03816793893129855
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724da0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b84e0> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.20992366412214203 14
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.34351145038168696 22
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.5152671755725304 32
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.763358778625971 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.8587786259542174 52
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.240458015267203 73
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.3358778625954493 83
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.4885496183206435 94
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.4885496183206435 109
Completed Iteration #18
Best Reward: 0.03816793893129855
Completed Iteration #19
Best Reward: 0.03816793893129855
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b84e0> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.20992366412214203 15
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.34351145038168696 23
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.5152671755725304 33
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.763358778625971 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.8587786259542174 53
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.240458015267203 74
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.3358778625954493 84
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.4885496183206435 95
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.4885496183206435 110
Completed Iteration #20
Best Reward: 0.03816793893129855
Reward: 0.03816793893129855
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1ba8> 0.03816793893129855 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc780> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.24809160305344058 16
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7b70> 0.3816793893129855 24
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.553435114503829 34
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d30> 0.8015267175572696 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790eb8> 0.8969465648855159 54
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 1.2786259541985014 75
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3898> 1.3740458015267478 85
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6748> 1.526717557251942 96
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8550> 1.526717557251942 111
Completed Iteration #21
Best Reward: 0.03816793893129855
Completed Iteration #22
Best Reward: 0.03816793893129855
Completed Iteration #23
Best Reward: 0.03816793893129855
coverage_call_count 800
Completed Iteration #24
Best Reward: 0.03816793893129855
Completed Iteration #25
Best Reward: 0.03816793893129855
Completed MCTS Level/Depth: #8
root->5->10->5->12->3->1->0->29
Best Reward: 0.03816793893129855
iteration: 7
found coverage increase 0.03816793893129855
Current Total Coverage 8.740458015267176
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40456d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 8.740458015267176
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 8.740458015267176
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 8.740458015267176
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 8
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 9
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 10
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 11
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 12
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 13
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 14
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 15
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 16
Completed Iteration #19
Best Reward: 0.038167938931296774
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 17
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 18
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 19
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 20
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 21
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 22
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #0
root
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.038167938931296774 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 23
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.038167938931296774 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.038167938931296774 24
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506f07b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.05725190839694427 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.05725190839694427 25
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.05725190839694427 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.05725190839694427 26
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.05725190839694427 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.05725190839694427 27
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.05725190839694427 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.05725190839694427 28
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c748> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c2b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a20> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.07633587786259177 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.07633587786259177 29
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.07633587786259177 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.07633587786259177 30
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.07633587786259177 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.07633587786259177 31
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f07b8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.07633587786259177 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.07633587786259177 32
Completed Iteration #24
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.07633587786259177 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.07633587786259177 33
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.038167938931296774
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698240> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.05725190839694427 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.09541984732823927 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.09541984732823927 34
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.05725190839694427 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.09541984732823927 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.09541984732823927 35
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1be0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3fd0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.07633587786259177 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.11450381679388677 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.11450381679388677 36
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.07633587786259177 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.11450381679388677 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.11450381679388677 37
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.07633587786259177 7
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.11450381679388677 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.11450381679388677 38
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1be0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3fd0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.07633587786259177 8
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.11450381679388677 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.11450381679388677 39
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cda0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.09541984732823927 9
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.13358778625953427 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.13358778625953427 40
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.09541984732823927 10
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.13358778625953427 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.13358778625953427 41
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.09541984732823927 11
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.13358778625953427 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.13358778625953427 42
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e50699630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1940> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.11450381679388677 12
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.15267175572518177 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.15267175572518177 43
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.11450381679388677 13
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.15267175572518177 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.15267175572518177 44
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506996a0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.13358778625953427 14
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.17175572519082927 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.17175572519082927 45
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.13358778625953427 15
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.17175572519082927 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.17175572519082927 46
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506a28d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cfd0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.15267175572518177 16
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.19083969465647677 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.19083969465647677 47
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e507170f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.07633587786259 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.17175572519082927 17
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.20992366412212426 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.20992366412212426 48
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0898> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.0954198473282375 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.19083969465647677 18
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.22900763358777176 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.22900763358777176 49
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #2
root->5->17
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0f28> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.114503816793885 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.20992366412212426 19
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.24809160305341926 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.24809160305341926 50
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0f28> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.114503816793885 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.20992366412212426 20
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.24809160305341926 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.24809160305341926 51
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0f28> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.114503816793885 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.20992366412212426 21
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.24809160305341926 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.24809160305341926 52
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e50699240> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.1335877862595325 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.22900763358777176 22
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.26717557251906676 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.26717557251906676 53
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e50699908> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.15267175572518 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.24809160305341926 23
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.28625954198471426 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.28625954198471426 54
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.15267175572518 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.24809160305341926 24
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.28625954198471426 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.28625954198471426 55
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.1717557251908275 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.26717557251906676 25
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.30534351145036176 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.30534351145036176 56
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.1717557251908275 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.26717557251906676 26
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.30534351145036176 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.30534351145036176 57
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #3
root->5->17->2
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.1717557251908275 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.26717557251906676 27
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.30534351145036176 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.30534351145036176 58
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b7b8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2588> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.190839694656475 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.28625954198471426 28
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.32442748091600926 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.32442748091600926 59
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bc18> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b198> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 29
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 60
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 30
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 61
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 31
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 62
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 32
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 63
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 33
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 64
Completed Iteration #11
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 34
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 65
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 35
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 66
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0572519083969425 12
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2099236641221225 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.30534351145036176 36
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.34351145038165676 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.34351145038165676 67
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b0f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.07633587786259 13
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.22900763358777 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.32442748091600926 37
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.36259541984730426 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.36259541984730426 68
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.07633587786259 14
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.22900763358777 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.32442748091600926 38
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.36259541984730426 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.36259541984730426 69
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f5c0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0954198473282375 15
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2480916030534175 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.34351145038165676 39
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.38167938931295176 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.38167938931295176 70
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #4
root->5->17->2->2
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0954198473282375 16
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2480916030534175 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.34351145038165676 40
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.38167938931295176 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.38167938931295176 71
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Completed Iteration #2
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb38> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.114503816793885 17
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.267175572519065 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.36259541984730426 41
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.40076335877859925 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.40076335877859925 72
Completed Iteration #3
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.114503816793885 18
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.267175572519065 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.36259541984730426 42
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.40076335877859925 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.40076335877859925 73
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f5c0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.114503816793885 19
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.267175572519065 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.36259541984730426 43
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.40076335877859925 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.40076335877859925 74
Completed Iteration #5
Best Reward: 0.038167938931296774
coverage_call_count 1000
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb38> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.114503816793885 20
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.267175572519065 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.36259541984730426 44
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.40076335877859925 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.40076335877859925 75
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f908> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506994a8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c160> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.1335877862595325 21
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.2862595419847125 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.38167938931295176 45
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.41984732824424675 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.41984732824424675 76
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.07633587786259 9
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.15267175572518 22
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.30534351145036 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.40076335877859925 46
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.43893129770989425 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.43893129770989425 77
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #5
root->5->17->2->2->2
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d320> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.0954198473282375 10
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.1717557251908275 23
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.3244274809160075 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.41984732824424675 47
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.45801526717554175 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.45801526717554175 78
Completed Iteration #0
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.0954198473282375 11
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.1717557251908275 24
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.3244274809160075 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.41984732824424675 48
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.45801526717554175 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.45801526717554175 79
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d320> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.0954198473282375 12
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.1717557251908275 25
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.3244274809160075 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.41984732824424675 49
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.45801526717554175 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.45801526717554175 80
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e3011df60> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d320> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.114503816793885 13
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.190839694656475 26
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.343511450381655 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.43893129770989425 50
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.47709923664118925 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.47709923664118925 81
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.114503816793885 14
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.190839694656475 27
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.343511450381655 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.43893129770989425 51
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.47709923664118925 64
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.47709923664118925 82
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.114503816793885 15
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.190839694656475 28
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.343511450381655 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.43893129770989425 52
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.47709923664118925 65
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.47709923664118925 83
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.114503816793885 16
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.190839694656475 29
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.343511450381655 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.43893129770989425 53
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.47709923664118925 66
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.47709923664118925 84
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.114503816793885 17
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.190839694656475 30
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.343511450381655 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.43893129770989425 54
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.47709923664118925 67
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.47709923664118925 85
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.114503816793885 18
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.190839694656475 31
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.343511450381655 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.43893129770989425 55
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.47709923664118925 68
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.47709923664118925 86
Completed Iteration #17
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b080> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.07633587786259 12
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.1335877862595325 19
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.2099236641221225 32
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.3625954198473025 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.45801526717554175 56
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.49618320610683675 69
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.49618320610683675 87
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.11450381679388677 13
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.17175572519082927 20
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.24809160305341926 33
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.40076335877859925 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.4961832061068385 57
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.5343511450381335 70
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.5343511450381335 88
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301281d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.11450381679388677 14
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.17175572519082927 21
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.24809160305341926 34
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.40076335877859925 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.4961832061068385 58
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.5343511450381335 71
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.5343511450381335 89
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #6
root->5->17->2->2->2->11
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.038167938931296774 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.038167938931296774 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.11450381679388677 15
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.17175572519082927 22
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.24809160305341926 35
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.40076335877859925 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.4961832061068385 59
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.5343511450381335 72
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.5343511450381335 90
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fa20> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.05725190839694427 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.13358778625953427 16
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.19083969465647677 23
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.26717557251906676 36
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.41984732824424675 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.515267175572486 60
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.553435114503781 73
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.553435114503781 91
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e30141c88> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.07633587786259177 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.15267175572518177 17
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.20992366412212426 24
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.28625954198471426 37
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.43893129770989425 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.5343511450381335 61
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.5725190839694285 74
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.5725190839694285 92
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e30128e10> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.09541984732823927 7
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.17175572519082927 18
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.22900763358777176 25
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.30534351145036176 38
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.45801526717554175 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.553435114503781 62
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.591603053435076 75
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.591603053435076 93
Completed Iteration #8
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b00> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.11450381679388677 8
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.19083969465647677 19
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.24809160305341926 26
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.32442748091600926 39
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.47709923664118925 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.5725190839694285 63
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.6106870229007235 76
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.6106870229007235 94
Completed Iteration #9
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.11450381679388677 9
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.19083969465647677 20
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.24809160305341926 27
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.32442748091600926 40
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.47709923664118925 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.5725190839694285 64
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.6106870229007235 77
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.6106870229007235 95
Completed Iteration #10
Best Reward: 0.038167938931296774
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.11450381679388677 10
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.19083969465647677 21
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.24809160305341926 28
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.32442748091600926 41
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.47709923664118925 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.5725190839694285 65
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.6106870229007235 78
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.6106870229007235 96
Completed Iteration #14
Best Reward: 0.038167938931296774
Completed Iteration #15
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141c88> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.11450381679388677 11
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.19083969465647677 22
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.24809160305341926 29
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.32442748091600926 42
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.47709923664118925 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.5725190839694285 66
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.6106870229007235 79
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.6106870229007235 97
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2da0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.13358778625953427 12
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.20992366412212426 23
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.26717557251906676 30
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.34351145038165676 43
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.49618320610683675 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.591603053435076 67
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.629770992366371 80
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.629770992366371 98
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141c88> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.13358778625953427 13
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.20992366412212426 24
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.26717557251906676 31
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.34351145038165676 44
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.49618320610683675 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.591603053435076 68
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.629770992366371 81
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.629770992366371 99
Completed Iteration #21
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.13358778625953427 14
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.20992366412212426 25
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.26717557251906676 32
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.34351145038165676 45
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.49618320610683675 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.591603053435076 69
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.629770992366371 82
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.629770992366371 100
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #7
root->5->17->2->2->2->11->1
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e30155be0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301554e0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.05725190839694427 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.15267175572518177 15
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.22900763358777176 26
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.28625954198471426 33
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.36259541984730426 46
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.5152671755724842 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.6106870229007235 70
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.6488549618320185 83
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.6488549618320185 101
Completed Iteration #0
Best Reward: 0.038167938931296774
Completed Iteration #1
Best Reward: 0.038167938931296774
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d978> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011de48> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.07633587786259177 5
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.17175572519082927 16
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.24809160305341926 27
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.30534351145036176 34
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.38167938931295176 47
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.5343511450381317 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.629770992366371 71
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.667938931297666 84
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.667938931297666 102
Completed Iteration #2
Best Reward: 0.038167938931296774
Completed Iteration #3
Best Reward: 0.038167938931296774
Completed Iteration #4
Best Reward: 0.038167938931296774
Completed Iteration #5
Best Reward: 0.038167938931296774
Completed Iteration #6
Best Reward: 0.038167938931296774
Completed Iteration #7
Best Reward: 0.038167938931296774
Completed Iteration #8
Best Reward: 0.038167938931296774
Completed Iteration #9
Best Reward: 0.038167938931296774
Completed Iteration #10
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.07633587786259177 6
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.17175572519082927 17
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.24809160305341926 28
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.30534351145036176 35
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.38167938931295176 48
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.5343511450381317 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.629770992366371 72
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.667938931297666 85
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.667938931297666 103
Completed Iteration #11
Best Reward: 0.038167938931296774
Completed Iteration #12
Best Reward: 0.038167938931296774
Completed Iteration #13
Best Reward: 0.038167938931296774
Completed Iteration #14
Best Reward: 0.038167938931296774
Reward: 0.038167938931296774
backprop <src.mcts.MCTS_Node object at 0x7f7e30155f28> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301417f0> 0.038167938931296774 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.11450381679388855 7
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.20992366412212604 18
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.28625954198471604 29
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.34351145038165853 36
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.41984732824424853 49
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.5725190839694285 61
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.6679389312976678 73
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.7061068702289628 86
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.7061068702289628 104
Completed Iteration #15
Best Reward: 0.038167938931296774
Completed Iteration #16
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d978> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3011de48> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.11450381679388855 8
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.20992366412212604 19
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.28625954198471604 30
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.34351145038165853 37
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.41984732824424853 50
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.5725190839694285 62
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.6679389312976678 74
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.7061068702289628 87
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.7061068702289628 105
Completed Iteration #17
Best Reward: 0.038167938931296774
Completed Iteration #18
Best Reward: 0.038167938931296774
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301554e0> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c88> 0.11450381679388855 9
backprop <src.mcts.MCTS_Node object at 0x7f7e50699978> 0.20992366412212604 20
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.28625954198471604 31
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bfd0> 0.34351145038165853 38
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.41984732824424853 51
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ac8> 0.5725190839694285 63
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.6679389312976678 75
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.7061068702289628 88
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1668> 0.7061068702289628 106
Completed Iteration #19
Best Reward: 0.038167938931296774
Completed Iteration #20
Best Reward: 0.038167938931296774
Completed Iteration #21
Best Reward: 0.038167938931296774
Completed Iteration #22
Best Reward: 0.038167938931296774
Completed Iteration #23
Best Reward: 0.038167938931296774
Completed Iteration #24
Best Reward: 0.038167938931296774
Completed Iteration #25
Best Reward: 0.038167938931296774
Completed MCTS Level/Depth: #8
root->5->17->2->2->2->11->1->29
Best Reward: 0.038167938931296774
iteration: 11
found coverage increase 0.038167938931296774
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 1100
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea3c8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 8.778625954198473
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 8.778625954198473
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2cf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 6
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 7
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 8
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 9
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 10
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 11
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 12
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 6
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 13
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 14
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 7
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 15
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 16
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 17
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 18
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 19
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 20
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #0
root
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 8
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 21
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 9
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 22
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 10
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 23
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 11
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 24
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 12
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 25
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 13
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 26
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 14
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 27
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 15
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 28
Completed Iteration #8
Best Reward: 0.019083969465649275
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.019083969465649275 16
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.019083969465649275 29
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.03816793893129855 17
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.03816793893129855 30
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.03816793893129855 18
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.03816793893129855 31
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300d25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.03816793893129855 19
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.03816793893129855 32
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f518> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 20
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 33
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 21
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 34
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 22
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 35
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 23
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 36
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 24
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 37
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 25
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 38
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2cf8> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 26
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 39
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 27
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 40
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 28
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 41
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.057251908396947826 29
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.057251908396947826 42
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e30073438> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0763358778625971 30
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0763358778625971 43
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.057251908396947826 7
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0763358778625971 31
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0763358778625971 44
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.057251908396947826 8
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0763358778625971 32
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0763358778625971 45
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.057251908396947826 9
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0763358778625971 33
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0763358778625971 46
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.057251908396947826 10
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0763358778625971 34
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0763358778625971 47
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #2
root->0->19
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.057251908396947826 11
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.0763358778625971 35
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0763358778625971 48
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bb00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.0763358778625971 12
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.09541984732824638 36
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.09541984732824638 49
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.03816793893129855 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.0763358778625971 13
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.09541984732824638 37
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.09541984732824638 50
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.09541984732824638 14
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.11450381679389565 38
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.11450381679389565 51
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.057251908396947826 7
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.09541984732824638 15
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.11450381679389565 39
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.11450381679389565 52
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300736a0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.0763358778625971 8
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.11450381679389565 16
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.13358778625954493 40
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.13358778625954493 53
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.09541984732824638 9
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.13358778625954493 17
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.1526717557251942 41
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.1526717557251942 54
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.09541984732824638 10
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.13358778625954493 18
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.1526717557251942 42
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.1526717557251942 55
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300361d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.09541984732824638 11
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.13358778625954493 19
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.1526717557251942 43
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.1526717557251942 56
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #3
root->0->19->2
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036400> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.11450381679389565 12
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.1526717557251942 20
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.17175572519084348 44
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.17175572519084348 57
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e30036470> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.057251908396947826 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.13358778625954493 13
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.17175572519084348 21
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.19083969465649275 45
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.19083969465649275 58
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2c50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.09541984732824638 6
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.1526717557251942 14
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.19083969465649275 22
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.20992366412214203 46
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.20992366412214203 59
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dd30> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.11450381679389565 7
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.17175572519084348 15
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.20992366412214203 23
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.2290076335877913 47
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.2290076335877913 60
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.11450381679389565 8
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.17175572519084348 16
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.20992366412214203 24
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.2290076335877913 48
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.2290076335877913 61
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db38> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dcf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.13358778625954493 9
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.19083969465649275 17
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.2290076335877913 25
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.24809160305344058 49
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.24809160305344058 62
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3004ff28> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f400> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.1526717557251942 10
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.20992366412214203 18
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.24809160305344058 26
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.26717557251908985 50
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.26717557251908985 63
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d1d0> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.17175572519084348 11
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.2290076335877913 19
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.26717557251908985 27
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.28625954198473913 51
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.28625954198473913 64
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300362b0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc50> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.19083969465649275 12
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.24809160305344058 20
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.28625954198473913 28
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3053435114503884 52
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3053435114503884 65
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e30036828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f978> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 13
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 21
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 29
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 53
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 66
Completed Iteration #23
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d1d0> 0.019083969465649275 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 14
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 22
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 30
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 54
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 67
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #4
root->0->19->2->3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 15
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 23
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 31
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 55
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 68
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 7
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 16
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 24
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 32
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 56
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 69
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 8
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 17
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 25
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 33
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 57
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 70
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 9
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 18
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 26
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 34
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 58
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 71
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 10
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 19
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 27
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 35
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 59
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 72
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.0763358778625971 11
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.20992366412214203 20
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.26717557251908985 28
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3053435114503884 36
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3244274809160377 60
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3244274809160377 73
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf630> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.09541984732824638 12
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.2290076335877913 21
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.28625954198473913 29
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3244274809160377 37
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.34351145038168696 61
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.34351145038168696 74
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
coverage_call_count 1300
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b860> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.11450381679389565 13
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.24809160305344058 22
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.3053435114503884 30
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.34351145038168696 38
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.36259541984733623 62
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.36259541984733623 75
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.11450381679389565 14
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.24809160305344058 23
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.3053435114503884 31
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.34351145038168696 39
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.36259541984733623 63
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.36259541984733623 76
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e30036518> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.13358778625954493 15
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.26717557251908985 24
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.3244274809160377 32
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.36259541984733623 40
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.3816793893129855 64
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.3816793893129855 77
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e30073c50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf208> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf630> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.1526717557251942 16
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.28625954198473913 25
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.34351145038168696 33
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3816793893129855 41
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4007633587786348 65
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4007633587786348 78
Completed Iteration #21
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036518> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.1526717557251942 17
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.28625954198473913 26
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.34351145038168696 34
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3816793893129855 42
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4007633587786348 66
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4007633587786348 79
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #5
root->0->19->2->3->3
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.1526717557251942 18
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.28625954198473913 27
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.34351145038168696 35
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.3816793893129855 43
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4007633587786348 67
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4007633587786348 80
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf048> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfd30> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.17175572519084348 19
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.3053435114503884 28
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.36259541984733623 36
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4007633587786348 44
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.41984732824428406 68
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.41984732824428406 81
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.0763358778625971 6
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.19083969465649275 20
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.3244274809160377 29
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.3816793893129855 37
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.41984732824428406 45
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.43893129770993333 69
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.43893129770993333 82
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e280eaac8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.09541984732824638 7
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.20992366412214203 21
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.34351145038168696 30
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4007633587786348 38
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.43893129770993333 46
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4580152671755826 70
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4580152671755826 83
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.09541984732824638 8
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.20992366412214203 22
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.34351145038168696 31
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4007633587786348 39
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.43893129770993333 47
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4580152671755826 71
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4580152671755826 84
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036400> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.09541984732824638 9
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.20992366412214203 23
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.34351145038168696 32
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4007633587786348 40
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.43893129770993333 48
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4580152671755826 72
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4580152671755826 85
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #6
root->0->19->2->3->3->1
Best Reward: 0.019083969465649275
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bcf8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.11450381679389565 10
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.2290076335877913 24
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.36259541984733623 33
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.41984732824428406 41
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4580152671755826 49
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4770992366412319 73
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4770992366412319 86
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.11450381679389565 11
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.2290076335877913 25
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.36259541984733623 34
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.41984732824428406 42
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4580152671755826 50
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.4770992366412319 74
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.4770992366412319 87
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc50> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.13358778625954493 12
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.24809160305344058 26
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.3816793893129855 35
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.43893129770993333 43
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4770992366412319 51
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.49618320610688116 75
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.49618320610688116 88
Completed Iteration #6
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.13358778625954493 13
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.24809160305344058 27
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.3816793893129855 36
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.43893129770993333 44
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4770992366412319 52
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.49618320610688116 76
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.49618320610688116 89
Completed Iteration #7
Best Reward: 0.019083969465649275
Completed Iteration #8
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.057251908396947826 7
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.13358778625954493 14
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.24809160305344058 28
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.3816793893129855 37
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.43893129770993333 45
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4770992366412319 53
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.49618320610688116 77
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.49618320610688116 90
Completed Iteration #9
Best Reward: 0.019083969465649275
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Completed Iteration #12
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.057251908396947826 8
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.13358778625954493 15
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.24809160305344058 29
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.3816793893129855 38
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.43893129770993333 46
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.4770992366412319 54
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.49618320610688116 78
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.49618320610688116 91
Completed Iteration #13
Best Reward: 0.019083969465649275
Completed Iteration #14
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e28078e10> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078d30> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc50> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.0763358778625971 9
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.1526717557251942 16
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.26717557251908985 30
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.4007633587786348 39
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4580152671755826 47
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.49618320610688116 55
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5152671755725304 79
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5152671755725304 92
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e28078780> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078828> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.03816793893129855 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.09541984732824638 10
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.17175572519084348 17
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.28625954198473913 31
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.41984732824428406 40
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4770992366412319 48
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5152671755725304 56
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5343511450381797 80
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5343511450381797 93
Completed Iteration #19
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.09541984732824638 11
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.17175572519084348 18
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.28625954198473913 32
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.41984732824428406 41
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4770992366412319 49
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5152671755725304 57
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5343511450381797 81
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5343511450381797 94
Completed Iteration #20
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.09541984732824638 12
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.17175572519084348 19
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.28625954198473913 33
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.41984732824428406 42
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4770992366412319 50
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5152671755725304 58
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5343511450381797 82
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5343511450381797 95
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #7
root->0->19->2->3->3->1->4
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.09541984732824638 13
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.17175572519084348 20
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.28625954198473913 34
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.41984732824428406 43
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.4770992366412319 51
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5152671755725304 59
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5343511450381797 83
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5343511450381797 96
Completed Iteration #0
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e28078ba8> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf4e0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.11450381679389565 14
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.19083969465649275 21
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.3053435114503884 35
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.43893129770993333 44
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.49618320610688116 52
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5343511450381797 60
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.553435114503829 84
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.553435114503829 97
Completed Iteration #1
Best Reward: 0.019083969465649275
Completed Iteration #2
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.057251908396947826 6
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.11450381679389565 15
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.19083969465649275 22
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.3053435114503884 36
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.43893129770993333 45
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.49618320610688116 53
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5343511450381797 61
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.553435114503829 85
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.553435114503829 98
Completed Iteration #3
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078828> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.057251908396947826 7
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.11450381679389565 16
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.19083969465649275 23
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.3053435114503884 37
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.43893129770993333 46
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.49618320610688116 54
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5343511450381797 62
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.553435114503829 86
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.553435114503829 99
Completed Iteration #4
Best Reward: 0.019083969465649275
Completed Iteration #5
Best Reward: 0.019083969465649275
Completed Iteration #6
Best Reward: 0.019083969465649275
Completed Iteration #7
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e28087e48> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ead68> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0763358778625971 8
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.13358778625954493 17
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.20992366412214203 24
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.3244274809160377 38
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.4580152671755826 47
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.5152671755725304 55
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.553435114503829 63
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5725190839694783 87
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5725190839694783 100
Completed Iteration #8
Best Reward: 0.019083969465649275
Completed Iteration #9
Best Reward: 0.019083969465649275
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ead68> 0.019083969465649275 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0763358778625971 9
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.13358778625954493 18
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.20992366412214203 25
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.3244274809160377 39
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.4580152671755826 48
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.5152671755725304 56
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.553435114503829 64
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5725190839694783 88
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5725190839694783 101
Completed Iteration #10
Best Reward: 0.019083969465649275
Completed Iteration #11
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fbe0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078828> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.09541984732824638 10
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.1526717557251942 19
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.2290076335877913 26
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.34351145038168696 40
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.4770992366412319 49
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.5343511450381797 57
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5725190839694783 65
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.5916030534351275 89
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.5916030534351275 102
Completed Iteration #12
Best Reward: 0.019083969465649275
Completed Iteration #13
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e2809ffd0> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ead68> 0.03816793893129855 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.11450381679389565 11
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.17175572519084348 20
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.24809160305344058 27
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.36259541984733623 41
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.49618320610688116 50
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.553435114503829 58
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.5916030534351275 66
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.6106870229007768 90
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.6106870229007768 103
Completed Iteration #14
Best Reward: 0.019083969465649275
Completed Iteration #15
Best Reward: 0.019083969465649275
Completed Iteration #16
Best Reward: 0.019083969465649275
Reward: 0.019083969465649275
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b278> 0.019083969465649275 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078828> 0.057251908396947826 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.13358778625954493 12
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fdd8> 0.19083969465649275 21
backprop <src.mcts.MCTS_Node object at 0x7f7e301079b0> 0.26717557251908985 28
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b70> 0.3816793893129855 42
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.5152671755725304 51
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.5725190839694783 59
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.6106870229007768 67
backprop <src.mcts.MCTS_Node object at 0x7f7e300d26a0> 0.6297709923664261 91
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.6297709923664261 104
Completed Iteration #17
Best Reward: 0.019083969465649275
Completed Iteration #18
Best Reward: 0.019083969465649275
Completed Iteration #19
Best Reward: 0.019083969465649275
Completed Iteration #20
Best Reward: 0.019083969465649275
Completed Iteration #21
Best Reward: 0.019083969465649275
Completed Iteration #22
Best Reward: 0.019083969465649275
Completed Iteration #23
Best Reward: 0.019083969465649275
Completed Iteration #24
Best Reward: 0.019083969465649275
Completed Iteration #25
Best Reward: 0.019083969465649275
Completed MCTS Level/Depth: #8
root->0->19->2->3->3->1->4->0
Best Reward: 0.019083969465649275
iteration: 15
found coverage increase 0.019083969465649275
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e0b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e320> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f128> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280517f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280517f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280780b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300367b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 15
Completed Iteration #14
Best Reward: 0
coverage_call_count 1600
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300365f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280784e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301078d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301070f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301070f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e301071d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cac8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1800
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b780> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eae80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107e10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301550b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb6673f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3ef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb6673828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506996a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5828> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c72e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb6673828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de4a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506993c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40572b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507175f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2200
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb42932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb66359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb42933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a90> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb6635908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb42936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb42932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40debe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2300
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506f08d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 14
Completed Iteration #23
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b5f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7310b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7310b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea4164588> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40252b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40252b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7582b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c23c8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe76a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7452e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7452e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40258d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eaac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 5
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 6
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 7
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 8
Completed Iteration #17
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb662aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3007fdd8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42933c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42933c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4138eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea401df28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4191c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3007f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4280fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e507170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5076feb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4779400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50699080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50717b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7eb42930f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301289b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301287f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301289b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f7f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30107eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301415f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e301415f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30107470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30107470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30141fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e300f57b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005ddd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e50729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea401dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4045780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb42935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506a20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f780> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3100
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30141978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e280786a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e507172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28078940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30128b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e3005db38> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 3
Completed Iteration #4
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea41fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7eb4293048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3011deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6795c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3003dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50717eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e50729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4025898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3005bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea414e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 3300
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300eac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea414eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3008f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea415a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40252e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7905f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7905f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7319e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a87b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3400
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280871d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e3004f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e300732e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f60> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5076f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4057c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5067c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2805eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e30073978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7317f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1abe7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7317f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087be0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28078a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4095eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 21
Completed Iteration #20
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a60b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a60b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280516a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28051e48> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28051cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c679da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e28087438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e280518d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28051550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e280518d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ab00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd437b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb21d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e30073f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd433c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd433c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c731240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e300363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c6c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e5063f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd060f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea4066f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c698b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8ae80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea40b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c7e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e301554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e28087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c790748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c77b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd274a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e2809ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd278d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd274a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd276a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9fac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e28087160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84278> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 8.797709923664122
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e1ab8a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e280a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd06e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb588> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 8.797709923664122
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 9
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 10
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 11
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 12
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 13
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 14
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcdfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 15
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 16
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 17
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc841d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 18
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 19
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 20
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0190839694656475 21
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3320> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 22
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 23
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 24
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 25
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 26
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 27
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 28
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 29
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e506e3320> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 30
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 15
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 31
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 16
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 32
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 17
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 33
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 18
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 34
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbdb2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.038167938931295 19
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.038167938931295 35
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5a90> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5278> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc860> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0572519083969425 20
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0572519083969425 36
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0572519083969425 21
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0572519083969425 37
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7e2809f1d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 22
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 38
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e1abfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 23
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 39
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 24
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 40
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7e5065c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 25
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 41
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0190839694656475 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 26
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 42
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0190839694656475 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 27
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 43
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0190839694656475 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.07633587786259 28
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.07633587786259 44
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbceb320> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57390> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.038167938931295 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.0954198473282375 29
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.0954198473282375 45
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.114503816793885 30
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.114503816793885 46
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57390> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.114503816793885 31
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.114503816793885 47
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.114503816793885 32
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.114503816793885 48
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0572519083969425 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.114503816793885 33
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.114503816793885 49
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0572519083969425 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.114503816793885 34
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.114503816793885 50
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62be0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc208> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.07633587786259 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1335877862595325 35
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1335877862595325 51
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00ac8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0954198473282375 15
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.15267175572518 36
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.15267175572518 52
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #2
root->8->15
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0954198473282375 16
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.15267175572518 37
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.15267175572518 53
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.0954198473282375 17
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.15267175572518 38
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.15267175572518 54
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08668> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 18
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 39
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 55
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 19
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 40
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 56
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 20
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 41
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 57
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 21
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 42
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 58
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 22
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 43
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 59
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 23
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 44
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 60
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 24
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 45
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 61
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #3
root->8->15->2
Best Reward: 0.0190839694656475
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0572519083969425 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.114503816793885 25
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.1717557251908275 46
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.1717557251908275 62
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08c18> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08710> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.07633587786259 15
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.1335877862595325 26
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.190839694656475 47
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.190839694656475 63
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.07633587786259 16
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.1335877862595325 27
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.190839694656475 48
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.190839694656475 64
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f60> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22390> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0954198473282375 17
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.15267175572518 28
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2099236641221225 49
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2099236641221225 65
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0954198473282375 18
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.15267175572518 29
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2099236641221225 50
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2099236641221225 66
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.0954198473282375 19
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.15267175572518 30
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2099236641221225 51
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2099236641221225 67
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08550> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.07633587786259 9
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.114503816793885 20
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.1717557251908275 31
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.22900763358777 52
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.22900763358777 68
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27e10> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08710> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.0954198473282375 10
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.1335877862595325 21
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.190839694656475 32
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2480916030534175 53
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2480916030534175 69
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62eb8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.114503816793885 11
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.15267175572518 22
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2099236641221225 33
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.267175572519065 54
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.267175572519065 70
Completed Iteration #24
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22390> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.114503816793885 12
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.15267175572518 23
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2099236641221225 34
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.267175572519065 55
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.267175572519065 71
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #4
root->8->15->2->1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.114503816793885 13
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.15267175572518 24
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2099236641221225 35
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.267175572519065 56
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.267175572519065 72
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.114503816793885 14
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.15267175572518 25
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2099236641221225 36
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.267175572519065 57
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.267175572519065 73
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.038167938931295 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.114503816793885 15
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.15267175572518 26
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2099236641221225 37
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.267175572519065 58
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.267175572519065 74
Completed Iteration #3
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.038167938931295 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.114503816793885 16
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.15267175572518 27
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2099236641221225 38
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.267175572519065 59
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.267175572519065 75
Completed Iteration #4
Best Reward: 0.0190839694656475
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.1335877862595325 17
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.1717557251908275 28
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.22900763358777 39
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2862595419847125 60
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2862595419847125 76
Completed Iteration #7
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.1335877862595325 18
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.1717557251908275 29
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.22900763358777 40
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2862595419847125 61
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2862595419847125 77
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.0572519083969425 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.1335877862595325 19
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.1717557251908275 30
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.22900763358777 41
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2862595419847125 62
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2862595419847125 78
Completed Iteration #10
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.0572519083969425 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.1335877862595325 20
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.1717557251908275 31
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.22900763358777 42
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.2862595419847125 63
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.2862595419847125 79
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27eb8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.07633587786259 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.15267175572518 21
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.190839694656475 32
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2480916030534175 43
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.30534351145036 64
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.30534351145036 80
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3ccc0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.0954198473282375 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.1717557251908275 22
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2099236641221225 33
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.267175572519065 44
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3244274809160075 65
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3244274809160075 81
Completed Iteration #14
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc627f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57a90> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.114503816793885 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.190839694656475 23
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.22900763358777 34
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2862595419847125 45
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.343511450381655 66
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.343511450381655 82
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.114503816793885 15
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.190839694656475 24
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.22900763358777 35
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2862595419847125 46
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.343511450381655 67
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.343511450381655 83
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.114503816793885 16
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.190839694656475 25
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.22900763358777 36
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.2862595419847125 47
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.343511450381655 68
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.343511450381655 84
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08b70> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1335877862595325 17
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2099236641221225 26
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2480916030534175 37
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.30534351145036 48
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3625954198473025 69
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3625954198473025 85
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #5
root->8->15->2->1->4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57a90> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0572519083969425 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1335877862595325 18
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2099236641221225 27
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2480916030534175 38
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.30534351145036 49
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3625954198473025 70
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3625954198473025 86
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Completed Iteration #2
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1335877862595325 19
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2099236641221225 28
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2480916030534175 39
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.30534351145036 50
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3625954198473025 71
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3625954198473025 87
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0572519083969425 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1335877862595325 20
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2099236641221225 29
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2480916030534175 40
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.30534351145036 51
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3625954198473025 72
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3625954198473025 88
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57a90> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0572519083969425 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1335877862595325 21
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2099236641221225 30
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2480916030534175 41
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.30534351145036 52
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3625954198473025 73
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3625954198473025 89
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0572519083969425 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1335877862595325 22
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2099236641221225 31
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2480916030534175 42
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.30534351145036 53
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.3625954198473025 74
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.3625954198473025 90
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc082b0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57a90> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.07633587786259 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.15267175572518 23
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.22900763358777 32
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.267175572519065 43
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.3244274809160075 54
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.38167938931295 75
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.38167938931295 91
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.07633587786259 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.15267175572518 24
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.22900763358777 33
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.267175572519065 44
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.3244274809160075 55
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.38167938931295 76
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.38167938931295 92
Completed Iteration #12
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31898> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c828> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0954198473282375 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1717557251908275 25
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2480916030534175 34
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2862595419847125 45
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.343511450381655 56
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.4007633587785975 77
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.4007633587785975 93
Completed Iteration #13
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0954198473282375 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1717557251908275 26
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2480916030534175 35
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2862595419847125 46
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.343511450381655 57
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.4007633587785975 78
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.4007633587785975 94
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c828> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.0954198473282375 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.1717557251908275 27
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2480916030534175 36
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.2862595419847125 47
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.343511450381655 58
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.4007633587785975 79
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.4007633587785975 95
Completed Iteration #16
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22cf8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c828> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.114503816793885 15
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.190839694656475 28
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.267175572519065 37
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.30534351145036 48
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.3625954198473025 59
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.419847328244245 80
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.419847328244245 96
Completed Iteration #17
Best Reward: 0.0190839694656475
Completed Iteration #18
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.114503816793885 16
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.190839694656475 29
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.267175572519065 38
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.30534351145036 49
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.3625954198473025 60
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.419847328244245 81
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.419847328244245 97
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2860> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.1335877862595325 17
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.2099236641221225 30
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.2862595419847125 39
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.3244274809160075 50
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.38167938931295 61
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.4389312977098925 82
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.4389312977098925 98
Completed Iteration #20
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e82e8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3ca90> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.15267175572518 18
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.22900763358777 31
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.30534351145036 40
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.343511450381655 51
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.4007633587785975 62
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.45801526717554 83
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.45801526717554 99
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8dd8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cd30> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.1717557251908275 19
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.2480916030534175 32
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.3244274809160075 41
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.3625954198473025 52
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.419847328244245 63
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.4770992366411875 84
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.4770992366411875 100
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8e48> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e27b8> 0.0190839694656475 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.190839694656475 20
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.267175572519065 33
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.343511450381655 42
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.38167938931295 53
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.4389312977098925 64
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.496183206106835 85
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.496183206106835 101
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #6
root->8->15->2->1->4->10
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c5c0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2099236641221225 21
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.2862595419847125 34
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.3625954198473025 43
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4007633587785975 54
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.45801526717554 65
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5152671755724825 86
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5152671755724825 102
Completed Iteration #0
Best Reward: 0.0190839694656475
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5908> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.07633587786259 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.22900763358777 22
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.30534351145036 35
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.38167938931295 44
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.419847328244245 55
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.4770992366411875 66
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.53435114503813 87
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.53435114503813 103
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8cf8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.0954198473282375 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2480916030534175 23
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.3244274809160075 36
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4007633587785975 45
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4389312977098925 56
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.496183206106835 67
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5534351145037775 88
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5534351145037775 104
Completed Iteration #5
Best Reward: 0.0190839694656475
Completed Iteration #6
Best Reward: 0.0190839694656475
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd27eb8> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.0954198473282375 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2480916030534175 24
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.3244274809160075 37
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4007633587785975 46
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4389312977098925 57
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.496183206106835 68
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5534351145037775 89
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5534351145037775 105
Completed Iteration #9
Best Reward: 0.0190839694656475
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2860> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.0954198473282375 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2480916030534175 25
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.3244274809160075 38
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4007633587785975 47
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4389312977098925 58
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.496183206106835 69
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5534351145037775 90
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5534351145037775 106
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.114503816793885 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.267175572519065 26
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.343511450381655 39
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.419847328244245 48
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.45801526717554 59
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.5152671755724825 70
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.572519083969425 91
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.572519083969425 107
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Completed Iteration #20
Best Reward: 0.0190839694656475
coverage_call_count 4000
Completed Iteration #21
Best Reward: 0.0190839694656475
Completed Iteration #22
Best Reward: 0.0190839694656475
Completed Iteration #23
Best Reward: 0.0190839694656475
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #7
root->8->15->2->1->4->10->5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7940f0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.1335877862595325 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2862595419847125 27
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.3625954198473025 40
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4389312977098925 49
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4770992366411875 60
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.53435114503813 71
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5916030534350725 92
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5916030534350725 108
Completed Iteration #0
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.038167938931295 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.1335877862595325 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2862595419847125 28
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.3625954198473025 41
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4389312977098925 50
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4770992366411875 61
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.53435114503813 72
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5916030534350725 93
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5916030534350725 109
Completed Iteration #1
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.038167938931295 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.1335877862595325 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.2862595419847125 29
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.3625954198473025 42
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4389312977098925 51
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.4770992366411875 62
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.53435114503813 73
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.5916030534350725 94
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.5916030534350725 110
Completed Iteration #2
Best Reward: 0.0190839694656475
Completed Iteration #3
Best Reward: 0.0190839694656475
Completed Iteration #4
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e88d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7940f0> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.0572519083969425 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.15267175572518 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.30534351145036 30
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.38167938931295 43
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.45801526717554 52
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.496183206106835 63
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.5534351145037775 74
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.61068702290072 95
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.61068702290072 111
Completed Iteration #5
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb828> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc578d0> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.07633587786259 7
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.1717557251908275 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.3244274809160075 31
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.4007633587785975 44
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4770992366411875 53
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.5152671755724825 64
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.572519083969425 75
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.6297709923663675 96
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.6297709923663675 112
Completed Iteration #6
Best Reward: 0.0190839694656475
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.07633587786259 8
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.1717557251908275 15
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.3244274809160075 32
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.4007633587785975 45
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.4770992366411875 54
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.5152671755724825 65
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.572519083969425 76
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.6297709923663675 97
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.6297709923663675 113
Completed Iteration #7
Best Reward: 0.0190839694656475
Completed Iteration #8
Best Reward: 0.0190839694656475
Completed Iteration #9
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794278> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2518> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.0954198473282375 9
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.190839694656475 16
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.343511450381655 33
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.419847328244245 46
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.496183206106835 55
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.53435114503813 66
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.5916030534350725 77
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.648854961832015 98
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.648854961832015 114
Completed Iteration #10
Best Reward: 0.0190839694656475
Completed Iteration #11
Best Reward: 0.0190839694656475
Completed Iteration #12
Best Reward: 0.0190839694656475
Completed Iteration #13
Best Reward: 0.0190839694656475
Completed Iteration #14
Best Reward: 0.0190839694656475
Completed Iteration #15
Best Reward: 0.0190839694656475
Completed Iteration #16
Best Reward: 0.0190839694656475
Completed Iteration #17
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7ad630> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc578d0> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.114503816793885 10
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.2099236641221225 17
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.3625954198473025 34
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.4389312977098925 47
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.5152671755724825 56
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.5534351145037775 67
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.61068702290072 78
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.6679389312976625 99
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.6679389312976625 115
Completed Iteration #18
Best Reward: 0.0190839694656475
Completed Iteration #19
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e26d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7946d8> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.1335877862595325 11
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.22900763358777 18
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.38167938931295 35
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.45801526717554 48
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.53435114503813 57
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.572519083969425 68
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.6297709923663675 79
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.68702290076331 100
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.68702290076331 116
Completed Iteration #20
Best Reward: 0.0190839694656475
Completed Iteration #21
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7adf60> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794438> 0.0190839694656475 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.15267175572518 12
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.2480916030534175 19
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.4007633587785975 36
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.4770992366411875 49
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.5534351145037775 58
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.5916030534350725 69
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.648854961832015 80
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.7061068702289575 101
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.7061068702289575 117
Completed Iteration #22
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7b6470> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7946d8> 0.038167938931295 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.1717557251908275 13
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.267175572519065 20
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.419847328244245 37
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.496183206106835 50
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.572519083969425 59
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.61068702290072 70
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.6679389312976625 81
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.725190839694605 102
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.725190839694605 118
Completed Iteration #23
Best Reward: 0.0190839694656475
Reward: 0.0190839694656475
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7b6940> 0.0190839694656475 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7940f0> 0.0572519083969425 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.190839694656475 14
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08278> 0.2862595419847125 21
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222b0> 0.4389312977098925 38
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22780> 0.5152671755724825 51
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcd0eb8> 0.5916030534350725 60
backprop <src.mcts.MCTS_Node object at 0x7f7e6c719630> 0.6297709923663675 71
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcb5cf8> 0.68702290076331 82
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc84668> 0.7442748091602525 103
backprop <src.mcts.MCTS_Node object at 0x7f7dcbd510b8> 0.7442748091602525 119
Completed Iteration #24
Best Reward: 0.0190839694656475
Completed Iteration #25
Best Reward: 0.0190839694656475
Completed MCTS Level/Depth: #8
root->8->15->2->1->4->10->5->0
Best Reward: 0.0190839694656475
iteration: 111
found coverage increase 0.0190839694656475
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb4e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e87f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e20f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e23c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c3c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc085c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc005f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc005f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc005f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc31e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc00550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc312b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ea400a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc629e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 8.81679389312977
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc08438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7942e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb794cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc22f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 8.81679389312977
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc3c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcb7e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 4200
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc57cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc62e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc575f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7dcbcbc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7dcbc576d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 8.81679389312977
initial coverage: 8.58779
time passed (minutes): 60.288
iterations: 119
number of new inputs: 448
final coverage: 8.81679
total coverage increase: 0.229008
