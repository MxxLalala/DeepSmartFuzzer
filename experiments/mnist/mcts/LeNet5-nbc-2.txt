Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f3769db4f28>, tc2=<function tc2 at 0x7f3769dc5048>, tc3=<function tc3 at 0x7f3769dc5158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 7.82443
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41477f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41758d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41756d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41756d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e41757b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41151d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41256a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41396d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41471d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccd68> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc710> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0518> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40faa20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1780> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41395f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41395f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41395f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400eba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7912b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f37383346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f373828ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f37382ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e467f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f80fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f373828ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f373828ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7445f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e467f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f373828fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f930f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f930f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f930f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41157f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ef0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e06a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e415e940> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41756a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41759e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41750b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f76a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40faba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40430b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f72b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f72b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41476a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41476a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1701d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1133c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1133c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1133c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc183550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1839e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 20
Completed Iteration #21
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc400> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0385f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40930f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40930f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407acf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404bc18> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0114e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79eac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a05c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc038518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7742b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7740f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7747b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c760e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1834e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b70> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4043ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4147c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4147a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae160> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f373828ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e469e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e469e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e464ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41250f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7607f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7916a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e467f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ced68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7607f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e41394a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 1800
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41253c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41253c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41253c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41253c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc2e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40fadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7602e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7602e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e415e668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc038978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b407a588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 7.8244274809160315
coverage_call_count 2000
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0119b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cce10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0382e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0110b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0114e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0110b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0110b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e358> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 15
Completed Iteration #21
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40591d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40591d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40932b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40932b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f80f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4102b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4102b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f368a410ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4105c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1707f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0386d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1707f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689debe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689debe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689debbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d987f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d987f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d987f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d987f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d985c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885123c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d985c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885123c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885126a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3738334128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7877b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7877b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7873c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d982e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ad30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884efb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884efb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884efb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884efb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885128d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7601d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884984e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885128d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884984e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472080> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a431390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884295c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837caf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368843b2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885380b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885380b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837caeb8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e415e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b407ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e415e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc011160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a431e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689dfce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e401a438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521358> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40364e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4115278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc06dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4036518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885219b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b407a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885219b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4115f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e401ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885385c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885385c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f373828fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885385c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f373828fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f37383346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f37383347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b4059630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e464ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b40a0588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f37383347b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40e00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc0117f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f373828fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f373828fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e467f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e405a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e46b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e469e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4175a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd75ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a431710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41cecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f931d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4125e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41cecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4319e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4319e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f931d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3735f931d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41cecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a208> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e400e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7d87f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e401a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688538cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c774d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e400eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368843bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e405a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc01eda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3738334a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd75a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc011f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b898> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc01ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884291d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884291d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 20
Completed Iteration #20
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aec88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884e1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884ef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 10
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36884ef128> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884297b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884295c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884295c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884297b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4125278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7ae048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689dfc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e400e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c774e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368843bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bc710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4175be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885127f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d989b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 3200
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b4093ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0ea908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689d98ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884294a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd7912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884294a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368841d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c774908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36885383c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688521898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688538f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 3300
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a41f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0384a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc038198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bc1702e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689debc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4036978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688512860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd76a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c787e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368a410e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36885122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884298d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884986a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884986a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837ddbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837dd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822cae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822cae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc09c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822cae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4147128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 3500
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a41fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688498588> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689d987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36837dd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd744940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c760978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36837dd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f369c79e898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682293518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822934a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc0eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36822932b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688429438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822a26a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d400> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d390> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688429438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368224fc50> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822023c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36b404b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822023c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822023c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368844df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822dc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822dc208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682271588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368225d780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a4317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b404ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368844d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682293358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc07b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3735f93358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e41477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36b40a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688498630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a4316d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368848a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822027b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822710b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822027b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822710b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822026a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3800
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681df3828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d422b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d427b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368225dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688521ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d426a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d427b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d566d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822a2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688498c88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 2
Completed Iteration #2
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f368223cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d190b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368841d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d084a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d08400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d08390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689ddb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688498630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d08710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681df3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da9630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682271cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d42320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681da9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368225dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682293cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ddf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c79e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd76ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cfc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681da96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e4043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681df3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d197f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d193c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d9a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681cd6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681ce7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d193c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d19da0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c69400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c69a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688512eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c425c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc0bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bd7915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f369c760390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d565f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c42748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c42cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 4200
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d56b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3682202a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368223c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c42da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681dc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d19160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c90e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681d190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681d19d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822caf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822caf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822caa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36837dd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3682202780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 7.8244274809160315
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc183dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36884729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc144a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc1836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c787908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c7876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689debb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc144438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36837dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368a410940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36e40ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36bc183748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc170f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36e40cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc1706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368a410668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 7.8244274809160315
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36884726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f369c760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3682202c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368223c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368224f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3689deb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f36822ca198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3688472fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36822cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3689deb240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f368845c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368845c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f36822ca198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f36bc113dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f368224fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681dc9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681d569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f3681c904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f3688472a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f3681c56e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 7.8244274809160315
initial coverage: 7.82443
time passed (minutes): 60.0981
iterations: 168
number of new inputs: 0
final coverage: 7.82443
total coverage increase: 0
