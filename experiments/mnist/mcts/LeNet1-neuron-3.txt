Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f63d2774f28>, tc2=<function tc2 at 0x7f63d2785048>, tc3=<function tc3 at 0x7f63d2785158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 41.6667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390006240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae10> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390006390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f0828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684c88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 300
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806842e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806626a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707cec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 8
Completed Iteration #12
Best Reward: 0
coverage_call_count 400
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806624e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d79e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707945f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707024e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707240f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707240f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707240f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707240f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707240f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900640b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63ef04cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639007e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900640b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63ef04ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900758d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900758d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639007e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900640b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707020f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707020f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707020f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707020f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63ef04c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639007e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639007e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63ef04cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806749e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806624e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab160> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900643c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638074bfd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639007e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 900
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806976a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806976a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073ae48> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63ef04cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639007e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639007e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639007e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638073a438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701198d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701196a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63701026d8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707247f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700defd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700dedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700defd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700dedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 1200
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700523c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700525f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700525f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700523c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ade80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700526a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f9e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637006ab70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6328017860> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900649e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328027dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0898> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700add30> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a857b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a857b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a857b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1ddd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280273c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280273c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280273c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63ef04c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c29b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639000f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f639000f8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380784898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638074b780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806840b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700defd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700defd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 1800
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390006dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806abf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638072a978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390006320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bacf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639004aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071ce80> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700decc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702710> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e9998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e9998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac42b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2000
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707946d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639007e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e9995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e9993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700715f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280176a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280176a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280179e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280179e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280179e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700716d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370071128> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a90> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280170b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280170b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701196d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701196d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638079c588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701025f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3240> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a859e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f632807da90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700d1b00> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d6d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f632807dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c5f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3147080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31475c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31475c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f1d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d312c470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701194a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312c278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 2700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d308c748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d311ca90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31550f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637003f1d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280278d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280278d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 16
Completed Iteration #24
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4208> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639006ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63701024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31557b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866be48> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d866b0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30572b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30572b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63707027f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3000
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638071c7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707149b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707149b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ba320> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639000f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380784080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6380697208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3155550> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0c74b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700de518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30402e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c20b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2908> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc88> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a854e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31aad68> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 3500
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380784240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30030f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30030f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23566a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23566a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23679b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23563c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23561d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d234bac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23004e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308cba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0ac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 14
Completed Iteration #21
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b358> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d226b6d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22052b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22267f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22181d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22181d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23304e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23304e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23304e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1deffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1deff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1deffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22464a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22464a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22465f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d738d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d736a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d736a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 4200
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22460b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73630> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f632807de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc57f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23565c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2392320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63280175f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23924a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700710b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700710b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700710b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63700a0160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0c74b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380697c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637006aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370071470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370724278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 4500
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806abda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806abda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707248d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806740b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d368d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4600
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900641d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63900641d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707cee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d312ca58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390006320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3155fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3155518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d309c7f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638072a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31557b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d209b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ceb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d866b2e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233fcf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d308c400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f639e999630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702630> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23005f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a852e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d866b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22465f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 5000
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22460b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22465f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d3003c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23302e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23304a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23302e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23309e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 5100
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d308c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2330630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f894a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d474e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d2218e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22187b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 5400
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e917f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e917f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e917f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e917f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5500
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba0f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f352e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f217b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f217b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e015f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e012b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e010b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bfd0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 16
Completed Iteration #21
Best Reward: 0
coverage_call_count 5600
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09daef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09475c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09475c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0e017f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09baba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09baba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09baba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 5800
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09249e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09244a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09359b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09240f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09242e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09240f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 5900
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09242e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09242e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09240f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0924240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d09a86a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08984e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370724668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3155d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc208> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09badd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09badd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbe48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09dab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2356e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e91d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e912e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e912e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e100b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09f73c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09471d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01208> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0947198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f355c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f216a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f215c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638072ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f215c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e10a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecde48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2356748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d095bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328027d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d47be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328027ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f435f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f637f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2205f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f637f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f216a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2226668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234ba90> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22464a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d311cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d2246278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1def668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0eba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22464a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2226e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2246fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d311c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d234bba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2205f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09bad30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23670f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d226b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e91748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a9e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2367d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d22b70b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f35c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ebac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2246908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229cda0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3040eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3057668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30579e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3057a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3003828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30034e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d234b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30034e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a1de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0edb4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d233f390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638074b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d226bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a85c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 6600
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d23677f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370102320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370714710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ecd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380674978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701029e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63807f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638075b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380674be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700adac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d308ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638075bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63807f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2300b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707ce550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d312cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390075f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d233f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63900754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806ab2e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d234b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d319c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0947f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d233f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1deff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d229c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1deff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 6700
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1deff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6390064eb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63701198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380684320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806977f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637073cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637073cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300ad6898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370052e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370119080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637006aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0c747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370052550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700de668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700deb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638073a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c24a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370119e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d866b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2300da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806977f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ac47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637073cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638063f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63700712b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d30e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6300a2c9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d095b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370102cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300ac49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63280175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d309c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6300ac49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1defc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f63be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d73828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d309c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63806847f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31472e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31472e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d31479b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707e3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d366a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d366a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36780> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d36668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d319c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637074a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2392be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6328017a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707249e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d5f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638073a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f51ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63707021d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d312c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0935400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0975208> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d30034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09355c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0975d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63700522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63707ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09355c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e01438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2392438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370714160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d228fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31474a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31474a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31474a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22185f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d310f4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0c25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6390064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1d20d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cd9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d229c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d228f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22183c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d306e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23305c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23305c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d1dfde10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 7100
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f632807de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08980b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d306ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d2330b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638071c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0924828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e1fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d23677b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f514e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d23677b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d31edb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898748> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d1de1e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d22180f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a524a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b780> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08986d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7300
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a384e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d23308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ceb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d59e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0935c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a388d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358ab00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b55c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0975cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b4e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d1cc5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b128> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3500588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c350c208> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2330b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08986d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3500e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08986d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3500240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35007f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c358aeb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34922b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c358a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34dae10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34449e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34927b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 7
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3444d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3416fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c34445f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c3428a20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34da0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c346ef28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3492f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3492828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 307
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3aa1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c358a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a7bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6300ab3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c351e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c351e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3456128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a2c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 308
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3428eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c346eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3428b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3492588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 309
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d066d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d066d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d066d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f390> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 310
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 7
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d06a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2de3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d16358> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 311
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c350c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3416ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3416e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3500400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c346ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2da2a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 312
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3456668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3435ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d6ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3435320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2dbf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d93668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d169b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd92b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2d2ce80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 313
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2c922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2c92470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd09f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63806ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c2cd9e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 314
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6328017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 8100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6328017d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6370794b70> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 315
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35429e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b58d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 316
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f638079c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 317
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d09a89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 8200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f638079c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 318
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d3147208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a52668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f639e999278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34445c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3542cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d3147978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 319
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d31477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a38d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 320
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c2cfb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c359bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d2218390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 321
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d09a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0898d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 8300
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6380662a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0898d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08e0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d22185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 322
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d08981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c34446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6370702940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c34443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3444da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c35b5588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c359bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62c3a88ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3a6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3444b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62d0ea5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d08a6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c3542240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0f89198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62c35e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62d0e4bf28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 323
found coverage increase 0
Current Total Coverage 41.66666666666667
initial coverage: 41.6667
time passed (minutes): 60.1607
iterations: 324
number of new inputs: 0
final coverage: 41.6667
total coverage increase: 0
