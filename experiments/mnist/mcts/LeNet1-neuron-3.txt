Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fcadceacf28>, tc2=<function tc2 at 0x7fcadcebb048>, tc3=<function tc3 at 0x7fcadcebb158>, tfc_threshold=33000000, time_period=3600, verbose=True)
initial coverage: 41.6667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98146c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98146c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980cba20> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980809b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980188d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980188d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980188d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cb8d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 300
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca980cb208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798710> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907438d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907438d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907437b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907437b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907430b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907430b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907079e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071af60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906f7390> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906f7160> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98146c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98146128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684dd8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98146128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 4
Completed Iteration #7
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9814d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c85f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98146c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981bef28> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907568d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90756b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca980cbc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907436d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907433c8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907566a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907566a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907566a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907566a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907bcda0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 1000
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072fcc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98780668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f27b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907439b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906992b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906992b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064aba8> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ac8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237deba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237608d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806684a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237d2128> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237384e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237383c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237383c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237383c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23721588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237382b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236cca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237214e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237214e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237214e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237214e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca23721ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc88> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365f5c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907077b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981a6748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a66d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064af28> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980805c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b048> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa91c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa90d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa90d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907436a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907436a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90798160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f7f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa91c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2000
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237216d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236902e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721160> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b26a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b26a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907434e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca8063ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806e67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374d2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237382b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237382b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90699dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237387f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 2300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01e22fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35240> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01da24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d351d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01db0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d354a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c702b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c532e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c532e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c314e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d354a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 2900
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78ba58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01d35828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1898> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 3000
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23784a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806f2eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 9
Completed Iteration #18
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237755f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806689b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806689b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806689b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981aa710> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9814d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 3200
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906995c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237754e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca907c8198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca981b4fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237216d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907070f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237216d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907070f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980a2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90756978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980805f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237210f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237210f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237210f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806b1128> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3500
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa914e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9806b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c537f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c537f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bda20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f1d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa914e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd15f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c70748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c534a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c534a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c534a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd19e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23738e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23738358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 3800
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fbe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c536a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c536a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6a0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43795c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379390> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43486d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43210f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43210f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43212e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43218d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d451d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 4200
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cec50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422acf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 4400
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c538d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c538d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90684cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf320> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 4
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1e10> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907569e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 4500
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907569e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca2366f0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a20f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2367d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfadd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca2366fba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa914e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23775b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90743c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8064a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980dfcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9818cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980df668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907981d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907bc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca806682e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cd14a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9806b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907a99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca2365fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2366f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237dee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d357f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d357f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9071a208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237def98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237def98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237213c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981aa8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d355c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bc18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ceef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e227b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236dd7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaf8fefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43487b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ef28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b04e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43797f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43798d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43798d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 5
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cdd8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 5200
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f85f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43045f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43045f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b02e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237386a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f24a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237389e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8063b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b83c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6198> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42874a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2066a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2061d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2061d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2061d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2069b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2069b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed825c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed827b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed827b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed825c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed979b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cdd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2767f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4048> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30908> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec922b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec929e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec924e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec924e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec929e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec924e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec927b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec927b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec926a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec926a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec926a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec927b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba58> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 5900
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec774a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec774a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec774a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec224e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 6000
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec228d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7892b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7892b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7892b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec225f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec229b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec225f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec225f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec229e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec229e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ac50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fcaa909a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7890b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237d2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbffd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23721a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca237211d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6300
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2062b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23738b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01db0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01db0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321198> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed82cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c9eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed978d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca236dd5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d8fd30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec9fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca236dd470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43048d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43046d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43048d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d06a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4287fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23721a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f438db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca9072f400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce7b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed4d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806e67f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806f2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42ce0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4304128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc7e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01e229e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907e6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 6700
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98018160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9807c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca23784a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5ea3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90756940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2366f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2007d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23690710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9808feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23690080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98018588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23775b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9072fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 7
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2365f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2365f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 8
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 9
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 10
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 11
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecdb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01dc1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237bc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef22dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca806b15c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98080b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c319b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f439ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237de668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cfab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c319b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca9071aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907c8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c53978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d455f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cdfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d455f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cdf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01da2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d455f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45a90> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01d45d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca01d45ef0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9071afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9805f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f424ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01cfa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef206a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f43b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecbfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca806b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79fe48> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01ddbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca8063bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fca981b42b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42058d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42058d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c70828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fb70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c70d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c700b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23760160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2007dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc77c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2b8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca2374d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237f10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef218ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5e6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9fc79f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98080160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2367da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01e22e80> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01da2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2186a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981b4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9fc78b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f422a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6780> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4348ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 7100
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90743ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9808f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f421c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fcaa90a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca98137b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca98137a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5ae10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec920f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec929e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec929e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f422af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef24f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca980a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2765c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f425ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca906f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca01c31828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc22e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed306a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca90798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec803c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca237758d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec802e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec802e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca981376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed7c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9f28> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4321a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec227f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d45f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca9807c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f4205710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedc2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2a7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01d35b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9570b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957080> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec77f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01cd16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f421cb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eedf47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca90699b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed30160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca236a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9249e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9249e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9249e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9247b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9247b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9247b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9008d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed6c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca907989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fca906f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eecc2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef276eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b550> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f423f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f42050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9f42050f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b64e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca23784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca01c31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed957550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8dda90> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ef2f23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8282e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8282e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca80668cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80ee80> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca8064a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ee74f128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8281d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee7e96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 7800
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8973c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fca2374d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed87c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3924e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b40f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ee76b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b40f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b40f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b45f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed897f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ec18> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 307
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 308
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fac50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 309
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3390f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3714e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed970208> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 310
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 311
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eed5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3714e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed828dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 312
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9eec22828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 313
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2904e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2905f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2905f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2905f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 314
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 8100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed86f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed80e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 315
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9f5eb72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3397f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed93ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 316
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 317
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2752b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2753c8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 318
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed924908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 8200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8285c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8285c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2663c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 319
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed900c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31fcc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 320
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed290048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed9000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 321
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2cf8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 322
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2139e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 8300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed392d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2909e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2909e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2909e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed34e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2139e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed8cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed371e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed35d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 323
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed339cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbd6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbc2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2750f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2750f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed213da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed275128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed31f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed266390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed2b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fc9ecbf9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fc9ed3b4048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fc9ed29e2b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 324
found coverage increase 0
Current Total Coverage 41.66666666666667
initial coverage: 41.6667
time passed (minutes): 60.0267
iterations: 325
number of new inputs: 0
final coverage: 41.6667
total coverage increase: 0
