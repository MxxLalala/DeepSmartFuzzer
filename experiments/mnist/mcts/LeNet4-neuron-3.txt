Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fd189c88f28>, tc2=<function tc2 at 0x7fd189c97048>, tc3=<function tc3 at 0x7fd189c97158>, tfc_threshold=3300000, time_period=3600, verbose=True)
initial coverage: 69.0141
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14012ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ece80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ece80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400d52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ece80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 12
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400131d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400654e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14012ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad400> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13074d668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd130725278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306bebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 500
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e75f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306bebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd15821eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd158243240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140148f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140148f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400137f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14012ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14016a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14016a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14016a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14016a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14016a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14016a2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400134e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140156160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401562b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1501270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140156128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140148e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400651d0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140065e80> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd158243240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140148e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140148e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13073bf28> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 69.01408450704226
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140156208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140156208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1401567f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725860> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14016a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14016a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1501270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13069ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307144e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140163b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307144e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307140b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130714080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307147f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 1000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0e80> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1dfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b07f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 9
Completed Iteration #14
Best Reward: 0
coverage_call_count 1100
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106929e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e7f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106566a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106664a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106664a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00638d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00638d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00206d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00206d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063860> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78545c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78545c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00951d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00951d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00951d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00951d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78397b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78398d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78614e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78544e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78544e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78397f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3340f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3340f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307ada58> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3019b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14016a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3019b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3019b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ccf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00209e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00209e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 69.01408450704226
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 1700
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00950b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd11067ecc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 69.01408450704226
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.7042253521126725 10
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.7042253521126725 11
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.7042253521126725 12
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.7042253521126725 13
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 0.7042253521126725 6
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.7042253521126725 14
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 0.7042253521126725 15
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 1.408450704225345 16
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 1.408450704225345 17
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 1.408450704225345 18
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.1126760563380174 10
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.1126760563380174 19
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.1126760563380174 11
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.1126760563380174 20
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.1126760563380174 12
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.1126760563380174 21
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.1126760563380174 13
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.1126760563380174 22
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.81690140845069 14
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.81690140845069 23
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.81690140845069 15
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.81690140845069 24
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.81690140845069 16
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.81690140845069 25
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.81690140845069 17
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.81690140845069 26
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 2.81690140845069 18
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 2.81690140845069 27
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd150117e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 3.5211267605633623 19
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 3.5211267605633623 28
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 4.225352112676035 20
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 4.225352112676035 29
Completed Iteration #19
Best Reward: 0.7042253521126725
coverage_call_count 1800
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd150117be0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 4.929577464788707 21
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 4.929577464788707 30
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 4.929577464788707 22
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 4.929577464788707 31
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117be0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 4.929577464788707 23
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 4.929577464788707 32
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 5.63380281690138 24
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 5.63380281690138 33
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd155faa080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 6.338028169014052 25
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 6.338028169014052 34
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd11064aef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0978> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0630> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 7.0422535211267245 26
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 7.0422535211267245 35
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd150117940> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 7.0422535211267245 11
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 7.746478873239397 27
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 7.746478873239397 36
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 7.746478873239397 28
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 7.746478873239397 37
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117940> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0550> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 4.929577464788707 8
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 8.45070422535207 29
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 8.45070422535207 38
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 5.63380281690138 9
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 8.45070422535207 14
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 9.154929577464742 30
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 9.154929577464742 39
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd130725668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 9.154929577464742 15
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 9.859154929577414 31
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 9.859154929577414 40
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064aef0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0978> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0630> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 9.859154929577414 32
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 9.859154929577414 41
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd14007f4a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 6.338028169014052 10
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 10.563380281690087 33
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 10.563380281690087 42
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117e48> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 6.338028169014052 11
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 9.859154929577414 18
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 10.563380281690087 34
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 10.563380281690087 43
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 7.0422535211267245 12
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 10.563380281690087 19
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 11.26760563380276 35
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 11.26760563380276 44
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd14009e278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 7.746478873239397 13
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 11.26760563380276 20
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 11.971830985915432 36
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 11.971830985915432 45
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117940> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0550> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 7.746478873239397 14
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 11.26760563380276 21
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 11.971830985915432 37
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 11.971830985915432 46
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f4a8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 8.45070422535207 15
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 11.971830985915432 22
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 12.676056338028104 38
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 12.676056338028104 47
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 9.154929577464742 16
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 12.676056338028104 23
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 13.380281690140777 39
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 13.380281690140777 48
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd11064af28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065dd8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd150117940> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0550> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 9.859154929577414 17
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 14.084507042253449 40
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 14.084507042253449 49
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1501179b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 10.563380281690087 18
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 14.084507042253449 25
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 14.788732394366122 41
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 14.788732394366122 50
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->18->8
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1400137f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c18> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 11.26760563380276 19
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 14.788732394366122 26
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 15.492957746478794 42
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 15.492957746478794 51
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 11.971830985915432 20
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 15.492957746478794 27
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 16.197183098591466 43
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 16.197183098591466 52
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.225352112676035 7
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 12.676056338028104 21
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.197183098591466 28
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 16.90140845070414 44
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 16.90140845070414 53
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7518> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0c18> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 12.676056338028104 22
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.197183098591466 29
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 16.90140845070414 45
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 16.90140845070414 54
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd13069e390> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0cf8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 9
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 23
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 30
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 46
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 55
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0cf8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 24
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 31
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 47
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 56
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 25
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 32
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 48
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 57
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0cf8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 26
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 33
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 49
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 58
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->18->8->1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4b38> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 27
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 34
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 50
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 59
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 35
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 51
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 60
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 15
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 29
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 52
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 61
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 16
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 30
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 53
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 62
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 13.380281690140777 31
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 16.90140845070414 38
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 17.60563380281681 54
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 17.60563380281681 63
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 2.1126760563380174 9
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 5.63380281690138 18
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 17.60563380281681 39
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 18.309859154929484 55
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 18.309859154929484 64
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1106f01d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0a90> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b38> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 2.81690140845069 10
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 6.338028169014052 19
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 14.788732394366122 33
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 18.309859154929484 40
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 19.014084507042156 56
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 19.014084507042156 65
Completed Iteration #20
Best Reward: 0.7042253521126725
coverage_call_count 1900
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 2.81690140845069 11
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 6.338028169014052 20
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 18.309859154929484 41
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 19.014084507042156 57
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 19.014084507042156 66
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->18->8->1->2
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0a90> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b38> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 7.0422535211267245 21
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 19.014084507042156 42
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 19.71830985915483 58
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 19.71830985915483 67
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 3.5211267605633623 13
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 7.0422535211267245 22
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 15.492957746478794 36
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 19.014084507042156 43
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 19.71830985915483 59
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 19.71830985915483 68
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 3.5211267605633623 14
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 7.0422535211267245 23
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 15.492957746478794 37
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 19.014084507042156 44
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 19.71830985915483 60
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 19.71830985915483 69
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 3.5211267605633623 15
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 7.0422535211267245 24
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 15.492957746478794 38
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 19.014084507042156 45
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 19.71830985915483 61
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 19.71830985915483 70
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095ba8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b8d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f01d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0a90> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b38> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 4.225352112676035 16
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 7.746478873239397 25
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 16.197183098591466 39
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 19.71830985915483 46
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 20.4225352112675 62
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 20.4225352112675 71
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 4.929577464788707 17
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 8.45070422535207 26
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 16.90140845070414 40
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 20.4225352112675 47
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 21.126760563380174 63
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 21.126760563380174 72
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 4.929577464788707 18
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 8.45070422535207 27
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 16.90140845070414 41
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 20.4225352112675 48
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 21.126760563380174 64
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 21.126760563380174 73
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->18->8->1->2->4
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 4.225352112676035 12
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 4.929577464788707 19
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 8.45070422535207 28
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 16.90140845070414 42
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 20.4225352112675 49
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 21.126760563380174 65
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 21.126760563380174 74
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 5.63380281690138 20
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 9.154929577464742 29
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 17.60563380281681 43
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 21.126760563380174 50
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 21.830985915492846 66
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 21.830985915492846 75
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 5.63380281690138 21
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 9.154929577464742 30
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 17.60563380281681 44
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 21.126760563380174 51
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 21.830985915492846 67
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 21.830985915492846 76
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd13069e550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 6.338028169014052 22
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 9.859154929577414 31
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 18.309859154929484 45
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 21.830985915492846 52
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 22.53521126760552 68
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 22.53521126760552 77
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1306f03c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 7.0422535211267245 23
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 10.563380281690087 32
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 19.014084507042156 46
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 22.53521126760552 53
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 23.23943661971819 69
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 23.23943661971819 78
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 7.0422535211267245 24
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 10.563380281690087 33
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 19.014084507042156 47
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 22.53521126760552 54
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 23.23943661971819 70
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 23.23943661971819 79
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e550> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 6.338028169014052 18
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 7.0422535211267245 25
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 10.563380281690087 34
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 19.014084507042156 48
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 22.53521126760552 55
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 23.23943661971819 71
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 23.23943661971819 80
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 7.0422535211267245 19
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 7.746478873239397 26
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 11.26760563380276 35
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 19.71830985915483 49
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 23.23943661971819 56
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 23.943661971830863 72
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 23.943661971830863 81
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd1106667b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 7.746478873239397 20
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 8.45070422535207 27
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 11.971830985915432 36
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 20.4225352112675 50
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 23.943661971830863 57
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 24.647887323943536 73
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 24.647887323943536 82
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 9.154929577464742 28
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 12.676056338028104 37
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 21.126760563380174 51
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 24.647887323943536 58
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 25.35211267605621 74
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 25.35211267605621 83
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b74e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 9.859154929577414 29
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 13.380281690140777 38
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 21.830985915492846 52
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 25.35211267605621 59
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 26.05633802816888 75
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 26.05633802816888 84
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->18->8->1->2->4->7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 9.154929577464742 23
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 9.859154929577414 30
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 13.380281690140777 39
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 21.830985915492846 53
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 25.35211267605621 60
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 26.05633802816888 76
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 26.05633802816888 85
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 9.859154929577414 24
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 10.563380281690087 31
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 14.084507042253449 40
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 22.53521126760552 54
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 26.05633802816888 61
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 26.760563380281553 77
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 26.760563380281553 86
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854eb8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 6.338028169014052 16
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 10.563380281690087 32
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 14.084507042253449 41
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 22.53521126760552 55
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 26.05633802816888 62
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 26.760563380281553 78
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 26.760563380281553 87
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7668> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 11.26760563380276 33
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 14.788732394366122 42
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 23.23943661971819 56
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 26.760563380281553 63
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 27.464788732394226 79
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 27.464788732394226 88
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef60> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 3.5211267605633623 11
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 10.563380281690087 27
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 11.26760563380276 34
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 14.788732394366122 43
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 23.23943661971819 57
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 26.760563380281553 64
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 27.464788732394226 80
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 27.464788732394226 89
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f03c8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d003be80> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 3.5211267605633623 12
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 7.0422535211267245 19
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 10.563380281690087 28
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 11.26760563380276 35
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 14.788732394366122 44
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 23.23943661971819 58
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 26.760563380281553 65
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 27.464788732394226 81
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 27.464788732394226 90
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecdd8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 4.225352112676035 13
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 7.746478873239397 20
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 11.26760563380276 29
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 11.971830985915432 36
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 15.492957746478794 45
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 23.943661971830863 59
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 27.464788732394226 66
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 28.169014084506898 82
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 28.169014084506898 91
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301240> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f28> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 11.971830985915432 30
backprop <src.mcts.MCTS_Node object at 0x7fd1400b07f0> 12.676056338028104 37
backprop <src.mcts.MCTS_Node object at 0x7fd11064a908> 16.197183098591466 46
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab70> 24.647887323943536 60
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 28.169014084506898 67
backprop <src.mcts.MCTS_Node object at 0x7fd0d00200b8> 28.87323943661957 83
backprop <src.mcts.MCTS_Node object at 0x7fd0d00204a8> 28.87323943661957 92
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->18->8->1->2->4->7->3
Best Reward: 0.7042253521126725
iteration: 68
found coverage increase 0.7042253521126725
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 2000
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00635f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106927f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106927f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00635f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110692b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78197f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78197f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 2100
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3344e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78394e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106927f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106927f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87190b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3414a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78395c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3416d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106560b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00638d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86980f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ada90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78193c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ffd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ea90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86982e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86982e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707048> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81019e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81016a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81019e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81016a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba58> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698438> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b81202e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3860> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325748> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78199b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78192e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78199b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78192e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106924e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3518> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd155faa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1501179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 3000
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f048> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e76d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd13068b940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 3100
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140156358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11064a940> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1401513c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307654e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307654e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b04a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140163f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 2
Completed Iteration #3
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106662b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0ef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cfd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150117d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd155faa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87079e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140065d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87076a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020dd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b39b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00201d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b6a0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ccc0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86705c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 3700
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86705c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81010f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79832e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79834e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ecc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067e780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79772b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79772b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79772b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79774e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79254e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 69.71830985915493
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85086d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85336a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85336a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 4000
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 69.71830985915493
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.7042253521126725 14
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.7042253521126725 15
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 0.7042253521126725 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.7042253521126725 16
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.7042253521126725 17
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e89e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.7042253521126725 18
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #0
root
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 0.7042253521126725 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 0.7042253521126725 19
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533048> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b9e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 20
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 21
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 22
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 23
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 24
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 25
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 1.408450704225345 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 1.408450704225345 26
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 27
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 28
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 29
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 30
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 31
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 32
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 33
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.1126760563380174 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.1126760563380174 34
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e780> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b9e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.81690140845069 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.81690140845069 35
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.81690140845069 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.81690140845069 36
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b9e8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 2.81690140845069 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 2.81690140845069 37
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b128> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 3.5211267605633623 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 3.5211267605633623 38
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 4.225352112676035 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 4.225352112676035 39
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d550> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847ddd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 4.929577464788707 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 4.929577464788707 40
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa2b0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 5.63380281690138 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 5.63380281690138 41
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 5.63380281690138 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 5.63380281690138 42
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533048> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b9e8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 5.63380281690138 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 5.63380281690138 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 5.63380281690138 43
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa2b0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b978> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 5.63380281690138 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 5.63380281690138 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 5.63380281690138 44
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aabe0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533208> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 6.338028169014052 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 6.338028169014052 45
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2208> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 7.0422535211267245 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 7.0422535211267245 46
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #2
root->6->18
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533208> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 7.0422535211267245 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 7.0422535211267245 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 7.0422535211267245 47
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d550> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847ddd8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 7.0422535211267245 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 7.0422535211267245 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 7.0422535211267245 48
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2208> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 4.225352112676035 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 7.0422535211267245 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 7.0422535211267245 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 7.0422535211267245 49
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa0f0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aabe0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533208> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 2.81690140845069 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 7.746478873239397 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 7.746478873239397 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 7.746478873239397 50
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977da0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b128> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533208> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 8.45070422535207 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 8.45070422535207 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 8.45070422535207 51
Completed Iteration #10
Best Reward: 0.7042253521126725
coverage_call_count 4100
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 9.154929577464742 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 9.154929577464742 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 9.154929577464742 52
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2f28> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 9.859154929577414 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 9.859154929577414 53
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2828> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84473c8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2080> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 7.746478873239397 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 10.563380281690087 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 10.563380281690087 54
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447278> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2208> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 11.26760563380276 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 11.26760563380276 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 11.26760563380276 55
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 11.971830985915432 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 11.971830985915432 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 11.971830985915432 56
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2208> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 12.676056338028104 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 12.676056338028104 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 12.676056338028104 57
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977da0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b128> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533208> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d30> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 10.563380281690087 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 13.380281690140777 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 13.380281690140777 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 13.380281690140777 58
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2080> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 13.380281690140777 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 13.380281690140777 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 13.380281690140777 59
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #3
root->6->18->0
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 14.084507042253449 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 14.084507042253449 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 14.084507042253449 60
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2f28> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 14.084507042253449 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 14.084507042253449 61
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 11.971830985915432 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 14.788732394366122 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 14.788732394366122 62
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447dd8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447320> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 4.929577464788707 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 12.676056338028104 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 15.492957746478794 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 15.492957746478794 63
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 12.676056338028104 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 15.492957746478794 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 15.492957746478794 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 15.492957746478794 64
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847ddd8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 16.197183098591466 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 16.197183098591466 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 16.197183098591466 65
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847ddd8> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 16.90140845070414 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 16.90140845070414 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 16.90140845070414 66
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 7.0422535211267245 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 14.788732394366122 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 17.60563380281681 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 17.60563380281681 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 17.60563380281681 67
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ef60> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ec18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 7.746478873239397 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 15.492957746478794 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 18.309859154929484 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 18.309859154929484 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 18.309859154929484 68
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 15.492957746478794 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 18.309859154929484 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 18.309859154929484 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 18.309859154929484 69
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #4
root->6->18->0->4
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 3.5211267605633623 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 16.197183098591466 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 19.014084507042156 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 19.014084507042156 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 19.014084507042156 70
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 8.45070422535207 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 16.197183098591466 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 19.014084507042156 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 19.014084507042156 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 19.014084507042156 71
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447b00> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447cc0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 16.90140845070414 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 19.71830985915483 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 19.71830985915483 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 19.71830985915483 72
Completed Iteration #4
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 9.154929577464742 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 16.90140845070414 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 19.71830985915483 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 19.71830985915483 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 19.71830985915483 73
Completed Iteration #5
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 9.154929577464742 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 19.71830985915483 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 19.71830985915483 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 19.71830985915483 74
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84730b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84734e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 9.859154929577414 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 17.60563380281681 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 20.4225352112675 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 20.4225352112675 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 20.4225352112675 75
Completed Iteration #10
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84739e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e5f8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 10.563380281690087 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 18.309859154929484 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 21.126760563380174 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 21.126760563380174 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 21.126760563380174 76
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473d30> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa208> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 19.014084507042156 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 21.830985915492846 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 21.830985915492846 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 21.830985915492846 77
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447cc0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 6.338028169014052 14
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 11.26760563380276 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 19.014084507042156 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 21.830985915492846 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 21.830985915492846 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 21.830985915492846 78
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1240> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 7.0422535211267245 15
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 11.971830985915432 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 19.71830985915483 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 22.53521126760552 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 22.53521126760552 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 22.53521126760552 79
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1898> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 7.746478873239397 16
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 12.676056338028104 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 20.4225352112675 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 23.23943661971819 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 23.23943661971819 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 23.23943661971819 80
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e10> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 8.45070422535207 17
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 13.380281690140777 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 21.126760563380174 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 23.943661971830863 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 23.943661971830863 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 23.943661971830863 81
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447b70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e48> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1240> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 9.154929577464742 18
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 14.084507042253449 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 21.830985915492846 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 24.647887323943536 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 24.647887323943536 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 24.647887323943536 82
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84730b8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84734e0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b630> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 9.154929577464742 19
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 14.084507042253449 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 21.830985915492846 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 24.647887323943536 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 24.647887323943536 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 24.647887323943536 83
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #5
root->6->18->0->4->1
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473d68> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 9.859154929577414 20
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 14.788732394366122 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 22.53521126760552 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 25.35211267605621 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 25.35211267605621 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 25.35211267605621 84
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473d68> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 9.859154929577414 21
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 14.788732394366122 32
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 22.53521126760552 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 25.35211267605621 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 25.35211267605621 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 25.35211267605621 85
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846efd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 3.5211267605633623 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 10.563380281690087 22
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 15.492957746478794 33
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 23.23943661971819 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 26.05633802816888 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 26.05633802816888 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 26.05633802816888 86
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb70> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcef0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb38> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846efd0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.225352112676035 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.26760563380276 23
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.197183098591466 34
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 23.943661971830863 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 26.760563380281553 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 26.760563380281553 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 26.760563380281553 87
Completed Iteration #13
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e48> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1240> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.225352112676035 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.26760563380276 24
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.197183098591466 35
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 23.943661971830863 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 26.760563380281553 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 26.760563380281553 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 26.760563380281553 88
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846efd0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.26760563380276 25
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.197183098591466 36
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 23.943661971830863 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 26.760563380281553 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 26.760563380281553 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 26.760563380281553 89
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fef0b8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb70> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcef0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb38> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846efd0> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.971830985915432 26
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.90140845070414 37
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 24.647887323943536 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 27.464788732394226 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 27.464788732394226 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 27.464788732394226 90
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6eb8> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb70> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcef0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb38> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a846efd0> 2.1126760563380174 6
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.971830985915432 27
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.90140845070414 38
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 24.647887323943536 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 27.464788732394226 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 27.464788732394226 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 27.464788732394226 91
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.929577464788707 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.971830985915432 28
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.90140845070414 39
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 24.647887323943536 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 27.464788732394226 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 27.464788732394226 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 27.464788732394226 92
Completed Iteration #22
Best Reward: 0.7042253521126725
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #6
root->6->18->0->4->1->10
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 2.1126760563380174 7
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.929577464788707 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.90140845070414 40
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 24.647887323943536 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 27.464788732394226 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 27.464788732394226 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 27.464788732394226 93
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1240> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 2.1126760563380174 8
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 4.929577464788707 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 11.971830985915432 30
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 16.90140845070414 41
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 24.647887323943536 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 27.464788732394226 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 27.464788732394226 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 27.464788732394226 94
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 2.81690140845069 9
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 5.63380281690138 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 12.676056338028104 31
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 17.60563380281681 42
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 25.35211267605621 58
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 28.169014084506898 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 28.169014084506898 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 28.169014084506898 95
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
coverage_call_count 4200
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fefa20> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc6a0> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473d68> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 3.5211267605633623 10
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 6.338028169014052 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 13.380281690140777 32
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 18.309859154929484 43
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 26.05633802816888 59
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 28.87323943661957 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 28.87323943661957 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 28.87323943661957 96
Completed Iteration #11
Best Reward: 0.7042253521126725
Completed Iteration #12
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091feff98> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 4.225352112676035 11
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 14.084507042253449 33
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 19.014084507042156 44
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 26.760563380281553 60
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 29.577464788732243 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 29.577464788732243 83
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 29.577464788732243 97
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d518> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d2e8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 4.929577464788707 12
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 14.788732394366122 34
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 19.71830985915483 45
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 27.464788732394226 61
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 30.281690140844916 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 30.281690140844916 84
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 30.281690140844916 98
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473fd0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473eb8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefa20> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc6a0> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473d68> 2.1126760563380174 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 5.63380281690138 13
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 8.45070422535207 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 15.492957746478794 35
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 20.4225352112675 46
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 28.169014084506898 62
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 30.985915492957588 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 30.985915492957588 85
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 30.985915492957588 99
Completed Iteration #18
Best Reward: 0.7042253521126725
Completed Iteration #19
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091feff98> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 5.63380281690138 14
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 15.492957746478794 36
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 20.4225352112675 47
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 28.169014084506898 63
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 30.985915492957588 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 30.985915492957588 86
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 30.985915492957588 100
Completed Iteration #20
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b24e0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 6.338028169014052 15
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 16.197183098591466 37
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 21.126760563380174 48
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 28.87323943661957 64
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 31.69014084507026 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 31.69014084507026 87
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 31.69014084507026 101
Completed Iteration #21
Best Reward: 0.7042253521126725
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fefb38> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d2e8> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 7.0422535211267245 16
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 9.859154929577414 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 16.90140845070414 38
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 21.830985915492846 49
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 29.577464788732243 65
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 32.39436619718293 74
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 32.39436619718293 88
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 32.39436619718293 102
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #7
root->6->18->0->4->1->10->1
Best Reward: 0.7042253521126725
Completed Iteration #0
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef198> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 2.81690140845069 6
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 7.0422535211267245 17
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 9.859154929577414 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 16.90140845070414 39
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 21.830985915492846 50
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 29.577464788732243 66
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 32.39436619718293 75
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 32.39436619718293 89
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 32.39436619718293 103
Completed Iteration #1
Best Reward: 0.7042253521126725
Completed Iteration #2
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefb38> 0.7042253521126725 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d2e8> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 2.81690140845069 7
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 7.0422535211267245 18
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 9.859154929577414 25
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 16.90140845070414 40
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 21.830985915492846 51
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 29.577464788732243 67
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 32.39436619718293 76
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 32.39436619718293 90
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 32.39436619718293 104
Completed Iteration #3
Best Reward: 0.7042253521126725
Completed Iteration #4
Best Reward: 0.7042253521126725
Completed Iteration #5
Best Reward: 0.7042253521126725
Completed Iteration #6
Best Reward: 0.7042253521126725
Completed Iteration #7
Best Reward: 0.7042253521126725
Completed Iteration #8
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd091fa31d0> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d080> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 3.5211267605633623 8
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 7.746478873239397 19
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 10.563380281690087 26
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 17.60563380281681 41
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 22.53521126760552 52
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 30.281690140844916 68
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 33.098591549295605 77
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 33.098591549295605 91
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 33.098591549295605 105
Completed Iteration #9
Best Reward: 0.7042253521126725
Completed Iteration #10
Best Reward: 0.7042253521126725
Completed Iteration #11
Best Reward: 0.7042253521126725
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d2e8> 1.408450704225345 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 3.5211267605633623 9
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 7.746478873239397 20
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 10.563380281690087 27
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 17.60563380281681 42
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 22.53521126760552 53
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 30.281690140844916 69
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 33.098591549295605 78
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 33.098591549295605 92
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 33.098591549295605 106
Completed Iteration #12
Best Reward: 0.7042253521126725
Completed Iteration #13
Best Reward: 0.7042253521126725
Completed Iteration #14
Best Reward: 0.7042253521126725
Completed Iteration #15
Best Reward: 0.7042253521126725
Completed Iteration #16
Best Reward: 0.7042253521126725
Completed Iteration #17
Best Reward: 0.7042253521126725
Completed Iteration #18
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533198> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc14a8> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b24e0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fef198> 1.408450704225345 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 4.225352112676035 10
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 8.45070422535207 21
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 11.26760563380276 28
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 18.309859154929484 43
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 23.23943661971819 54
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 30.985915492957588 70
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 33.80281690140828 79
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 33.80281690140828 93
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 33.80281690140828 107
Completed Iteration #19
Best Reward: 0.7042253521126725
Completed Iteration #20
Best Reward: 0.7042253521126725
Completed Iteration #21
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447a58> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d080> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 4.929577464788707 11
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 9.154929577464742 22
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 11.971830985915432 29
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 19.014084507042156 44
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 23.943661971830863 55
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 31.69014084507026 71
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 34.50704225352095 80
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 34.50704225352095 94
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 34.50704225352095 108
Completed Iteration #22
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452630> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d080> 2.1126760563380174 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 5.63380281690138 12
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 9.859154929577414 23
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 12.676056338028104 30
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 19.71830985915483 45
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 24.647887323943536 56
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 32.39436619718293 72
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 35.21126760563362 81
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 35.21126760563362 95
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 35.21126760563362 109
Completed Iteration #23
Best Reward: 0.7042253521126725
Completed Iteration #24
Best Reward: 0.7042253521126725
Reward: 0.7042253521126725
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9c18> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6978> 0.7042253521126725 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa31d0> 1.408450704225345 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d080> 2.81690140845069 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 6.338028169014052 13
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1358> 10.563380281690087 24
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 13.380281690140777 31
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447c50> 20.4225352112675 46
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 25.35211267605621 57
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533e10> 33.098591549295605 73
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9128> 35.915492957746295 82
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8eb8> 35.915492957746295 96
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87f0> 35.915492957746295 110
Completed Iteration #25
Best Reward: 0.7042253521126725
Completed MCTS Level/Depth: #8
root->6->18->0->4->1->10->1->11
Best Reward: 0.7042253521126725
iteration: 148
found coverage increase 0.7042253521126725
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fefb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84737b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84733c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85338d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091feffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85338d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85338d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091feffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091feffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091feffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533dd8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4300
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85080b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84735c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091feffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aacf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79835c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962518> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86add68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ade48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4500
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86701d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ade10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ade10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b6a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fcc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4600
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86987f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86987f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fa90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13073b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1d8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14016a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140163f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140163f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78610b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130725ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106664e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00950b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1401514a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00950b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400577b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1501179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd150127048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 4900
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1306be6d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14009e630> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3342b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 5000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78540b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3342b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140156748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140148f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334d30> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa36a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140148e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d59e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140148e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1401514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fa58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2ff28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5528d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5439e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5796a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5796a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b528198> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5799b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab325898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5799b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5521d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5521d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4867b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4867b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1b38> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4792e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4792e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4792e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4086a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2dd8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4087b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4087b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b443390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff22e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb50b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af275f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af605c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af607f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af605c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af607f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 6000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11064a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae806d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae806d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5795c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5792b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 6100
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5791d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab341c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14009e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaaf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130714dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae967b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b579940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140148f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e75f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80828> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc180f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140148f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd140057908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140057cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b552860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc184a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b552e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110656978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd150117d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400fdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b53fc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3342b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3342b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b579748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306b05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307adeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7819ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140025c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140151eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b53f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140151be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd11067e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130725e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd11067eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140163f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1a1dfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28cd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7861898> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd14007ff98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13074d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab28c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc765f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc765f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc765f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140065a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307ad2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8707a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd140013da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110692240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afaa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7839208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7854898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd140013438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc0b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091feff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13073b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091f8def0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd091f8dc50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd110656780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd110692240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc76860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86989b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8698940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fefdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13074d240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06ae806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fefa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13069e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fefeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b810b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b860a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab3346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8473f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84473c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ef0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b782acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b782ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84521d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fa3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc18898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b58d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1106f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd130765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fdc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fc13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d0020978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b87199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b865fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 6800
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79836d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc444a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7983d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79836d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b873f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd091fc1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab29f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8452668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc44ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091f8d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b862f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84aaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0063ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd1306e72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b86ad550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1306e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd13068bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b56a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85334a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d0095c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8533be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a846ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8447438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d00632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b79254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b872f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd13068b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85083c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85083c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b865f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b25c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b793de80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7962a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b863eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b81b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b7f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd14007f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fe6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a85084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1400b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b86d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8719da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b799b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a846e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b78b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0b863ee80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd1307f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00632e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0ab301d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0d00632e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd14007fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a853bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 7100
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a853b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2dd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e87b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b794cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7925208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b876ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff26d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5430f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b87195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b79837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a85089e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b486128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b408d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0d003b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f85f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b793def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b486cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afb5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b543940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b793ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab334f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b808f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4089b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b543160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b486eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3550> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3a58> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f8d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f898> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a847d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5285f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af044a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd091fef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af044a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06afde0f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 7400
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afde438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b7977e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84d93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4167b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a8508b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af492b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b408f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b528ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b789af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af27470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b528ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b443128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afdec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b479c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afde7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b416898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af604e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af604e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b528518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af157b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af15828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06af15ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af601d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 7500
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af27860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b408f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0a84e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b416f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06af600f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b81c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a0390f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a0393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aff2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af04080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699db6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069993908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069993cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb128> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 7600
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a0393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699936d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a0395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb390> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0ab2b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b479c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af3eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b4d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af496a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069993828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069993828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069993828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fbf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aeac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeace10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699530b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06996ad68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 7700
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b8670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a0395f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699532b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699532b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069993828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06996afd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699dba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699377f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd069937b70> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af04160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 7800
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069953f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069937828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5281d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06b5281d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06997af98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06afd25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd069937908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06aeacc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 70.4225352112676
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698abdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06996ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698abdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd06989b470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 70.4225352112676
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06989ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06bc2f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b4f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0b80d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd069953940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06af60748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06af49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06aef2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06997add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06a039518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06989bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06a039d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699db9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0699a86a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 70.4225352112676
coverage_call_count 7900
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06997a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06afd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06b443160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd06997a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698ab2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06986d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0699db710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06986d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd0698bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698e3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06986d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd06986d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06986d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd06986d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd0698bc2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 70.4225352112676
initial coverage: 69.0141
time passed (minutes): 60.2817
iterations: 293
number of new inputs: 128
final coverage: 70.4225
total coverage increase: 1.40845
